{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "O9OVdX3KDuXc"
      },
      "id": "O9OVdX3KDuXc"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lmUjF9kRjzX3",
        "outputId": "9eddf0d2-52f3-4869-eb97-86133a8f381d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lmUjF9kRjzX3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "%cd rapidsai-csp-utils\n",
        "!git checkout 22.12-patch\n",
        "%cd ..\n",
        "!python rapidsai-csp-utils/colab/env-check.py\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ],
      "metadata": {
        "id": "fy79bdDdCZRG",
        "outputId": "b44efc60-6c83-498e-cf88-c1a3339d7f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fy79bdDdCZRG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 390, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 390 (delta 89), reused 51 (delta 51), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (390/390), 107.11 KiB | 2.10 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n",
            "/content/rapidsai-csp-utils\n",
            "Branch '22.12-patch' set up to track remote branch '22.12-patch' from 'origin'.\n",
            "Switched to a new branch '22.12-patch'\n",
            "/content\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 1.2 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/rapidsai-csp-utils/colab/env-check.py\", line 26, in <module>\n",
            "    gpu_name = pynvml.nvmlDeviceGetName(pynvml.nvmlDeviceGetHandleByIndex(0)).decode('UTF-8')\n",
            "AttributeError: 'str' object has no attribute 'decode'. Did you mean: 'encode'?\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/rapidsai-csp-utils/colab/pip-install.py\", line 26, in <module>\n",
            "    gpu_name = pynvml.nvmlDeviceGetName(pynvml.nvmlDeviceGetHandleByIndex(0)).decode('UTF-8')\n",
            "AttributeError: 'str' object has no attribute 'decode'. Did you mean: 'encode'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Install the Merlin Framework\n",
        "pip install -Uq git+https://github.com/NVIDIA-Merlin/models.git@release-23.04\n",
        "pip install -Uq git+https://github.com/NVIDIA-Merlin/nvtabular.git@release-23.04\n",
        "pip install -Uq git+https://github.com/NVIDIA-Merlin/core.git@release-23.04\n",
        "# pip install -Uq git+https://github.com/NVIDIA-Merlin/system.git@release-23.04\n",
        "# pip install -Uq git+https://github.com/NVIDIA-Merlin/dataloader.git@release-23.04\n",
        "pip install -Uq git+https://github.com/NVIDIA-Merlin/Transformers4Rec.git@release-23.04\n",
        "# pip install -Uq xgboost lightfm implicit"
      ],
      "metadata": {
        "id": "l_p9H2WdCxT8",
        "outputId": "21d7cf0b-42f7-4a96-a3fb-19c30c12dbbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l_p9H2WdCxT8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.8/140.8 kB 2.4 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.9/46.9 kB 3.7 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.0/122.0 kB 5.3 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 3.6 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.3/62.3 kB 4.6 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 8.8 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 985.5/985.5 kB 13.3 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 21.7 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 23.3 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 7.1 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.4/7.4 MB 17.2 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 25.9 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 43.8 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 45.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "merlin-dataloader 23.6.0 requires merlin-core<23.07,>=23.06, but you have merlin-core 23.4.0+4.gc5c9bc2 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install -q tensorflow-recommenders"
      ],
      "metadata": {
        "id": "FO0n46Xv9Gw-",
        "outputId": "5082d875-867b-4e7c-b830-f7e46d2082c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FO0n46Xv9Gw-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.2/96.2 kB 2.0 MB/s eta 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "Reference\n",
        "- https://github.com/NVIDIA-Merlin/models/blob/main/examples/02-Merlin-Models-and-NVTabular-integration.ipynb"
      ],
      "metadata": {
        "id": "leuxcq3yQb0_"
      },
      "id": "leuxcq3yQb0_"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from nvtabular import ops\n",
        "from merlin.schema.tags import Tags\n",
        "import merlin.io\n",
        "import merlin.models.tf as mm\n",
        "\n",
        "import nvtabular as nvt\n",
        "\n",
        "from os import path\n",
        "\n",
        "# Get dataframe library - cudf or pandas\n",
        "from merlin.core.dispatch import get_lib\n",
        "pd = get_lib()"
      ],
      "metadata": {
        "id": "LjSofSHsQeSt",
        "outputId": "1d14bef5-2eb0-4bc7-a6a5-66870ee80f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LjSofSHsQeSt",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'\n",
            "  warn(f\"Triton dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = os.environ.get(\n",
        "    \"DATA_DIR\", os.path.expanduser(\"/content/drive/MyDrive/ml-twotower-model/data/\")\n",
        ")"
      ],
      "metadata": {
        "id": "oMyxkDFKQm1T"
      },
      "id": "oMyxkDFKQm1T",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "USE_AUGMENTED_DATASET= False\n",
        "DATA_VERSION = 'v4'\n",
        "\n",
        "_TRAIN,_VALID,_TEST = ('train_aug', 'valid_aug', 'test_aug') if USE_AUGMENTED_DATASET else ('train', 'valid', 'test')\n",
        "\n",
        "TRAIN_PATHS = sorted(glob.glob(os.path.join(DATA_DIR, _TRAIN + f'_{DATA_VERSION}', \"*.parquet\")))\n",
        "VALID_PATHS = sorted(glob.glob(os.path.join(DATA_DIR, _VALID + f'_{DATA_VERSION}', \"*.parquet\")))\n",
        "TEST_PATHS = sorted(glob.glob(os.path.join(DATA_DIR, _TEST + f'_{DATA_VERSION}', \"*.parquet\")))\n",
        "TRAIN_PATHS, VALID_PATHS, TEST_PATHS"
      ],
      "metadata": {
        "id": "5D6cdG2uexNC",
        "outputId": "7cd7e95b-8e77-4627-ca3d-5c9955ba9f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5D6cdG2uexNC",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content/drive/MyDrive/ml-twotower-model/data/train_v4/part_0.parquet'],\n",
              " ['/content/drive/MyDrive/ml-twotower-model/data/valid_v4/part_0.parquet'],\n",
              " ['/content/drive/MyDrive/ml-twotower-model/data/test_v4/part_0.parquet'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = merlin.io.Dataset(\n",
        "    TRAIN_PATHS, engine=\"parquet\"\n",
        ")\n",
        "valid = merlin.io.Dataset(\n",
        "    VALID_PATHS, engine=\"parquet\"\n",
        ")"
      ],
      "metadata": {
        "id": "zFq-mldJ_29G",
        "outputId": "4c3e7db5-4ae5-4590-f8d5-f4a71c1fec2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zFq-mldJ_29G",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = train.schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER, Tags.TARGET])\n",
        "schema"
      ],
      "metadata": {
        "id": "CGqTYHx7e7S3",
        "outputId": "10e9c642-d9be-4a67-adf0-f27c6d2058f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "id": "CGqTYHx7e7S3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'movie_id', 'tags': {<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'start_index': 0.0, 'max_size': 0.0, 'freq_threshold': 0.0, 'embedding_sizes': {'cardinality': 1665.0, 'dimension': 102.0}, 'num_buckets': None, 'cat_path': './/categories/unique.movie_id.parquet', 'domain': {'min': 0, 'max': 1664, 'name': 'movie_id'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_id', 'tags': {<Tags.ID: 'id'>, <Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'max_size': 0.0, 'embedding_sizes': {'cardinality': 944.0, 'dimension': 74.0}, 'num_buckets': None, 'freq_threshold': 0.0, 'cat_path': './/categories/unique.user_id.parquet', 'start_index': 0.0, 'domain': {'min': 0, 'max': 943, 'name': 'user_id'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'gender', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'max_size': 0.0, 'embedding_sizes': {'cardinality': 3.0, 'dimension': 16.0}, 'cat_path': './/categories/unique.gender.parquet', 'start_index': 0.0, 'freq_threshold': 0.0, 'domain': {'min': 0, 'max': 2, 'name': 'gender'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'occupation', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'max_size': 0.0, 'num_buckets': None, 'cat_path': './/categories/unique.occupation.parquet', 'freq_threshold': 0.0, 'start_index': 0.0, 'embedding_sizes': {'dimension': 16.0, 'cardinality': 22.0}, 'domain': {'min': 0, 'max': 21, 'name': 'occupation'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'genres', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'start_index': 0.0, 'cat_path': './/categories/unique.genres.parquet', 'num_buckets': None, 'max_size': 0.0, 'embedding_sizes': {'dimension': 16.0, 'cardinality': 20.0}, 'freq_threshold': 0.0, 'domain': {'min': 0, 'max': 19, 'name': 'genres'}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'rating', 'tags': {<Tags.TARGET: 'target'>, <Tags.BINARY_CLASSIFICATION: 'binary_classification'>}, 'properties': {}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>dtype</th>\n",
              "      <th>is_list</th>\n",
              "      <th>is_ragged</th>\n",
              "      <th>properties.start_index</th>\n",
              "      <th>properties.max_size</th>\n",
              "      <th>properties.freq_threshold</th>\n",
              "      <th>properties.embedding_sizes.cardinality</th>\n",
              "      <th>properties.embedding_sizes.dimension</th>\n",
              "      <th>properties.num_buckets</th>\n",
              "      <th>properties.cat_path</th>\n",
              "      <th>properties.domain.min</th>\n",
              "      <th>properties.domain.max</th>\n",
              "      <th>properties.domain.name</th>\n",
              "      <th>properties.value_count.min</th>\n",
              "      <th>properties.value_count.max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie_id</td>\n",
              "      <td>(Tags.ID, Tags.ITEM, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1665.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.//categories/unique.movie_id.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1664.0</td>\n",
              "      <td>movie_id</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user_id</td>\n",
              "      <td>(Tags.ID, Tags.USER, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>944.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.//categories/unique.user_id.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>943.0</td>\n",
              "      <td>user_id</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gender</td>\n",
              "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.//categories/unique.gender.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>gender</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>occupation</td>\n",
              "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.//categories/unique.occupation.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>occupation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>genres</td>\n",
              "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.//categories/unique.genres.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>genres</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rating</td>\n",
              "      <td>(Tags.TARGET, Tags.BINARY_CLASSIFICATION)</td>\n",
              "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_ddf().compute()"
      ],
      "metadata": {
        "id": "LxvBJ9AAu2jv",
        "outputId": "da3fb447-5ca7-4693-928c-bcb898834095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "id": "LxvBJ9AAu2jv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       movie_id  user_id  gender  occupation     genres  rating  movie_id_raw\n",
              "0           121       13       1           1        [1]     1.0           134\n",
              "1           196       33       1          18  [1, 4, 8]     1.0            31\n",
              "2           451      901       1           1     [2, 5]     1.0           354\n",
              "3            48       88       2           8     [2, 5]     0.0           202\n",
              "4           330       30       1           4        [1]     0.0           708\n",
              "...         ...      ...     ...         ...        ...     ...           ...\n",
              "70197        60      232       1           1    [1, 13]     0.0           289\n",
              "70198        89       80       1           1  [4, 3, 9]     0.0           273\n",
              "70199       180      253       1          11        [1]     1.0           285\n",
              "70200       507      111       1          15        [1]     1.0           468\n",
              "70201       919      114       2          12        [2]     0.0           335\n",
              "\n",
              "[70202 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-be93e8fd-1fa0-4f48-a13c-3560cc18d537\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>occupation</th>\n",
              "      <th>genres</th>\n",
              "      <th>rating</th>\n",
              "      <th>movie_id_raw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>196</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>[1, 4, 8]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>451</td>\n",
              "      <td>901</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 5]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>88</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>[2, 5]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>330</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70197</th>\n",
              "      <td>60</td>\n",
              "      <td>232</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 13]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70198</th>\n",
              "      <td>89</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[4, 3, 9]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70199</th>\n",
              "      <td>180</td>\n",
              "      <td>253</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70200</th>\n",
              "      <td>507</td>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70201</th>\n",
              "      <td>919</td>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>[2]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70202 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be93e8fd-1fa0-4f48-a13c-3560cc18d537')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-94ad6259-9a21-43e5-9de1-5c023399913b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94ad6259-9a21-43e5-9de1-5c023399913b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-94ad6259-9a21-43e5-9de1-5c023399913b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be93e8fd-1fa0-4f48-a13c-3560cc18d537 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be93e8fd-1fa0-4f48-a13c-3560cc18d537');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select only trainable features and exclude the target\n",
        "train.schema = schema\n",
        "valid.schema = schema"
      ],
      "metadata": {
        "id": "WbRIH8RFGffj"
      },
      "id": "WbRIH8RFGffj",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(schema.select_by_tag(Tags.TARGET).column_names) == 0"
      ],
      "metadata": {
        "id": "2GIeVnCBGorg",
        "outputId": "84329b47-8198-415a-e929-718d6e941362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "id": "2GIeVnCBGorg",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4362730046aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_by_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "Reference\n",
        "- https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb"
      ],
      "metadata": {
        "id": "JPEWOKkqBfEv"
      },
      "id": "JPEWOKkqBfEv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition"
      ],
      "metadata": {
        "id": "5CsVpfG9Seei"
      },
      "id": "5CsVpfG9Seei"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_towers(schema=schema, tower_dim = 64):\n",
        "    # create user schema using USER tag\n",
        "    user_schema = schema.select_by_tag(Tags.USER)\n",
        "    # create user (query) tower input block\n",
        "    user_inputs = mm.InputBlockV2(user_schema)\n",
        "    # create user (query) encoder block\n",
        "    query = mm.Encoder(user_inputs, mm.MLPBlock([128, tower_dim], no_activation_last_layer=True))\n",
        "\n",
        "    # create item schema using ITEM tag\n",
        "    item_schema = schema.select_by_tag(Tags.ITEM)\n",
        "    # create item (candidate) tower input block\n",
        "    item_inputs = mm.InputBlockV2(item_schema)\n",
        "    # create item (candidate) encoder block\n",
        "    candidate = mm.Encoder(item_inputs, mm.MLPBlock([128, tower_dim], no_activation_last_layer=True))\n",
        "\n",
        "    return mm.TwoTowerModelV2(query, candidate)\n"
      ],
      "metadata": {
        "id": "gwUoJkdV6Mna"
      },
      "id": "gwUoJkdV6Mna",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v1"
      ],
      "metadata": {
        "id": "X44WDTdsydUO"
      },
      "id": "X44WDTdsydUO"
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_towers()"
      ],
      "metadata": {
        "id": "mqPId2wVHT1f"
      },
      "id": "mqPId2wVHT1f",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adagrad(learning_rate=1e-2)\n",
        "model.compile(optimizer=opt, run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10), tf.keras.metrics.AUC()])\n",
        "history = model.fit(train, validation_data=valid, batch_size=128, epochs=10)"
      ],
      "metadata": {
        "id": "6KPUbfd0HnV1",
        "outputId": "378fed6e-4fa7-4c14-b805-6cacef69d398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6KPUbfd0HnV1",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 34s 41ms/step - loss: 4.8493 - auc: 0.4999 - recall_at_10: 0.0801 - ndcg_at_10: 0.0371 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5002 - val_recall_at_10: 0.0790 - val_ndcg_at_10: 0.0361 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.8494 - auc: 0.5000 - recall_at_10: 0.0813 - ndcg_at_10: 0.0374 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5002 - val_recall_at_10: 0.0788 - val_ndcg_at_10: 0.0361 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 14s 23ms/step - loss: 4.8493 - auc: 0.5000 - recall_at_10: 0.0816 - ndcg_at_10: 0.0376 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8487 - val_auc: 0.5001 - val_recall_at_10: 0.0803 - val_ndcg_at_10: 0.0366 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.8494 - auc: 0.5000 - recall_at_10: 0.0818 - ndcg_at_10: 0.0376 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5001 - val_recall_at_10: 0.0800 - val_ndcg_at_10: 0.0369 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.8493 - auc: 0.5000 - recall_at_10: 0.0838 - ndcg_at_10: 0.0385 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5000 - val_recall_at_10: 0.0802 - val_ndcg_at_10: 0.0369 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 11s 20ms/step - loss: 4.8493 - auc: 0.5001 - recall_at_10: 0.0840 - ndcg_at_10: 0.0389 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5001 - val_recall_at_10: 0.0812 - val_ndcg_at_10: 0.0374 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.8493 - auc: 0.5001 - recall_at_10: 0.0840 - ndcg_at_10: 0.0390 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5001 - val_recall_at_10: 0.0827 - val_ndcg_at_10: 0.0383 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.8493 - auc: 0.5001 - recall_at_10: 0.0846 - ndcg_at_10: 0.0393 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8488 - val_auc: 0.5000 - val_recall_at_10: 0.0831 - val_ndcg_at_10: 0.0383 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.8493 - auc: 0.5001 - recall_at_10: 0.0840 - ndcg_at_10: 0.0393 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8487 - val_auc: 0.5003 - val_recall_at_10: 0.0831 - val_ndcg_at_10: 0.0387 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5984\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.8493 - auc: 0.5004 - recall_at_10: 0.0853 - ndcg_at_10: 0.0390 - regularization_loss: 0.0000e+00 - loss_batch: 4.8471 - val_loss: 4.8487 - val_auc: 0.5009 - val_recall_at_10: 0.0837 - val_ndcg_at_10: 0.0393 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v2"
      ],
      "metadata": {
        "id": "jihtAbOwr5nA"
      },
      "id": "jihtAbOwr5nA"
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2 = build_towers()"
      ],
      "metadata": {
        "id": "W247T5Ea1kh9"
      },
      "id": "W247T5Ea1kh9",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "model_v2.compile(optimizer=opt, run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10), tf.keras.metrics.AUC(), mm.MRRAt(10), mm.PrecisionAt(10)])\n",
        "history = model_v2.fit(train, validation_data=valid, batch_size=128, epochs=50)"
      ],
      "metadata": {
        "id": "OimNlStb1yL-",
        "outputId": "2985c3c7-b615-40af-8242-761144750afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OimNlStb1yL-",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "549/549 [==============================] - 31s 42ms/step - loss: 4.7178 - auc_3: 0.5832 - recall_at_10: 0.1140 - ndcg_at_10: 0.0533 - mrr_at_10: 0.0353 - precision_at_10: 0.0114 - regularization_loss: 0.0000e+00 - loss_batch: 4.7155 - val_loss: 4.7411 - val_auc_3: 0.6028 - val_recall_at_10: 0.1718 - val_ndcg_at_10: 0.0811 - val_mrr_at_10: 0.0542 - val_precision_at_10: 0.0172 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8512\n",
            "Epoch 2/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.4944 - auc_3: 0.6298 - recall_at_10: 0.2186 - ndcg_at_10: 0.1048 - mrr_at_10: 0.0709 - precision_at_10: 0.0219 - regularization_loss: 0.0000e+00 - loss_batch: 4.4922 - val_loss: 4.6490 - val_auc_3: 0.5609 - val_recall_at_10: 0.1874 - val_ndcg_at_10: 0.0910 - val_mrr_at_10: 0.0621 - val_precision_at_10: 0.0187 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.6053\n",
            "Epoch 3/50\n",
            "549/549 [==============================] - 16s 28ms/step - loss: 4.4325 - auc_3: 0.6364 - recall_at_10: 0.2422 - ndcg_at_10: 0.1198 - mrr_at_10: 0.0831 - precision_at_10: 0.0242 - regularization_loss: 0.0000e+00 - loss_batch: 4.4304 - val_loss: 4.7065 - val_auc_3: 0.5864 - val_recall_at_10: 0.1968 - val_ndcg_at_10: 0.0941 - val_mrr_at_10: 0.0634 - val_precision_at_10: 0.0197 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9498\n",
            "Epoch 4/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.4004 - auc_3: 0.6414 - recall_at_10: 0.2587 - ndcg_at_10: 0.1300 - mrr_at_10: 0.0914 - precision_at_10: 0.0259 - regularization_loss: 0.0000e+00 - loss_batch: 4.3982 - val_loss: 4.6644 - val_auc_3: 0.5819 - val_recall_at_10: 0.1955 - val_ndcg_at_10: 0.0956 - val_mrr_at_10: 0.0658 - val_precision_at_10: 0.0195 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8557\n",
            "Epoch 5/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.3749 - auc_3: 0.6440 - recall_at_10: 0.2719 - ndcg_at_10: 0.1383 - mrr_at_10: 0.0982 - precision_at_10: 0.0272 - regularization_loss: 0.0000e+00 - loss_batch: 4.3726 - val_loss: 4.6578 - val_auc_3: 0.5784 - val_recall_at_10: 0.2020 - val_ndcg_at_10: 0.0980 - val_mrr_at_10: 0.0669 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7656\n",
            "Epoch 6/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3579 - auc_3: 0.6507 - recall_at_10: 0.2760 - ndcg_at_10: 0.1407 - mrr_at_10: 0.1001 - precision_at_10: 0.0276 - regularization_loss: 0.0000e+00 - loss_batch: 4.3556 - val_loss: 4.6742 - val_auc_3: 0.5737 - val_recall_at_10: 0.2047 - val_ndcg_at_10: 0.0991 - val_mrr_at_10: 0.0676 - val_precision_at_10: 0.0205 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1531\n",
            "Epoch 7/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.3469 - auc_3: 0.6486 - recall_at_10: 0.2835 - ndcg_at_10: 0.1457 - mrr_at_10: 0.1043 - precision_at_10: 0.0283 - regularization_loss: 0.0000e+00 - loss_batch: 4.3445 - val_loss: 4.6787 - val_auc_3: 0.5689 - val_recall_at_10: 0.2012 - val_ndcg_at_10: 0.0969 - val_mrr_at_10: 0.0658 - val_precision_at_10: 0.0201 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9248\n",
            "Epoch 8/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.3336 - auc_3: 0.6515 - recall_at_10: 0.2910 - ndcg_at_10: 0.1502 - mrr_at_10: 0.1079 - precision_at_10: 0.0291 - regularization_loss: 0.0000e+00 - loss_batch: 4.3314 - val_loss: 4.6481 - val_auc_3: 0.5727 - val_recall_at_10: 0.2001 - val_ndcg_at_10: 0.0958 - val_mrr_at_10: 0.0647 - val_precision_at_10: 0.0200 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0247\n",
            "Epoch 9/50\n",
            "549/549 [==============================] - 13s 21ms/step - loss: 4.3249 - auc_3: 0.6563 - recall_at_10: 0.2893 - ndcg_at_10: 0.1509 - mrr_at_10: 0.1092 - precision_at_10: 0.0289 - regularization_loss: 0.0000e+00 - loss_batch: 4.3226 - val_loss: 4.6604 - val_auc_3: 0.5683 - val_recall_at_10: 0.2026 - val_ndcg_at_10: 0.0971 - val_mrr_at_10: 0.0656 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0247\n",
            "Epoch 10/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3183 - auc_3: 0.6531 - recall_at_10: 0.2953 - ndcg_at_10: 0.1548 - mrr_at_10: 0.1125 - precision_at_10: 0.0295 - regularization_loss: 0.0000e+00 - loss_batch: 4.3160 - val_loss: 4.6475 - val_auc_3: 0.5909 - val_recall_at_10: 0.2130 - val_ndcg_at_10: 0.1024 - val_mrr_at_10: 0.0693 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8801\n",
            "Epoch 11/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3130 - auc_3: 0.6557 - recall_at_10: 0.2990 - ndcg_at_10: 0.1563 - mrr_at_10: 0.1134 - precision_at_10: 0.0299 - regularization_loss: 0.0000e+00 - loss_batch: 4.3106 - val_loss: 4.6813 - val_auc_3: 0.5651 - val_recall_at_10: 0.2026 - val_ndcg_at_10: 0.0984 - val_mrr_at_10: 0.0672 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9595\n",
            "Epoch 12/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.3076 - auc_3: 0.6514 - recall_at_10: 0.2967 - ndcg_at_10: 0.1549 - mrr_at_10: 0.1123 - precision_at_10: 0.0297 - regularization_loss: 0.0000e+00 - loss_batch: 4.3051 - val_loss: 4.7463 - val_auc_3: 0.5749 - val_recall_at_10: 0.2028 - val_ndcg_at_10: 0.0985 - val_mrr_at_10: 0.0672 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0902\n",
            "Epoch 13/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.3051 - auc_3: 0.6488 - recall_at_10: 0.2999 - ndcg_at_10: 0.1569 - mrr_at_10: 0.1138 - precision_at_10: 0.0300 - regularization_loss: 0.0000e+00 - loss_batch: 4.3027 - val_loss: 4.6808 - val_auc_3: 0.5731 - val_recall_at_10: 0.2117 - val_ndcg_at_10: 0.1030 - val_mrr_at_10: 0.0704 - val_precision_at_10: 0.0212 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0871\n",
            "Epoch 14/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2984 - auc_3: 0.6465 - recall_at_10: 0.2978 - ndcg_at_10: 0.1562 - mrr_at_10: 0.1136 - precision_at_10: 0.0298 - regularization_loss: 0.0000e+00 - loss_batch: 4.2963 - val_loss: 4.6508 - val_auc_3: 0.5632 - val_recall_at_10: 0.2064 - val_ndcg_at_10: 0.1004 - val_mrr_at_10: 0.0687 - val_precision_at_10: 0.0206 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9106\n",
            "Epoch 15/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.2954 - auc_3: 0.6461 - recall_at_10: 0.3029 - ndcg_at_10: 0.1580 - mrr_at_10: 0.1143 - precision_at_10: 0.0303 - regularization_loss: 0.0000e+00 - loss_batch: 4.2932 - val_loss: 4.7107 - val_auc_3: 0.5658 - val_recall_at_10: 0.1999 - val_ndcg_at_10: 0.0953 - val_mrr_at_10: 0.0641 - val_precision_at_10: 0.0200 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1159\n",
            "Epoch 16/50\n",
            "549/549 [==============================] - 11s 19ms/step - loss: 4.2934 - auc_3: 0.6490 - recall_at_10: 0.2994 - ndcg_at_10: 0.1575 - mrr_at_10: 0.1148 - precision_at_10: 0.0299 - regularization_loss: 0.0000e+00 - loss_batch: 4.2910 - val_loss: 4.6752 - val_auc_3: 0.5891 - val_recall_at_10: 0.2177 - val_ndcg_at_10: 0.1057 - val_mrr_at_10: 0.0722 - val_precision_at_10: 0.0218 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.6185\n",
            "Epoch 17/50\n",
            "549/549 [==============================] - 15s 25ms/step - loss: 4.2886 - auc_3: 0.6497 - recall_at_10: 0.3031 - ndcg_at_10: 0.1597 - mrr_at_10: 0.1166 - precision_at_10: 0.0303 - regularization_loss: 0.0000e+00 - loss_batch: 4.2861 - val_loss: 4.7468 - val_auc_3: 0.5595 - val_recall_at_10: 0.1962 - val_ndcg_at_10: 0.0946 - val_mrr_at_10: 0.0643 - val_precision_at_10: 0.0196 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2555\n",
            "Epoch 18/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2877 - auc_3: 0.6494 - recall_at_10: 0.3068 - ndcg_at_10: 0.1614 - mrr_at_10: 0.1176 - precision_at_10: 0.0307 - regularization_loss: 0.0000e+00 - loss_batch: 4.2852 - val_loss: 4.6906 - val_auc_3: 0.5806 - val_recall_at_10: 0.2133 - val_ndcg_at_10: 0.1036 - val_mrr_at_10: 0.0709 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.6245\n",
            "Epoch 19/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2847 - auc_3: 0.6477 - recall_at_10: 0.3067 - ndcg_at_10: 0.1612 - mrr_at_10: 0.1174 - precision_at_10: 0.0307 - regularization_loss: 0.0000e+00 - loss_batch: 4.2823 - val_loss: 4.6742 - val_auc_3: 0.5753 - val_recall_at_10: 0.2106 - val_ndcg_at_10: 0.1033 - val_mrr_at_10: 0.0711 - val_precision_at_10: 0.0211 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0795\n",
            "Epoch 20/50\n",
            "549/549 [==============================] - 12s 22ms/step - loss: 4.2832 - auc_3: 0.6437 - recall_at_10: 0.3025 - ndcg_at_10: 0.1588 - mrr_at_10: 0.1156 - precision_at_10: 0.0302 - regularization_loss: 0.0000e+00 - loss_batch: 4.2808 - val_loss: 4.6940 - val_auc_3: 0.5582 - val_recall_at_10: 0.2068 - val_ndcg_at_10: 0.0995 - val_mrr_at_10: 0.0674 - val_precision_at_10: 0.0207 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2136\n",
            "Epoch 21/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2810 - auc_3: 0.6398 - recall_at_10: 0.3070 - ndcg_at_10: 0.1620 - mrr_at_10: 0.1183 - precision_at_10: 0.0307 - regularization_loss: 0.0000e+00 - loss_batch: 4.2788 - val_loss: 4.7248 - val_auc_3: 0.5581 - val_recall_at_10: 0.2036 - val_ndcg_at_10: 0.0976 - val_mrr_at_10: 0.0660 - val_precision_at_10: 0.0204 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9909\n",
            "Epoch 22/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.2785 - auc_3: 0.6403 - recall_at_10: 0.3110 - ndcg_at_10: 0.1648 - mrr_at_10: 0.1206 - precision_at_10: 0.0311 - regularization_loss: 0.0000e+00 - loss_batch: 4.2761 - val_loss: 4.7200 - val_auc_3: 0.5506 - val_recall_at_10: 0.2009 - val_ndcg_at_10: 0.0958 - val_mrr_at_10: 0.0645 - val_precision_at_10: 0.0201 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1769\n",
            "Epoch 23/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2768 - auc_3: 0.6416 - recall_at_10: 0.3079 - ndcg_at_10: 0.1627 - mrr_at_10: 0.1189 - precision_at_10: 0.0308 - regularization_loss: 0.0000e+00 - loss_batch: 4.2745 - val_loss: 4.6889 - val_auc_3: 0.5584 - val_recall_at_10: 0.2046 - val_ndcg_at_10: 0.0994 - val_mrr_at_10: 0.0679 - val_precision_at_10: 0.0205 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0279\n",
            "Epoch 24/50\n",
            "549/549 [==============================] - 13s 24ms/step - loss: 4.2783 - auc_3: 0.6419 - recall_at_10: 0.3093 - ndcg_at_10: 0.1638 - mrr_at_10: 0.1199 - precision_at_10: 0.0309 - regularization_loss: 0.0000e+00 - loss_batch: 4.2758 - val_loss: 4.7237 - val_auc_3: 0.5667 - val_recall_at_10: 0.2106 - val_ndcg_at_10: 0.1027 - val_mrr_at_10: 0.0704 - val_precision_at_10: 0.0211 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2376\n",
            "Epoch 25/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.2742 - auc_3: 0.6438 - recall_at_10: 0.3066 - ndcg_at_10: 0.1624 - mrr_at_10: 0.1190 - precision_at_10: 0.0307 - regularization_loss: 0.0000e+00 - loss_batch: 4.2719 - val_loss: 4.7193 - val_auc_3: 0.5611 - val_recall_at_10: 0.2042 - val_ndcg_at_10: 0.0991 - val_mrr_at_10: 0.0676 - val_precision_at_10: 0.0204 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2764\n",
            "Epoch 26/50\n",
            "549/549 [==============================] - 13s 21ms/step - loss: 4.2725 - auc_3: 0.6384 - recall_at_10: 0.3066 - ndcg_at_10: 0.1623 - mrr_at_10: 0.1188 - precision_at_10: 0.0307 - regularization_loss: 0.0000e+00 - loss_batch: 4.2701 - val_loss: 4.7036 - val_auc_3: 0.5641 - val_recall_at_10: 0.2110 - val_ndcg_at_10: 0.1031 - val_mrr_at_10: 0.0708 - val_precision_at_10: 0.0211 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3940\n",
            "Epoch 27/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.2726 - auc_3: 0.6367 - recall_at_10: 0.3096 - ndcg_at_10: 0.1640 - mrr_at_10: 0.1201 - precision_at_10: 0.0310 - regularization_loss: 0.0000e+00 - loss_batch: 4.2702 - val_loss: 4.7553 - val_auc_3: 0.5605 - val_recall_at_10: 0.2127 - val_ndcg_at_10: 0.1028 - val_mrr_at_10: 0.0700 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5302\n",
            "Epoch 28/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.2712 - auc_3: 0.6370 - recall_at_10: 0.3088 - ndcg_at_10: 0.1646 - mrr_at_10: 0.1212 - precision_at_10: 0.0309 - regularization_loss: 0.0000e+00 - loss_batch: 4.2688 - val_loss: 4.6740 - val_auc_3: 0.5679 - val_recall_at_10: 0.2242 - val_ndcg_at_10: 0.1078 - val_mrr_at_10: 0.0730 - val_precision_at_10: 0.0224 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3952\n",
            "Epoch 29/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2707 - auc_3: 0.6373 - recall_at_10: 0.3061 - ndcg_at_10: 0.1614 - mrr_at_10: 0.1178 - precision_at_10: 0.0306 - regularization_loss: 0.0000e+00 - loss_batch: 4.2684 - val_loss: 4.6742 - val_auc_3: 0.5645 - val_recall_at_10: 0.2034 - val_ndcg_at_10: 0.0976 - val_mrr_at_10: 0.0660 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1099\n",
            "Epoch 30/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2673 - auc_3: 0.6380 - recall_at_10: 0.3098 - ndcg_at_10: 0.1643 - mrr_at_10: 0.1204 - precision_at_10: 0.0310 - regularization_loss: 0.0000e+00 - loss_batch: 4.2648 - val_loss: 4.7077 - val_auc_3: 0.5616 - val_recall_at_10: 0.2055 - val_ndcg_at_10: 0.0982 - val_mrr_at_10: 0.0661 - val_precision_at_10: 0.0205 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4830\n",
            "Epoch 31/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2672 - auc_3: 0.6395 - recall_at_10: 0.3104 - ndcg_at_10: 0.1650 - mrr_at_10: 0.1211 - precision_at_10: 0.0310 - regularization_loss: 0.0000e+00 - loss_batch: 4.2649 - val_loss: 4.7392 - val_auc_3: 0.5628 - val_recall_at_10: 0.2028 - val_ndcg_at_10: 0.0982 - val_mrr_at_10: 0.0668 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2745\n",
            "Epoch 32/50\n",
            "549/549 [==============================] - 12s 22ms/step - loss: 4.2654 - auc_3: 0.6323 - recall_at_10: 0.3115 - ndcg_at_10: 0.1653 - mrr_at_10: 0.1213 - precision_at_10: 0.0311 - regularization_loss: 0.0000e+00 - loss_batch: 4.2630 - val_loss: 4.7440 - val_auc_3: 0.5550 - val_recall_at_10: 0.2030 - val_ndcg_at_10: 0.0974 - val_mrr_at_10: 0.0659 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4538\n",
            "Epoch 33/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.2681 - auc_3: 0.6337 - recall_at_10: 0.3085 - ndcg_at_10: 0.1642 - mrr_at_10: 0.1207 - precision_at_10: 0.0308 - regularization_loss: 0.0000e+00 - loss_batch: 4.2658 - val_loss: 4.7237 - val_auc_3: 0.5630 - val_recall_at_10: 0.2143 - val_ndcg_at_10: 0.1020 - val_mrr_at_10: 0.0685 - val_precision_at_10: 0.0214 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1594\n",
            "Epoch 34/50\n",
            "549/549 [==============================] - 14s 23ms/step - loss: 4.2616 - auc_3: 0.6351 - recall_at_10: 0.3144 - ndcg_at_10: 0.1663 - mrr_at_10: 0.1216 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 4.2593 - val_loss: 4.7230 - val_auc_3: 0.5692 - val_recall_at_10: 0.2159 - val_ndcg_at_10: 0.1046 - val_mrr_at_10: 0.0714 - val_precision_at_10: 0.0216 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3405\n",
            "Epoch 35/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2620 - auc_3: 0.6333 - recall_at_10: 0.3119 - ndcg_at_10: 0.1664 - mrr_at_10: 0.1226 - precision_at_10: 0.0312 - regularization_loss: 0.0000e+00 - loss_batch: 4.2596 - val_loss: 4.7691 - val_auc_3: 0.5593 - val_recall_at_10: 0.2102 - val_ndcg_at_10: 0.1012 - val_mrr_at_10: 0.0687 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1992\n",
            "Epoch 36/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2703 - auc_3: 0.6343 - recall_at_10: 0.3081 - ndcg_at_10: 0.1631 - mrr_at_10: 0.1194 - precision_at_10: 0.0308 - regularization_loss: 0.0000e+00 - loss_batch: 4.2678 - val_loss: 4.6803 - val_auc_3: 0.5716 - val_recall_at_10: 0.2219 - val_ndcg_at_10: 0.1066 - val_mrr_at_10: 0.0722 - val_precision_at_10: 0.0222 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1482\n",
            "Epoch 37/50\n",
            "549/549 [==============================] - 12s 22ms/step - loss: 4.2582 - auc_3: 0.6339 - recall_at_10: 0.3128 - ndcg_at_10: 0.1666 - mrr_at_10: 0.1225 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2559 - val_loss: 4.7412 - val_auc_3: 0.5635 - val_recall_at_10: 0.2102 - val_ndcg_at_10: 0.1016 - val_mrr_at_10: 0.0691 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2099\n",
            "Epoch 38/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2583 - auc_3: 0.6319 - recall_at_10: 0.3138 - ndcg_at_10: 0.1660 - mrr_at_10: 0.1214 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 4.2559 - val_loss: 4.6821 - val_auc_3: 0.5634 - val_recall_at_10: 0.2255 - val_ndcg_at_10: 0.1088 - val_mrr_at_10: 0.0738 - val_precision_at_10: 0.0225 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3709\n",
            "Epoch 39/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2641 - auc_3: 0.6295 - recall_at_10: 0.3127 - ndcg_at_10: 0.1666 - mrr_at_10: 0.1226 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2617 - val_loss: 4.6932 - val_auc_3: 0.5746 - val_recall_at_10: 0.2195 - val_ndcg_at_10: 0.1074 - val_mrr_at_10: 0.0739 - val_precision_at_10: 0.0219 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3928\n",
            "Epoch 40/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.2615 - auc_3: 0.6276 - recall_at_10: 0.3079 - ndcg_at_10: 0.1643 - mrr_at_10: 0.1210 - precision_at_10: 0.0308 - regularization_loss: 0.0000e+00 - loss_batch: 4.2591 - val_loss: 4.7437 - val_auc_3: 0.5536 - val_recall_at_10: 0.2017 - val_ndcg_at_10: 0.0966 - val_mrr_at_10: 0.0653 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4113\n",
            "Epoch 41/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.2567 - auc_3: 0.6271 - recall_at_10: 0.3150 - ndcg_at_10: 0.1679 - mrr_at_10: 0.1235 - precision_at_10: 0.0315 - regularization_loss: 0.0000e+00 - loss_batch: 4.2543 - val_loss: 4.7589 - val_auc_3: 0.5657 - val_recall_at_10: 0.2117 - val_ndcg_at_10: 0.1022 - val_mrr_at_10: 0.0694 - val_precision_at_10: 0.0212 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4418\n",
            "Epoch 42/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2577 - auc_3: 0.6243 - recall_at_10: 0.3168 - ndcg_at_10: 0.1685 - mrr_at_10: 0.1238 - precision_at_10: 0.0317 - regularization_loss: 0.0000e+00 - loss_batch: 4.2553 - val_loss: 4.7272 - val_auc_3: 0.5576 - val_recall_at_10: 0.2066 - val_ndcg_at_10: 0.0990 - val_mrr_at_10: 0.0669 - val_precision_at_10: 0.0207 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4141\n",
            "Epoch 43/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2549 - auc_3: 0.6221 - recall_at_10: 0.3192 - ndcg_at_10: 0.1699 - mrr_at_10: 0.1250 - precision_at_10: 0.0319 - regularization_loss: 0.0000e+00 - loss_batch: 4.2526 - val_loss: 4.7207 - val_auc_3: 0.5627 - val_recall_at_10: 0.2145 - val_ndcg_at_10: 0.1035 - val_mrr_at_10: 0.0703 - val_precision_at_10: 0.0215 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4151\n",
            "Epoch 44/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.2565 - auc_3: 0.6215 - recall_at_10: 0.3152 - ndcg_at_10: 0.1684 - mrr_at_10: 0.1242 - precision_at_10: 0.0315 - regularization_loss: 0.0000e+00 - loss_batch: 4.2541 - val_loss: 4.7054 - val_auc_3: 0.5588 - val_recall_at_10: 0.2119 - val_ndcg_at_10: 0.1023 - val_mrr_at_10: 0.0695 - val_precision_at_10: 0.0212 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3332\n",
            "Epoch 45/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2548 - auc_3: 0.6201 - recall_at_10: 0.3163 - ndcg_at_10: 0.1680 - mrr_at_10: 0.1233 - precision_at_10: 0.0316 - regularization_loss: 0.0000e+00 - loss_batch: 4.2525 - val_loss: 4.7418 - val_auc_3: 0.5514 - val_recall_at_10: 0.2095 - val_ndcg_at_10: 0.1004 - val_mrr_at_10: 0.0677 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.6533\n",
            "Epoch 46/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2546 - auc_3: 0.6177 - recall_at_10: 0.3115 - ndcg_at_10: 0.1668 - mrr_at_10: 0.1232 - precision_at_10: 0.0312 - regularization_loss: 0.0000e+00 - loss_batch: 4.2522 - val_loss: 4.7258 - val_auc_3: 0.5490 - val_recall_at_10: 0.2081 - val_ndcg_at_10: 0.1009 - val_mrr_at_10: 0.0689 - val_precision_at_10: 0.0208 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1194\n",
            "Epoch 47/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2665 - auc_3: 0.6147 - recall_at_10: 0.3115 - ndcg_at_10: 0.1662 - mrr_at_10: 0.1225 - precision_at_10: 0.0311 - regularization_loss: 0.0000e+00 - loss_batch: 4.2641 - val_loss: 4.7134 - val_auc_3: 0.5533 - val_recall_at_10: 0.2053 - val_ndcg_at_10: 0.0989 - val_mrr_at_10: 0.0672 - val_precision_at_10: 0.0205 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5592\n",
            "Epoch 48/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2746 - auc_3: 0.6131 - recall_at_10: 0.3140 - ndcg_at_10: 0.1691 - mrr_at_10: 0.1254 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 4.2724 - val_loss: 4.6589 - val_auc_3: 0.5570 - val_recall_at_10: 0.2130 - val_ndcg_at_10: 0.1011 - val_mrr_at_10: 0.0677 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 6.9639\n",
            "Epoch 49/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2704 - auc_3: 0.6167 - recall_at_10: 0.3063 - ndcg_at_10: 0.1618 - mrr_at_10: 0.1183 - precision_at_10: 0.0306 - regularization_loss: 0.0000e+00 - loss_batch: 4.2681 - val_loss: 4.7305 - val_auc_3: 0.5501 - val_recall_at_10: 0.2041 - val_ndcg_at_10: 0.0998 - val_mrr_at_10: 0.0685 - val_precision_at_10: 0.0204 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3020\n",
            "Epoch 50/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2546 - auc_3: 0.6146 - recall_at_10: 0.3116 - ndcg_at_10: 0.1670 - mrr_at_10: 0.1234 - precision_at_10: 0.0312 - regularization_loss: 0.0000e+00 - loss_batch: 4.2524 - val_loss: 4.6861 - val_auc_3: 0.5574 - val_recall_at_10: 0.2073 - val_ndcg_at_10: 0.0992 - val_mrr_at_10: 0.0669 - val_precision_at_10: 0.0207 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2.fit(train, validation_data=valid, batch_size=128, epochs=100, initial_epoch=len(model_v2.history.epoch))"
      ],
      "metadata": {
        "id": "k2jAg5pPikqu",
        "outputId": "e3487d3e-05e7-4c80-e065-edde5b50c267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k2jAg5pPikqu",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2580 - auc_3: 0.6103 - recall_at_10: 0.3128 - ndcg_at_10: 0.1681 - mrr_at_10: 0.1244 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2557 - val_loss: 4.7088 - val_auc_3: 0.5440 - val_recall_at_10: 0.2060 - val_ndcg_at_10: 0.1006 - val_mrr_at_10: 0.0691 - val_precision_at_10: 0.0206 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1694\n",
            "Epoch 53/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2522 - auc_3: 0.6070 - recall_at_10: 0.3133 - ndcg_at_10: 0.1681 - mrr_at_10: 0.1243 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2500 - val_loss: 4.6901 - val_auc_3: 0.5508 - val_recall_at_10: 0.2080 - val_ndcg_at_10: 0.1003 - val_mrr_at_10: 0.0682 - val_precision_at_10: 0.0208 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1030\n",
            "Epoch 54/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2546 - auc_3: 0.6058 - recall_at_10: 0.3189 - ndcg_at_10: 0.1695 - mrr_at_10: 0.1244 - precision_at_10: 0.0319 - regularization_loss: 0.0000e+00 - loss_batch: 4.2523 - val_loss: 4.7571 - val_auc_3: 0.5504 - val_recall_at_10: 0.2171 - val_ndcg_at_10: 0.1041 - val_mrr_at_10: 0.0703 - val_precision_at_10: 0.0217 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5924\n",
            "Epoch 55/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2529 - auc_3: 0.6046 - recall_at_10: 0.3162 - ndcg_at_10: 0.1686 - mrr_at_10: 0.1241 - precision_at_10: 0.0316 - regularization_loss: 0.0000e+00 - loss_batch: 4.2506 - val_loss: 4.7317 - val_auc_3: 0.5508 - val_recall_at_10: 0.2085 - val_ndcg_at_10: 0.0990 - val_mrr_at_10: 0.0663 - val_precision_at_10: 0.0209 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5118\n",
            "Epoch 56/100\n",
            "549/549 [==============================] - 13s 21ms/step - loss: 4.2551 - auc_3: 0.6027 - recall_at_10: 0.3174 - ndcg_at_10: 0.1700 - mrr_at_10: 0.1256 - precision_at_10: 0.0317 - regularization_loss: 0.0000e+00 - loss_batch: 4.2529 - val_loss: 4.7012 - val_auc_3: 0.5604 - val_recall_at_10: 0.2098 - val_ndcg_at_10: 0.1004 - val_mrr_at_10: 0.0678 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4419\n",
            "Epoch 57/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2503 - auc_3: 0.6041 - recall_at_10: 0.3110 - ndcg_at_10: 0.1666 - mrr_at_10: 0.1231 - precision_at_10: 0.0311 - regularization_loss: 0.0000e+00 - loss_batch: 4.2480 - val_loss: 4.7034 - val_auc_3: 0.5489 - val_recall_at_10: 0.2078 - val_ndcg_at_10: 0.0997 - val_mrr_at_10: 0.0674 - val_precision_at_10: 0.0208 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4414\n",
            "Epoch 58/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3221 - auc_3: 0.5921 - recall_at_10: 0.2816 - ndcg_at_10: 0.1465 - mrr_at_10: 0.1060 - precision_at_10: 0.0282 - regularization_loss: 0.0000e+00 - loss_batch: 4.3197 - val_loss: 4.7549 - val_auc_3: 0.5497 - val_recall_at_10: 0.2087 - val_ndcg_at_10: 0.1001 - val_mrr_at_10: 0.0677 - val_precision_at_10: 0.0209 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4286\n",
            "Epoch 59/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2588 - auc_3: 0.6018 - recall_at_10: 0.3140 - ndcg_at_10: 0.1673 - mrr_at_10: 0.1231 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 4.2565 - val_loss: 4.7146 - val_auc_3: 0.5518 - val_recall_at_10: 0.2025 - val_ndcg_at_10: 0.0975 - val_mrr_at_10: 0.0661 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2417\n",
            "Epoch 60/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2539 - auc_3: 0.5973 - recall_at_10: 0.3131 - ndcg_at_10: 0.1667 - mrr_at_10: 0.1226 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2517 - val_loss: 4.7609 - val_auc_3: 0.5497 - val_recall_at_10: 0.2013 - val_ndcg_at_10: 0.0971 - val_mrr_at_10: 0.0660 - val_precision_at_10: 0.0201 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3942\n",
            "Epoch 61/100\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.2501 - auc_3: 0.5965 - recall_at_10: 0.3173 - ndcg_at_10: 0.1696 - mrr_at_10: 0.1252 - precision_at_10: 0.0317 - regularization_loss: 0.0000e+00 - loss_batch: 4.2478 - val_loss: 4.7291 - val_auc_3: 0.5505 - val_recall_at_10: 0.2099 - val_ndcg_at_10: 0.1007 - val_mrr_at_10: 0.0682 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2385\n",
            "Epoch 62/100\n",
            "549/549 [==============================] - 16s 27ms/step - loss: 4.2494 - auc_3: 0.5955 - recall_at_10: 0.3133 - ndcg_at_10: 0.1671 - mrr_at_10: 0.1230 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2471 - val_loss: 4.6824 - val_auc_3: 0.5486 - val_recall_at_10: 0.2187 - val_ndcg_at_10: 0.1060 - val_mrr_at_10: 0.0723 - val_precision_at_10: 0.0219 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1675\n",
            "Epoch 63/100\n",
            "549/549 [==============================] - 18s 31ms/step - loss: 4.2505 - auc_3: 0.5927 - recall_at_10: 0.3170 - ndcg_at_10: 0.1703 - mrr_at_10: 0.1260 - precision_at_10: 0.0317 - regularization_loss: 0.0000e+00 - loss_batch: 4.2481 - val_loss: 4.6957 - val_auc_3: 0.5433 - val_recall_at_10: 0.2058 - val_ndcg_at_10: 0.0993 - val_mrr_at_10: 0.0675 - val_precision_at_10: 0.0206 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3170\n",
            "Epoch 64/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2481 - auc_3: 0.5916 - recall_at_10: 0.3198 - ndcg_at_10: 0.1707 - mrr_at_10: 0.1259 - precision_at_10: 0.0320 - regularization_loss: 0.0000e+00 - loss_batch: 4.2458 - val_loss: 4.7127 - val_auc_3: 0.5474 - val_recall_at_10: 0.2109 - val_ndcg_at_10: 0.1023 - val_mrr_at_10: 0.0698 - val_precision_at_10: 0.0211 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4685\n",
            "Epoch 65/100\n",
            "549/549 [==============================] - 13s 24ms/step - loss: 4.2682 - auc_3: 0.5898 - recall_at_10: 0.3146 - ndcg_at_10: 0.1693 - mrr_at_10: 0.1256 - precision_at_10: 0.0315 - regularization_loss: 0.0000e+00 - loss_batch: 4.2659 - val_loss: 4.7586 - val_auc_3: 0.5514 - val_recall_at_10: 0.2092 - val_ndcg_at_10: 0.1009 - val_mrr_at_10: 0.0686 - val_precision_at_10: 0.0209 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3734\n",
            "Epoch 66/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2482 - auc_3: 0.5914 - recall_at_10: 0.3165 - ndcg_at_10: 0.1692 - mrr_at_10: 0.1248 - precision_at_10: 0.0316 - regularization_loss: 0.0000e+00 - loss_batch: 4.2460 - val_loss: 4.6975 - val_auc_3: 0.5505 - val_recall_at_10: 0.2105 - val_ndcg_at_10: 0.1014 - val_mrr_at_10: 0.0687 - val_precision_at_10: 0.0211 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0219\n",
            "Epoch 67/100\n",
            "549/549 [==============================] - 13s 21ms/step - loss: 4.2450 - auc_3: 0.5877 - recall_at_10: 0.3164 - ndcg_at_10: 0.1705 - mrr_at_10: 0.1265 - precision_at_10: 0.0316 - regularization_loss: 0.0000e+00 - loss_batch: 4.2426 - val_loss: 4.7819 - val_auc_3: 0.5482 - val_recall_at_10: 0.2016 - val_ndcg_at_10: 0.0969 - val_mrr_at_10: 0.0656 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3406\n",
            "Epoch 68/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2441 - auc_3: 0.5837 - recall_at_10: 0.3215 - ndcg_at_10: 0.1712 - mrr_at_10: 0.1258 - precision_at_10: 0.0322 - regularization_loss: 0.0000e+00 - loss_batch: 4.2418 - val_loss: 4.7526 - val_auc_3: 0.5447 - val_recall_at_10: 0.1979 - val_ndcg_at_10: 0.0945 - val_mrr_at_10: 0.0636 - val_precision_at_10: 0.0198 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2475\n",
            "Epoch 69/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2671 - auc_3: 0.5791 - recall_at_10: 0.3187 - ndcg_at_10: 0.1697 - mrr_at_10: 0.1249 - precision_at_10: 0.0319 - regularization_loss: 0.0000e+00 - loss_batch: 4.2648 - val_loss: 4.7218 - val_auc_3: 0.5440 - val_recall_at_10: 0.2256 - val_ndcg_at_10: 0.1091 - val_mrr_at_10: 0.0743 - val_precision_at_10: 0.0226 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.7399\n",
            "Epoch 70/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2510 - auc_3: 0.5790 - recall_at_10: 0.3153 - ndcg_at_10: 0.1690 - mrr_at_10: 0.1250 - precision_at_10: 0.0315 - regularization_loss: 0.0000e+00 - loss_batch: 4.2487 - val_loss: 4.7601 - val_auc_3: 0.5383 - val_recall_at_10: 0.2098 - val_ndcg_at_10: 0.1013 - val_mrr_at_10: 0.0689 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4071\n",
            "Epoch 71/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2435 - auc_3: 0.5792 - recall_at_10: 0.3189 - ndcg_at_10: 0.1707 - mrr_at_10: 0.1261 - precision_at_10: 0.0319 - regularization_loss: 0.0000e+00 - loss_batch: 4.2413 - val_loss: 4.8003 - val_auc_3: 0.5400 - val_recall_at_10: 0.1892 - val_ndcg_at_10: 0.0900 - val_mrr_at_10: 0.0604 - val_precision_at_10: 0.0189 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3711\n",
            "Epoch 72/100\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.2473 - auc_3: 0.5766 - recall_at_10: 0.3156 - ndcg_at_10: 0.1663 - mrr_at_10: 0.1214 - precision_at_10: 0.0316 - regularization_loss: 0.0000e+00 - loss_batch: 4.2450 - val_loss: 4.7030 - val_auc_3: 0.5416 - val_recall_at_10: 0.2136 - val_ndcg_at_10: 0.1025 - val_mrr_at_10: 0.0694 - val_precision_at_10: 0.0214 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2268\n",
            "Epoch 73/100\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2409 - auc_3: 0.5745 - recall_at_10: 0.3215 - ndcg_at_10: 0.1725 - mrr_at_10: 0.1274 - precision_at_10: 0.0322 - regularization_loss: 0.0000e+00 - loss_batch: 4.2385 - val_loss: 4.7540 - val_auc_3: 0.5388 - val_recall_at_10: 0.2163 - val_ndcg_at_10: 0.1039 - val_mrr_at_10: 0.0703 - val_precision_at_10: 0.0216 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5286\n",
            "Epoch 74/100\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2463 - auc_3: 0.5732 - recall_at_10: 0.3180 - ndcg_at_10: 0.1697 - mrr_at_10: 0.1250 - precision_at_10: 0.0318 - regularization_loss: 0.0000e+00 - loss_batch: 4.2440 - val_loss: 4.7261 - val_auc_3: 0.5382 - val_recall_at_10: 0.2101 - val_ndcg_at_10: 0.1017 - val_mrr_at_10: 0.0693 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3765\n",
            "Epoch 75/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2407 - auc_3: 0.5720 - recall_at_10: 0.3179 - ndcg_at_10: 0.1710 - mrr_at_10: 0.1267 - precision_at_10: 0.0318 - regularization_loss: 0.0000e+00 - loss_batch: 4.2384 - val_loss: 4.7704 - val_auc_3: 0.5376 - val_recall_at_10: 0.1989 - val_ndcg_at_10: 0.0960 - val_mrr_at_10: 0.0652 - val_precision_at_10: 0.0199 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5217\n",
            "Epoch 76/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.5741 - auc_3: 0.5682 - recall_at_10: 0.2460 - ndcg_at_10: 0.1279 - mrr_at_10: 0.0925 - precision_at_10: 0.0246 - regularization_loss: 0.0000e+00 - loss_batch: 4.5722 - val_loss: 4.8544 - val_auc_3: 0.5606 - val_recall_at_10: 0.1658 - val_ndcg_at_10: 0.0783 - val_mrr_at_10: 0.0522 - val_precision_at_10: 0.0166 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9653\n",
            "Epoch 77/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.4501 - auc_3: 0.5707 - recall_at_10: 0.2220 - ndcg_at_10: 0.1093 - mrr_at_10: 0.0756 - precision_at_10: 0.0222 - regularization_loss: 0.0000e+00 - loss_batch: 4.4474 - val_loss: 4.7195 - val_auc_3: 0.5546 - val_recall_at_10: 0.1970 - val_ndcg_at_10: 0.0937 - val_mrr_at_10: 0.0630 - val_precision_at_10: 0.0197 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9312\n",
            "Epoch 78/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3554 - auc_3: 0.5806 - recall_at_10: 0.2732 - ndcg_at_10: 0.1404 - mrr_at_10: 0.1005 - precision_at_10: 0.0273 - regularization_loss: 0.0000e+00 - loss_batch: 4.3529 - val_loss: 4.6791 - val_auc_3: 0.5521 - val_recall_at_10: 0.2020 - val_ndcg_at_10: 0.0968 - val_mrr_at_10: 0.0655 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3582\n",
            "Epoch 79/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3185 - auc_3: 0.5841 - recall_at_10: 0.2911 - ndcg_at_10: 0.1519 - mrr_at_10: 0.1099 - precision_at_10: 0.0291 - regularization_loss: 0.0000e+00 - loss_batch: 4.3160 - val_loss: 4.8458 - val_auc_3: 0.5521 - val_recall_at_10: 0.1898 - val_ndcg_at_10: 0.0920 - val_mrr_at_10: 0.0627 - val_precision_at_10: 0.0190 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2562\n",
            "Epoch 80/100\n",
            "549/549 [==============================] - 13s 24ms/step - loss: 4.3538 - auc_3: 0.5734 - recall_at_10: 0.2724 - ndcg_at_10: 0.1384 - mrr_at_10: 0.0983 - precision_at_10: 0.0272 - regularization_loss: 0.0000e+00 - loss_batch: 4.3514 - val_loss: 4.7099 - val_auc_3: 0.5543 - val_recall_at_10: 0.2022 - val_ndcg_at_10: 0.0993 - val_mrr_at_10: 0.0685 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2649\n",
            "Epoch 81/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.3155 - auc_3: 0.5597 - recall_at_10: 0.2940 - ndcg_at_10: 0.1531 - mrr_at_10: 0.1107 - precision_at_10: 0.0294 - regularization_loss: 0.0000e+00 - loss_batch: 4.3131 - val_loss: 4.6852 - val_auc_3: 0.5518 - val_recall_at_10: 0.1995 - val_ndcg_at_10: 0.0971 - val_mrr_at_10: 0.0665 - val_precision_at_10: 0.0200 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9719\n",
            "Epoch 82/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3067 - auc_3: 0.5603 - recall_at_10: 0.2928 - ndcg_at_10: 0.1535 - mrr_at_10: 0.1115 - precision_at_10: 0.0293 - regularization_loss: 0.0000e+00 - loss_batch: 4.3043 - val_loss: 4.6709 - val_auc_3: 0.5591 - val_recall_at_10: 0.2124 - val_ndcg_at_10: 0.1033 - val_mrr_at_10: 0.0707 - val_precision_at_10: 0.0212 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0552\n",
            "Epoch 83/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2994 - auc_3: 0.5717 - recall_at_10: 0.2982 - ndcg_at_10: 0.1569 - mrr_at_10: 0.1143 - precision_at_10: 0.0298 - regularization_loss: 0.0000e+00 - loss_batch: 4.2969 - val_loss: 4.7097 - val_auc_3: 0.5540 - val_recall_at_10: 0.2096 - val_ndcg_at_10: 0.1022 - val_mrr_at_10: 0.0701 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1240\n",
            "Epoch 84/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2917 - auc_3: 0.5836 - recall_at_10: 0.2980 - ndcg_at_10: 0.1566 - mrr_at_10: 0.1140 - precision_at_10: 0.0298 - regularization_loss: 0.0000e+00 - loss_batch: 4.2892 - val_loss: 4.7056 - val_auc_3: 0.5595 - val_recall_at_10: 0.2076 - val_ndcg_at_10: 0.1007 - val_mrr_at_10: 0.0688 - val_precision_at_10: 0.0208 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3201\n",
            "Epoch 85/100\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.2884 - auc_3: 0.5862 - recall_at_10: 0.3050 - ndcg_at_10: 0.1601 - mrr_at_10: 0.1165 - precision_at_10: 0.0305 - regularization_loss: 0.0000e+00 - loss_batch: 4.2860 - val_loss: 4.6692 - val_auc_3: 0.5524 - val_recall_at_10: 0.2173 - val_ndcg_at_10: 0.1054 - val_mrr_at_10: 0.0720 - val_precision_at_10: 0.0217 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0976\n",
            "Epoch 86/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2801 - auc_3: 0.5880 - recall_at_10: 0.3053 - ndcg_at_10: 0.1602 - mrr_at_10: 0.1165 - precision_at_10: 0.0305 - regularization_loss: 0.0000e+00 - loss_batch: 4.2776 - val_loss: 4.6821 - val_auc_3: 0.5522 - val_recall_at_10: 0.2077 - val_ndcg_at_10: 0.1008 - val_mrr_at_10: 0.0688 - val_precision_at_10: 0.0208 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0382\n",
            "Epoch 87/100\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2736 - auc_3: 0.5892 - recall_at_10: 0.3084 - ndcg_at_10: 0.1629 - mrr_at_10: 0.1191 - precision_at_10: 0.0308 - regularization_loss: 0.0000e+00 - loss_batch: 4.2712 - val_loss: 4.7336 - val_auc_3: 0.5474 - val_recall_at_10: 0.1989 - val_ndcg_at_10: 0.0981 - val_mrr_at_10: 0.0679 - val_precision_at_10: 0.0199 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.6445\n",
            "Epoch 88/100\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2700 - auc_3: 0.5852 - recall_at_10: 0.3120 - ndcg_at_10: 0.1651 - mrr_at_10: 0.1210 - precision_at_10: 0.0312 - regularization_loss: 0.0000e+00 - loss_batch: 4.2677 - val_loss: 4.6829 - val_auc_3: 0.5542 - val_recall_at_10: 0.2095 - val_ndcg_at_10: 0.1023 - val_mrr_at_10: 0.0702 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2823\n",
            "Epoch 89/100\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.2678 - auc_3: 0.5828 - recall_at_10: 0.3106 - ndcg_at_10: 0.1639 - mrr_at_10: 0.1197 - precision_at_10: 0.0311 - regularization_loss: 0.0000e+00 - loss_batch: 4.2654 - val_loss: 4.6888 - val_auc_3: 0.5550 - val_recall_at_10: 0.2127 - val_ndcg_at_10: 0.1033 - val_mrr_at_10: 0.0707 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3946\n",
            "Epoch 90/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2764 - auc_3: 0.5775 - recall_at_10: 0.3093 - ndcg_at_10: 0.1631 - mrr_at_10: 0.1191 - precision_at_10: 0.0309 - regularization_loss: 0.0000e+00 - loss_batch: 4.2739 - val_loss: 4.6529 - val_auc_3: 0.5564 - val_recall_at_10: 0.2152 - val_ndcg_at_10: 0.1039 - val_mrr_at_10: 0.0706 - val_precision_at_10: 0.0215 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2590\n",
            "Epoch 91/100\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.2618 - auc_3: 0.5855 - recall_at_10: 0.3098 - ndcg_at_10: 0.1640 - mrr_at_10: 0.1201 - precision_at_10: 0.0310 - regularization_loss: 0.0000e+00 - loss_batch: 4.2594 - val_loss: 4.6666 - val_auc_3: 0.5528 - val_recall_at_10: 0.2121 - val_ndcg_at_10: 0.1043 - val_mrr_at_10: 0.0720 - val_precision_at_10: 0.0212 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1676\n",
            "Epoch 92/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2606 - auc_3: 0.5851 - recall_at_10: 0.3142 - ndcg_at_10: 0.1667 - mrr_at_10: 0.1223 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 4.2583 - val_loss: 4.7415 - val_auc_3: 0.5576 - val_recall_at_10: 0.2129 - val_ndcg_at_10: 0.1036 - val_mrr_at_10: 0.0709 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2917\n",
            "Epoch 93/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3037 - auc_3: 0.5815 - recall_at_10: 0.3098 - ndcg_at_10: 0.1651 - mrr_at_10: 0.1215 - precision_at_10: 0.0310 - regularization_loss: 0.0000e+00 - loss_batch: 4.3019 - val_loss: 4.6833 - val_auc_3: 0.5295 - val_recall_at_10: 0.1876 - val_ndcg_at_10: 0.0895 - val_mrr_at_10: 0.0603 - val_precision_at_10: 0.0188 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8504\n",
            "Epoch 94/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3307 - auc_3: 0.5546 - recall_at_10: 0.2705 - ndcg_at_10: 0.1383 - mrr_at_10: 0.0987 - precision_at_10: 0.0271 - regularization_loss: 0.0000e+00 - loss_batch: 4.3280 - val_loss: 4.7401 - val_auc_3: 0.5341 - val_recall_at_10: 0.1973 - val_ndcg_at_10: 0.0956 - val_mrr_at_10: 0.0653 - val_precision_at_10: 0.0197 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1949\n",
            "Epoch 95/100\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.2940 - auc_3: 0.5551 - recall_at_10: 0.2971 - ndcg_at_10: 0.1565 - mrr_at_10: 0.1142 - precision_at_10: 0.0297 - regularization_loss: 0.0000e+00 - loss_batch: 4.2917 - val_loss: 4.7011 - val_auc_3: 0.5381 - val_recall_at_10: 0.2096 - val_ndcg_at_10: 0.1006 - val_mrr_at_10: 0.0680 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3238\n",
            "Epoch 96/100\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.2892 - auc_3: 0.5534 - recall_at_10: 0.3017 - ndcg_at_10: 0.1590 - mrr_at_10: 0.1161 - precision_at_10: 0.0302 - regularization_loss: 0.0000e+00 - loss_batch: 4.2869 - val_loss: 4.7466 - val_auc_3: 0.5398 - val_recall_at_10: 0.2070 - val_ndcg_at_10: 0.0993 - val_mrr_at_10: 0.0671 - val_precision_at_10: 0.0207 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3848\n",
            "Epoch 97/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2830 - auc_3: 0.5547 - recall_at_10: 0.3027 - ndcg_at_10: 0.1603 - mrr_at_10: 0.1174 - precision_at_10: 0.0303 - regularization_loss: 0.0000e+00 - loss_batch: 4.2805 - val_loss: 4.6868 - val_auc_3: 0.5389 - val_recall_at_10: 0.2099 - val_ndcg_at_10: 0.1030 - val_mrr_at_10: 0.0711 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3254\n",
            "Epoch 98/100\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.2692 - auc_3: 0.5604 - recall_at_10: 0.3110 - ndcg_at_10: 0.1647 - mrr_at_10: 0.1208 - precision_at_10: 0.0311 - regularization_loss: 0.0000e+00 - loss_batch: 4.2668 - val_loss: 4.7249 - val_auc_3: 0.5458 - val_recall_at_10: 0.2028 - val_ndcg_at_10: 0.0990 - val_mrr_at_10: 0.0679 - val_precision_at_10: 0.0203 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1181\n",
            "Epoch 99/100\n",
            "549/549 [==============================] - 15s 27ms/step - loss: 4.2603 - auc_3: 0.5619 - recall_at_10: 0.3131 - ndcg_at_10: 0.1654 - mrr_at_10: 0.1210 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 4.2579 - val_loss: 4.7201 - val_auc_3: 0.5472 - val_recall_at_10: 0.2040 - val_ndcg_at_10: 0.0980 - val_mrr_at_10: 0.0664 - val_precision_at_10: 0.0204 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2980\n",
            "Epoch 100/100\n",
            "549/549 [==============================] - 16s 27ms/step - loss: 4.2579 - auc_3: 0.5635 - recall_at_10: 0.3153 - ndcg_at_10: 0.1666 - mrr_at_10: 0.1217 - precision_at_10: 0.0315 - regularization_loss: 0.0000e+00 - loss_batch: 4.2555 - val_loss: 4.7405 - val_auc_3: 0.5483 - val_recall_at_10: 0.2009 - val_ndcg_at_10: 0.0972 - val_mrr_at_10: 0.0662 - val_precision_at_10: 0.0201 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d44502ab310>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v3"
      ],
      "metadata": {
        "id": "c-srs_yvsAZp"
      },
      "id": "c-srs_yvsAZp"
    },
    {
      "cell_type": "code",
      "source": [
        "model_v3 = build_towers(tower_dim=256)"
      ],
      "metadata": {
        "id": "Z-RQHGW2mKWc"
      },
      "id": "Z-RQHGW2mKWc",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                 run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10), tf.keras.metrics.AUC(), mm.MRRAt(10), mm.PrecisionAt(10)])\n",
        "model_v3.fit(train, validation_data=valid, batch_size=128, epochs=50)"
      ],
      "metadata": {
        "id": "6IFasdk5jRrP",
        "outputId": "ac4ca287-871c-485e-f6ad-9a6c164df830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6IFasdk5jRrP",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "549/549 [==============================] - 29s 43ms/step - loss: 4.7934 - auc_9: 0.5473 - recall_at_10: 0.0959 - ndcg_at_10: 0.0448 - mrr_at_10: 0.0297 - precision_at_10: 0.0096 - regularization_loss: 0.0000e+00 - loss_batch: 4.7909 - val_loss: 4.7574 - val_auc_9: 0.5705 - val_recall_at_10: 0.1465 - val_ndcg_at_10: 0.0679 - val_mrr_at_10: 0.0446 - val_precision_at_10: 0.0147 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7600\n",
            "Epoch 2/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.5831 - auc_9: 0.6291 - recall_at_10: 0.1819 - ndcg_at_10: 0.0869 - mrr_at_10: 0.0586 - precision_at_10: 0.0182 - regularization_loss: 0.0000e+00 - loss_batch: 4.5807 - val_loss: 4.6974 - val_auc_9: 0.5981 - val_recall_at_10: 0.1775 - val_ndcg_at_10: 0.0832 - val_mrr_at_10: 0.0552 - val_precision_at_10: 0.0178 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.6087\n",
            "Epoch 3/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.4773 - auc_9: 0.6481 - recall_at_10: 0.2246 - ndcg_at_10: 0.1093 - mrr_at_10: 0.0749 - precision_at_10: 0.0225 - regularization_loss: 0.0000e+00 - loss_batch: 4.4750 - val_loss: 4.6838 - val_auc_9: 0.6007 - val_recall_at_10: 0.1871 - val_ndcg_at_10: 0.0883 - val_mrr_at_10: 0.0588 - val_precision_at_10: 0.0187 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.6618\n",
            "Epoch 4/50\n",
            "549/549 [==============================] - 15s 25ms/step - loss: 4.4504 - auc_9: 0.6432 - recall_at_10: 0.2349 - ndcg_at_10: 0.1151 - mrr_at_10: 0.0794 - precision_at_10: 0.0235 - regularization_loss: 0.0000e+00 - loss_batch: 4.4484 - val_loss: 4.6729 - val_auc_9: 0.6069 - val_recall_at_10: 0.1902 - val_ndcg_at_10: 0.0904 - val_mrr_at_10: 0.0607 - val_precision_at_10: 0.0190 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7073\n",
            "Epoch 5/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.4349 - auc_9: 0.6451 - recall_at_10: 0.2424 - ndcg_at_10: 0.1194 - mrr_at_10: 0.0826 - precision_at_10: 0.0242 - regularization_loss: 0.0000e+00 - loss_batch: 4.4326 - val_loss: 4.7125 - val_auc_9: 0.5812 - val_recall_at_10: 0.1857 - val_ndcg_at_10: 0.0889 - val_mrr_at_10: 0.0601 - val_precision_at_10: 0.0186 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1582\n",
            "Epoch 6/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.4224 - auc_9: 0.6401 - recall_at_10: 0.2478 - ndcg_at_10: 0.1224 - mrr_at_10: 0.0849 - precision_at_10: 0.0248 - regularization_loss: 0.0000e+00 - loss_batch: 4.4201 - val_loss: 4.6649 - val_auc_9: 0.5995 - val_recall_at_10: 0.1933 - val_ndcg_at_10: 0.0922 - val_mrr_at_10: 0.0621 - val_precision_at_10: 0.0193 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0352\n",
            "Epoch 7/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.4144 - auc_9: 0.6364 - recall_at_10: 0.2525 - ndcg_at_10: 0.1268 - mrr_at_10: 0.0891 - precision_at_10: 0.0253 - regularization_loss: 0.0000e+00 - loss_batch: 4.4120 - val_loss: 4.6795 - val_auc_9: 0.5929 - val_recall_at_10: 0.1934 - val_ndcg_at_10: 0.0934 - val_mrr_at_10: 0.0636 - val_precision_at_10: 0.0193 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9146\n",
            "Epoch 8/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.4049 - auc_9: 0.6323 - recall_at_10: 0.2574 - ndcg_at_10: 0.1299 - mrr_at_10: 0.0917 - precision_at_10: 0.0257 - regularization_loss: 0.0000e+00 - loss_batch: 4.4026 - val_loss: 4.6659 - val_auc_9: 0.6084 - val_recall_at_10: 0.2107 - val_ndcg_at_10: 0.1004 - val_mrr_at_10: 0.0675 - val_precision_at_10: 0.0211 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1857\n",
            "Epoch 9/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.4298 - auc_9: 0.6097 - recall_at_10: 0.2504 - ndcg_at_10: 0.1259 - mrr_at_10: 0.0886 - precision_at_10: 0.0250 - regularization_loss: 0.0000e+00 - loss_batch: 4.4275 - val_loss: 4.6457 - val_auc_9: 0.5687 - val_recall_at_10: 0.2036 - val_ndcg_at_10: 0.0985 - val_mrr_at_10: 0.0670 - val_precision_at_10: 0.0204 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8624\n",
            "Epoch 10/50\n",
            "549/549 [==============================] - 13s 24ms/step - loss: 4.3910 - auc_9: 0.6009 - recall_at_10: 0.2591 - ndcg_at_10: 0.1307 - mrr_at_10: 0.0923 - precision_at_10: 0.0259 - regularization_loss: 0.0000e+00 - loss_batch: 4.3888 - val_loss: 4.6275 - val_auc_9: 0.5588 - val_recall_at_10: 0.2005 - val_ndcg_at_10: 0.0962 - val_mrr_at_10: 0.0651 - val_precision_at_10: 0.0201 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8826\n",
            "Epoch 11/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.3818 - auc_9: 0.5977 - recall_at_10: 0.2622 - ndcg_at_10: 0.1317 - mrr_at_10: 0.0926 - precision_at_10: 0.0262 - regularization_loss: 0.0000e+00 - loss_batch: 4.3795 - val_loss: 4.6952 - val_auc_9: 0.5698 - val_recall_at_10: 0.2062 - val_ndcg_at_10: 0.0987 - val_mrr_at_10: 0.0666 - val_precision_at_10: 0.0206 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 10.0709\n",
            "Epoch 12/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3768 - auc_9: 0.5943 - recall_at_10: 0.2637 - ndcg_at_10: 0.1342 - mrr_at_10: 0.0953 - precision_at_10: 0.0264 - regularization_loss: 0.0000e+00 - loss_batch: 4.3747 - val_loss: 4.6917 - val_auc_9: 0.5559 - val_recall_at_10: 0.1904 - val_ndcg_at_10: 0.0907 - val_mrr_at_10: 0.0610 - val_precision_at_10: 0.0190 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3081\n",
            "Epoch 13/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.3688 - auc_9: 0.5917 - recall_at_10: 0.2672 - ndcg_at_10: 0.1353 - mrr_at_10: 0.0957 - precision_at_10: 0.0267 - regularization_loss: 0.0000e+00 - loss_batch: 4.3666 - val_loss: 4.6230 - val_auc_9: 0.5599 - val_recall_at_10: 0.2020 - val_ndcg_at_10: 0.0967 - val_mrr_at_10: 0.0652 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0597\n",
            "Epoch 14/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3746 - auc_9: 0.5870 - recall_at_10: 0.2696 - ndcg_at_10: 0.1372 - mrr_at_10: 0.0975 - precision_at_10: 0.0270 - regularization_loss: 0.0000e+00 - loss_batch: 4.3722 - val_loss: 4.7159 - val_auc_9: 0.5476 - val_recall_at_10: 0.1941 - val_ndcg_at_10: 0.0940 - val_mrr_at_10: 0.0640 - val_precision_at_10: 0.0194 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4337\n",
            "Epoch 15/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.3692 - auc_9: 0.5857 - recall_at_10: 0.2693 - ndcg_at_10: 0.1375 - mrr_at_10: 0.0979 - precision_at_10: 0.0269 - regularization_loss: 0.0000e+00 - loss_batch: 4.3669 - val_loss: 4.6954 - val_auc_9: 0.5481 - val_recall_at_10: 0.1942 - val_ndcg_at_10: 0.0937 - val_mrr_at_10: 0.0638 - val_precision_at_10: 0.0194 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1169\n",
            "Epoch 16/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3531 - auc_9: 0.5853 - recall_at_10: 0.2742 - ndcg_at_10: 0.1399 - mrr_at_10: 0.0996 - precision_at_10: 0.0274 - regularization_loss: 0.0000e+00 - loss_batch: 4.3509 - val_loss: 4.6993 - val_auc_9: 0.5461 - val_recall_at_10: 0.1947 - val_ndcg_at_10: 0.0947 - val_mrr_at_10: 0.0649 - val_precision_at_10: 0.0195 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3958\n",
            "Epoch 17/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.3495 - auc_9: 0.5806 - recall_at_10: 0.2752 - ndcg_at_10: 0.1409 - mrr_at_10: 0.1006 - precision_at_10: 0.0275 - regularization_loss: 0.0000e+00 - loss_batch: 4.3471 - val_loss: 4.7115 - val_auc_9: 0.5434 - val_recall_at_10: 0.1985 - val_ndcg_at_10: 0.0954 - val_mrr_at_10: 0.0646 - val_precision_at_10: 0.0198 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3682\n",
            "Epoch 18/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.3688 - auc_9: 0.5717 - recall_at_10: 0.2736 - ndcg_at_10: 0.1403 - mrr_at_10: 0.1003 - precision_at_10: 0.0274 - regularization_loss: 0.0000e+00 - loss_batch: 4.3664 - val_loss: 4.6962 - val_auc_9: 0.5404 - val_recall_at_10: 0.1946 - val_ndcg_at_10: 0.0952 - val_mrr_at_10: 0.0654 - val_precision_at_10: 0.0195 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0594\n",
            "Epoch 19/50\n",
            "549/549 [==============================] - 13s 21ms/step - loss: 4.4280 - auc_9: 0.5667 - recall_at_10: 0.2648 - ndcg_at_10: 0.1345 - mrr_at_10: 0.0954 - precision_at_10: 0.0265 - regularization_loss: 0.0000e+00 - loss_batch: 4.4255 - val_loss: 4.7305 - val_auc_9: 0.5476 - val_recall_at_10: 0.1946 - val_ndcg_at_10: 0.0925 - val_mrr_at_10: 0.0620 - val_precision_at_10: 0.0195 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1449\n",
            "Epoch 20/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.3928 - auc_9: 0.5860 - recall_at_10: 0.2576 - ndcg_at_10: 0.1302 - mrr_at_10: 0.0920 - precision_at_10: 0.0258 - regularization_loss: 0.0000e+00 - loss_batch: 4.3905 - val_loss: 4.6915 - val_auc_9: 0.5588 - val_recall_at_10: 0.1958 - val_ndcg_at_10: 0.0952 - val_mrr_at_10: 0.0653 - val_precision_at_10: 0.0196 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1224\n",
            "Epoch 21/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3887 - auc_9: 0.5880 - recall_at_10: 0.2610 - ndcg_at_10: 0.1325 - mrr_at_10: 0.0940 - precision_at_10: 0.0261 - regularization_loss: 0.0000e+00 - loss_batch: 4.3863 - val_loss: 4.6944 - val_auc_9: 0.5637 - val_recall_at_10: 0.2053 - val_ndcg_at_10: 0.0995 - val_mrr_at_10: 0.0680 - val_precision_at_10: 0.0205 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0510\n",
            "Epoch 22/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.3578 - auc_9: 0.6019 - recall_at_10: 0.2727 - ndcg_at_10: 0.1392 - mrr_at_10: 0.0991 - precision_at_10: 0.0273 - regularization_loss: 0.0000e+00 - loss_batch: 4.3555 - val_loss: 4.7382 - val_auc_9: 0.5624 - val_recall_at_10: 0.1999 - val_ndcg_at_10: 0.0952 - val_mrr_at_10: 0.0638 - val_precision_at_10: 0.0200 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3602\n",
            "Epoch 23/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.3456 - auc_9: 0.5982 - recall_at_10: 0.2821 - ndcg_at_10: 0.1452 - mrr_at_10: 0.1041 - precision_at_10: 0.0282 - regularization_loss: 0.0000e+00 - loss_batch: 4.3433 - val_loss: 4.6879 - val_auc_9: 0.5590 - val_recall_at_10: 0.2076 - val_ndcg_at_10: 0.1018 - val_mrr_at_10: 0.0701 - val_precision_at_10: 0.0208 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2398\n",
            "Epoch 24/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.3376 - auc_9: 0.5864 - recall_at_10: 0.2813 - ndcg_at_10: 0.1448 - mrr_at_10: 0.1038 - precision_at_10: 0.0281 - regularization_loss: 0.0000e+00 - loss_batch: 4.3353 - val_loss: 4.7170 - val_auc_9: 0.5530 - val_recall_at_10: 0.2048 - val_ndcg_at_10: 0.0997 - val_mrr_at_10: 0.0683 - val_precision_at_10: 0.0205 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3047\n",
            "Epoch 25/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3398 - auc_9: 0.5798 - recall_at_10: 0.2801 - ndcg_at_10: 0.1442 - mrr_at_10: 0.1034 - precision_at_10: 0.0280 - regularization_loss: 0.0000e+00 - loss_batch: 4.3374 - val_loss: 4.6841 - val_auc_9: 0.5566 - val_recall_at_10: 0.2094 - val_ndcg_at_10: 0.1003 - val_mrr_at_10: 0.0677 - val_precision_at_10: 0.0209 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5224\n",
            "Epoch 26/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3592 - auc_9: 0.5686 - recall_at_10: 0.2817 - ndcg_at_10: 0.1460 - mrr_at_10: 0.1053 - precision_at_10: 0.0282 - regularization_loss: 0.0000e+00 - loss_batch: 4.3569 - val_loss: 4.7028 - val_auc_9: 0.5482 - val_recall_at_10: 0.2056 - val_ndcg_at_10: 0.0994 - val_mrr_at_10: 0.0677 - val_precision_at_10: 0.0206 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4586\n",
            "Epoch 27/50\n",
            "549/549 [==============================] - 13s 23ms/step - loss: 4.3384 - auc_9: 0.5663 - recall_at_10: 0.2772 - ndcg_at_10: 0.1431 - mrr_at_10: 0.1028 - precision_at_10: 0.0277 - regularization_loss: 0.0000e+00 - loss_batch: 4.3361 - val_loss: 4.6495 - val_auc_9: 0.5432 - val_recall_at_10: 0.2157 - val_ndcg_at_10: 0.1057 - val_mrr_at_10: 0.0728 - val_precision_at_10: 0.0216 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1286\n",
            "Epoch 28/50\n",
            "549/549 [==============================] - 13s 24ms/step - loss: 4.3296 - auc_9: 0.5648 - recall_at_10: 0.2848 - ndcg_at_10: 0.1475 - mrr_at_10: 0.1061 - precision_at_10: 0.0285 - regularization_loss: 0.0000e+00 - loss_batch: 4.3273 - val_loss: 4.6759 - val_auc_9: 0.5463 - val_recall_at_10: 0.2130 - val_ndcg_at_10: 0.1042 - val_mrr_at_10: 0.0716 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.7064\n",
            "Epoch 29/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3281 - auc_9: 0.5641 - recall_at_10: 0.2855 - ndcg_at_10: 0.1477 - mrr_at_10: 0.1063 - precision_at_10: 0.0286 - regularization_loss: 0.0000e+00 - loss_batch: 4.3258 - val_loss: 4.6560 - val_auc_9: 0.5410 - val_recall_at_10: 0.2096 - val_ndcg_at_10: 0.1029 - val_mrr_at_10: 0.0710 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3458\n",
            "Epoch 30/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.3322 - auc_9: 0.5600 - recall_at_10: 0.2844 - ndcg_at_10: 0.1471 - mrr_at_10: 0.1058 - precision_at_10: 0.0284 - regularization_loss: 0.0000e+00 - loss_batch: 4.3298 - val_loss: 4.6724 - val_auc_9: 0.5394 - val_recall_at_10: 0.2097 - val_ndcg_at_10: 0.1024 - val_mrr_at_10: 0.0702 - val_precision_at_10: 0.0210 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5018\n",
            "Epoch 31/50\n",
            "549/549 [==============================] - 14s 23ms/step - loss: 4.3232 - auc_9: 0.5605 - recall_at_10: 0.2861 - ndcg_at_10: 0.1479 - mrr_at_10: 0.1065 - precision_at_10: 0.0286 - regularization_loss: 0.0000e+00 - loss_batch: 4.3210 - val_loss: 4.6903 - val_auc_9: 0.5404 - val_recall_at_10: 0.2071 - val_ndcg_at_10: 0.0998 - val_mrr_at_10: 0.0678 - val_precision_at_10: 0.0207 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3267\n",
            "Epoch 32/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3233 - auc_9: 0.5600 - recall_at_10: 0.2874 - ndcg_at_10: 0.1481 - mrr_at_10: 0.1063 - precision_at_10: 0.0287 - regularization_loss: 0.0000e+00 - loss_batch: 4.3211 - val_loss: 4.6926 - val_auc_9: 0.5410 - val_recall_at_10: 0.2060 - val_ndcg_at_10: 0.1004 - val_mrr_at_10: 0.0688 - val_precision_at_10: 0.0206 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4012\n",
            "Epoch 33/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3307 - auc_9: 0.5562 - recall_at_10: 0.2854 - ndcg_at_10: 0.1480 - mrr_at_10: 0.1068 - precision_at_10: 0.0285 - regularization_loss: 0.0000e+00 - loss_batch: 4.3284 - val_loss: 4.6954 - val_auc_9: 0.5323 - val_recall_at_10: 0.2022 - val_ndcg_at_10: 0.0976 - val_mrr_at_10: 0.0664 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3822\n",
            "Epoch 34/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.3225 - auc_9: 0.5535 - recall_at_10: 0.2887 - ndcg_at_10: 0.1489 - mrr_at_10: 0.1070 - precision_at_10: 0.0289 - regularization_loss: 0.0000e+00 - loss_batch: 4.3201 - val_loss: 4.6675 - val_auc_9: 0.5381 - val_recall_at_10: 0.2094 - val_ndcg_at_10: 0.1013 - val_mrr_at_10: 0.0690 - val_precision_at_10: 0.0209 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2595\n",
            "Epoch 35/50\n",
            "549/549 [==============================] - 12s 20ms/step - loss: 4.3178 - auc_9: 0.5559 - recall_at_10: 0.2912 - ndcg_at_10: 0.1509 - mrr_at_10: 0.1088 - precision_at_10: 0.0291 - regularization_loss: 0.0000e+00 - loss_batch: 4.3154 - val_loss: 4.6683 - val_auc_9: 0.5331 - val_recall_at_10: 0.2129 - val_ndcg_at_10: 0.1040 - val_mrr_at_10: 0.0714 - val_precision_at_10: 0.0213 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2783\n",
            "Epoch 36/50\n",
            "549/549 [==============================] - 15s 25ms/step - loss: 4.4480 - auc_9: 0.5485 - recall_at_10: 0.2864 - ndcg_at_10: 0.1476 - mrr_at_10: 0.1059 - precision_at_10: 0.0286 - regularization_loss: 0.0000e+00 - loss_batch: 4.4464 - val_loss: 4.7887 - val_auc_9: 0.5169 - val_recall_at_10: 0.1576 - val_ndcg_at_10: 0.0729 - val_mrr_at_10: 0.0477 - val_precision_at_10: 0.0158 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2250\n",
            "Epoch 37/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.4950 - auc_9: 0.5259 - recall_at_10: 0.1945 - ndcg_at_10: 0.0933 - mrr_at_10: 0.0631 - precision_at_10: 0.0195 - regularization_loss: 0.0000e+00 - loss_batch: 4.4924 - val_loss: 4.7187 - val_auc_9: 0.5199 - val_recall_at_10: 0.1971 - val_ndcg_at_10: 0.0951 - val_mrr_at_10: 0.0646 - val_precision_at_10: 0.0197 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.7393\n",
            "Epoch 38/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.4214 - auc_9: 0.5425 - recall_at_10: 0.2443 - ndcg_at_10: 0.1209 - mrr_at_10: 0.0840 - precision_at_10: 0.0244 - regularization_loss: 0.0000e+00 - loss_batch: 4.4190 - val_loss: 4.7320 - val_auc_9: 0.5345 - val_recall_at_10: 0.1908 - val_ndcg_at_10: 0.0907 - val_mrr_at_10: 0.0609 - val_precision_at_10: 0.0191 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4673\n",
            "Epoch 39/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.4028 - auc_9: 0.5420 - recall_at_10: 0.2522 - ndcg_at_10: 0.1255 - mrr_at_10: 0.0876 - precision_at_10: 0.0252 - regularization_loss: 0.0000e+00 - loss_batch: 4.4002 - val_loss: 4.7531 - val_auc_9: 0.5130 - val_recall_at_10: 0.1953 - val_ndcg_at_10: 0.0939 - val_mrr_at_10: 0.0636 - val_precision_at_10: 0.0195 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.7574\n",
            "Epoch 40/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.3942 - auc_9: 0.5357 - recall_at_10: 0.2588 - ndcg_at_10: 0.1301 - mrr_at_10: 0.0915 - precision_at_10: 0.0259 - regularization_loss: 0.0000e+00 - loss_batch: 4.3916 - val_loss: 4.7131 - val_auc_9: 0.5148 - val_recall_at_10: 0.1976 - val_ndcg_at_10: 0.0951 - val_mrr_at_10: 0.0645 - val_precision_at_10: 0.0198 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3924\n",
            "Epoch 41/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3890 - auc_9: 0.5355 - recall_at_10: 0.2612 - ndcg_at_10: 0.1312 - mrr_at_10: 0.0922 - precision_at_10: 0.0261 - regularization_loss: 0.0000e+00 - loss_batch: 4.3865 - val_loss: 4.7362 - val_auc_9: 0.5117 - val_recall_at_10: 0.1829 - val_ndcg_at_10: 0.0889 - val_mrr_at_10: 0.0608 - val_precision_at_10: 0.0183 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3470\n",
            "Epoch 42/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.3739 - auc_9: 0.5353 - recall_at_10: 0.2628 - ndcg_at_10: 0.1331 - mrr_at_10: 0.0942 - precision_at_10: 0.0263 - regularization_loss: 0.0000e+00 - loss_batch: 4.3715 - val_loss: 4.6936 - val_auc_9: 0.5159 - val_recall_at_10: 0.2124 - val_ndcg_at_10: 0.1037 - val_mrr_at_10: 0.0712 - val_precision_at_10: 0.0212 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3469\n",
            "Epoch 43/50\n",
            "549/549 [==============================] - 16s 28ms/step - loss: 4.4608 - auc_9: 0.5392 - recall_at_10: 0.2726 - ndcg_at_10: 0.1391 - mrr_at_10: 0.0990 - precision_at_10: 0.0273 - regularization_loss: 0.0000e+00 - loss_batch: 4.4600 - val_loss: 7.2733 - val_auc_9: 0.4978 - val_recall_at_10: 0.1364 - val_ndcg_at_10: 0.0623 - val_mrr_at_10: 0.0404 - val_precision_at_10: 0.0136 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 10.2137\n",
            "Epoch 44/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.5459 - auc_9: 0.5156 - recall_at_10: 0.1698 - ndcg_at_10: 0.0805 - mrr_at_10: 0.0539 - precision_at_10: 0.0170 - regularization_loss: 0.0000e+00 - loss_batch: 4.5435 - val_loss: 4.7707 - val_auc_9: 0.5188 - val_recall_at_10: 0.1721 - val_ndcg_at_10: 0.0800 - val_mrr_at_10: 0.0526 - val_precision_at_10: 0.0172 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.2609\n",
            "Epoch 45/50\n",
            "549/549 [==============================] - 14s 24ms/step - loss: 4.4688 - auc_9: 0.5170 - recall_at_10: 0.2161 - ndcg_at_10: 0.1059 - mrr_at_10: 0.0730 - precision_at_10: 0.0216 - regularization_loss: 0.0000e+00 - loss_batch: 4.4663 - val_loss: 4.7474 - val_auc_9: 0.5233 - val_recall_at_10: 0.1886 - val_ndcg_at_10: 0.0904 - val_mrr_at_10: 0.0611 - val_precision_at_10: 0.0189 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.6382\n",
            "Epoch 46/50\n",
            "549/549 [==============================] - 13s 22ms/step - loss: 4.4215 - auc_9: 0.5252 - recall_at_10: 0.2418 - ndcg_at_10: 0.1202 - mrr_at_10: 0.0838 - precision_at_10: 0.0242 - regularization_loss: 0.0000e+00 - loss_batch: 4.4191 - val_loss: 4.7313 - val_auc_9: 0.5344 - val_recall_at_10: 0.1902 - val_ndcg_at_10: 0.0912 - val_mrr_at_10: 0.0617 - val_precision_at_10: 0.0190 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.3851\n",
            "Epoch 47/50\n",
            "549/549 [==============================] - 15s 26ms/step - loss: 4.3943 - auc_9: 0.5330 - recall_at_10: 0.2539 - ndcg_at_10: 0.1279 - mrr_at_10: 0.0900 - precision_at_10: 0.0254 - regularization_loss: 0.0000e+00 - loss_batch: 4.3919 - val_loss: 4.7084 - val_auc_9: 0.5328 - val_recall_at_10: 0.1939 - val_ndcg_at_10: 0.0945 - val_mrr_at_10: 0.0648 - val_precision_at_10: 0.0194 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.1199\n",
            "Epoch 48/50\n",
            "549/549 [==============================] - 14s 25ms/step - loss: 4.3809 - auc_9: 0.5328 - recall_at_10: 0.2663 - ndcg_at_10: 0.1345 - mrr_at_10: 0.0950 - precision_at_10: 0.0266 - regularization_loss: 0.0000e+00 - loss_batch: 4.3785 - val_loss: 4.7843 - val_auc_9: 0.5330 - val_recall_at_10: 0.1789 - val_ndcg_at_10: 0.0868 - val_mrr_at_10: 0.0593 - val_precision_at_10: 0.0179 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4006\n",
            "Epoch 49/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.3744 - auc_9: 0.5306 - recall_at_10: 0.2641 - ndcg_at_10: 0.1344 - mrr_at_10: 0.0955 - precision_at_10: 0.0264 - regularization_loss: 0.0000e+00 - loss_batch: 4.3719 - val_loss: 4.7308 - val_auc_9: 0.5244 - val_recall_at_10: 0.2020 - val_ndcg_at_10: 0.0973 - val_mrr_at_10: 0.0661 - val_precision_at_10: 0.0202 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5648\n",
            "Epoch 50/50\n",
            "549/549 [==============================] - 12s 21ms/step - loss: 4.3704 - auc_9: 0.5287 - recall_at_10: 0.2676 - ndcg_at_10: 0.1367 - mrr_at_10: 0.0974 - precision_at_10: 0.0268 - regularization_loss: 0.0000e+00 - loss_batch: 4.3681 - val_loss: 4.7140 - val_auc_9: 0.5279 - val_recall_at_10: 0.1979 - val_ndcg_at_10: 0.0958 - val_mrr_at_10: 0.0653 - val_precision_at_10: 0.0198 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.4455\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d4448420970>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v4"
      ],
      "metadata": {
        "id": "H0qe_GEksEvQ"
      },
      "id": "H0qe_GEksEvQ"
    },
    {
      "cell_type": "code",
      "source": [
        "model_v4 = build_towers(tower_dim=64)"
      ],
      "metadata": {
        "id": "FX4JB8dljRxf"
      },
      "id": "FX4JB8dljRxf",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                 run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10), tf.keras.metrics.AUC(), mm.MRRAt(10), mm.PrecisionAt(10)])\n",
        "model_v4.fit(train, validation_data=valid, batch_size=64, epochs=50)"
      ],
      "metadata": {
        "id": "bkA-BtI7q2IA",
        "outputId": "e3687f52-d85e-4db1-9f9d-e9879f6070c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bkA-BtI7q2IA",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1097/1097 [==============================] - 41s 30ms/step - loss: 4.0937 - auc_10: 0.5621 - recall_at_10: 0.1918 - ndcg_at_10: 0.0882 - mrr_at_10: 0.0575 - precision_at_10: 0.0192 - regularization_loss: 0.0000e+00 - loss_batch: 4.0935 - val_loss: 4.0448 - val_auc_10: 0.6044 - val_recall_at_10: 0.2650 - val_ndcg_at_10: 0.1258 - val_mrr_at_10: 0.0842 - val_precision_at_10: 0.0265 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 3.7124\n",
            "Epoch 2/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.9356 - auc_10: 0.6167 - recall_at_10: 0.2999 - ndcg_at_10: 0.1441 - mrr_at_10: 0.0975 - precision_at_10: 0.0300 - regularization_loss: 0.0000e+00 - loss_batch: 3.9356 - val_loss: 3.9807 - val_auc_10: 0.5899 - val_recall_at_10: 0.3061 - val_ndcg_at_10: 0.1483 - val_mrr_at_10: 0.1012 - val_precision_at_10: 0.0306 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 3.6598\n",
            "Epoch 3/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8501 - auc_10: 0.6220 - recall_at_10: 0.3507 - ndcg_at_10: 0.1709 - mrr_at_10: 0.1171 - precision_at_10: 0.0351 - regularization_loss: 0.0000e+00 - loss_batch: 3.8501 - val_loss: 3.9753 - val_auc_10: 0.5924 - val_recall_at_10: 0.3082 - val_ndcg_at_10: 0.1490 - val_mrr_at_10: 0.1015 - val_precision_at_10: 0.0308 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 3.7586\n",
            "Epoch 4/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8184 - auc_10: 0.6214 - recall_at_10: 0.3681 - ndcg_at_10: 0.1817 - mrr_at_10: 0.1259 - precision_at_10: 0.0368 - regularization_loss: 0.0000e+00 - loss_batch: 3.8183 - val_loss: 4.0190 - val_auc_10: 0.5808 - val_recall_at_10: 0.3000 - val_ndcg_at_10: 0.1466 - val_mrr_at_10: 0.1005 - val_precision_at_10: 0.0300 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.3601\n",
            "Epoch 5/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8036 - auc_10: 0.6154 - recall_at_10: 0.3769 - ndcg_at_10: 0.1853 - mrr_at_10: 0.1279 - precision_at_10: 0.0377 - regularization_loss: 0.0000e+00 - loss_batch: 3.8035 - val_loss: 3.9560 - val_auc_10: 0.5756 - val_recall_at_10: 0.3262 - val_ndcg_at_10: 0.1601 - val_mrr_at_10: 0.1103 - val_precision_at_10: 0.0326 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.0985\n",
            "Epoch 6/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.7940 - auc_10: 0.6085 - recall_at_10: 0.3787 - ndcg_at_10: 0.1882 - mrr_at_10: 0.1311 - precision_at_10: 0.0379 - regularization_loss: 0.0000e+00 - loss_batch: 3.7939 - val_loss: 3.9927 - val_auc_10: 0.5527 - val_recall_at_10: 0.3097 - val_ndcg_at_10: 0.1532 - val_mrr_at_10: 0.1062 - val_precision_at_10: 0.0310 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2051\n",
            "Epoch 7/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.7835 - auc_10: 0.6005 - recall_at_10: 0.3855 - ndcg_at_10: 0.1919 - mrr_at_10: 0.1338 - precision_at_10: 0.0385 - regularization_loss: 0.0000e+00 - loss_batch: 3.7834 - val_loss: 3.9656 - val_auc_10: 0.5595 - val_recall_at_10: 0.3200 - val_ndcg_at_10: 0.1560 - val_mrr_at_10: 0.1069 - val_precision_at_10: 0.0320 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.3933\n",
            "Epoch 8/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.7793 - auc_10: 0.5926 - recall_at_10: 0.3851 - ndcg_at_10: 0.1920 - mrr_at_10: 0.1341 - precision_at_10: 0.0385 - regularization_loss: 0.0000e+00 - loss_batch: 3.7792 - val_loss: 3.9843 - val_auc_10: 0.5590 - val_recall_at_10: 0.3204 - val_ndcg_at_10: 0.1582 - val_mrr_at_10: 0.1095 - val_precision_at_10: 0.0320 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5129\n",
            "Epoch 9/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.7775 - auc_10: 0.5883 - recall_at_10: 0.3865 - ndcg_at_10: 0.1929 - mrr_at_10: 0.1347 - precision_at_10: 0.0387 - regularization_loss: 0.0000e+00 - loss_batch: 3.7775 - val_loss: 3.9875 - val_auc_10: 0.5454 - val_recall_at_10: 0.3021 - val_ndcg_at_10: 0.1482 - val_mrr_at_10: 0.1021 - val_precision_at_10: 0.0302 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2030\n",
            "Epoch 10/50\n",
            "1097/1097 [==============================] - 32s 29ms/step - loss: 3.7806 - auc_10: 0.5840 - recall_at_10: 0.3855 - ndcg_at_10: 0.1916 - mrr_at_10: 0.1335 - precision_at_10: 0.0386 - regularization_loss: 0.0000e+00 - loss_batch: 3.7805 - val_loss: 3.9941 - val_auc_10: 0.5641 - val_recall_at_10: 0.3309 - val_ndcg_at_10: 0.1629 - val_mrr_at_10: 0.1125 - val_precision_at_10: 0.0331 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5335\n",
            "Epoch 11/50\n",
            "1097/1097 [==============================] - 27s 24ms/step - loss: 3.7693 - auc_10: 0.5785 - recall_at_10: 0.3927 - ndcg_at_10: 0.1955 - mrr_at_10: 0.1363 - precision_at_10: 0.0393 - regularization_loss: 0.0000e+00 - loss_batch: 3.7692 - val_loss: 4.0294 - val_auc_10: 0.5442 - val_recall_at_10: 0.3073 - val_ndcg_at_10: 0.1512 - val_mrr_at_10: 0.1045 - val_precision_at_10: 0.0307 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.8059\n",
            "Epoch 12/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.7676 - auc_10: 0.5764 - recall_at_10: 0.3929 - ndcg_at_10: 0.1963 - mrr_at_10: 0.1374 - precision_at_10: 0.0393 - regularization_loss: 0.0000e+00 - loss_batch: 3.7675 - val_loss: 3.9569 - val_auc_10: 0.5547 - val_recall_at_10: 0.3281 - val_ndcg_at_10: 0.1605 - val_mrr_at_10: 0.1103 - val_precision_at_10: 0.0328 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7425\n",
            "Epoch 13/50\n",
            "1097/1097 [==============================] - 24s 22ms/step - loss: 3.7664 - auc_10: 0.5747 - recall_at_10: 0.3912 - ndcg_at_10: 0.1950 - mrr_at_10: 0.1361 - precision_at_10: 0.0391 - regularization_loss: 0.0000e+00 - loss_batch: 3.7663 - val_loss: 4.0077 - val_auc_10: 0.5352 - val_recall_at_10: 0.3124 - val_ndcg_at_10: 0.1537 - val_mrr_at_10: 0.1061 - val_precision_at_10: 0.0312 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5802\n",
            "Epoch 14/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.7611 - auc_10: 0.5730 - recall_at_10: 0.3931 - ndcg_at_10: 0.1977 - mrr_at_10: 0.1390 - precision_at_10: 0.0393 - regularization_loss: 0.0000e+00 - loss_batch: 3.7610 - val_loss: 4.0517 - val_auc_10: 0.5329 - val_recall_at_10: 0.3061 - val_ndcg_at_10: 0.1505 - val_mrr_at_10: 0.1038 - val_precision_at_10: 0.0306 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5223\n",
            "Epoch 15/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.7604 - auc_10: 0.5719 - recall_at_10: 0.3974 - ndcg_at_10: 0.1988 - mrr_at_10: 0.1392 - precision_at_10: 0.0397 - regularization_loss: 0.0000e+00 - loss_batch: 3.7603 - val_loss: 3.9681 - val_auc_10: 0.5370 - val_recall_at_10: 0.3091 - val_ndcg_at_10: 0.1540 - val_mrr_at_10: 0.1074 - val_precision_at_10: 0.0309 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2722\n",
            "Epoch 16/50\n",
            "1097/1097 [==============================] - 24s 21ms/step - loss: 3.7578 - auc_10: 0.5702 - recall_at_10: 0.3958 - ndcg_at_10: 0.2002 - mrr_at_10: 0.1415 - precision_at_10: 0.0396 - regularization_loss: 0.0000e+00 - loss_batch: 3.7577 - val_loss: 4.0066 - val_auc_10: 0.5432 - val_recall_at_10: 0.3260 - val_ndcg_at_10: 0.1618 - val_mrr_at_10: 0.1125 - val_precision_at_10: 0.0326 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7046\n",
            "Epoch 17/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.7561 - auc_10: 0.5690 - recall_at_10: 0.3926 - ndcg_at_10: 0.1977 - mrr_at_10: 0.1392 - precision_at_10: 0.0393 - regularization_loss: 0.0000e+00 - loss_batch: 3.7560 - val_loss: 4.0135 - val_auc_10: 0.5460 - val_recall_at_10: 0.3258 - val_ndcg_at_10: 0.1601 - val_mrr_at_10: 0.1104 - val_precision_at_10: 0.0326 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5794\n",
            "Epoch 18/50\n",
            "1097/1097 [==============================] - 22s 19ms/step - loss: 3.7545 - auc_10: 0.5703 - recall_at_10: 0.3915 - ndcg_at_10: 0.1964 - mrr_at_10: 0.1379 - precision_at_10: 0.0392 - regularization_loss: 0.0000e+00 - loss_batch: 3.7545 - val_loss: 4.0551 - val_auc_10: 0.5383 - val_recall_at_10: 0.3152 - val_ndcg_at_10: 0.1558 - val_mrr_at_10: 0.1080 - val_precision_at_10: 0.0315 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.9884\n",
            "Epoch 19/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.7585 - auc_10: 0.5679 - recall_at_10: 0.3952 - ndcg_at_10: 0.1987 - mrr_at_10: 0.1397 - precision_at_10: 0.0395 - regularization_loss: 0.0000e+00 - loss_batch: 3.7584 - val_loss: 3.9862 - val_auc_10: 0.5352 - val_recall_at_10: 0.3126 - val_ndcg_at_10: 0.1541 - val_mrr_at_10: 0.1065 - val_precision_at_10: 0.0313 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.4813\n",
            "Epoch 20/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.7593 - auc_10: 0.5691 - recall_at_10: 0.3912 - ndcg_at_10: 0.1981 - mrr_at_10: 0.1401 - precision_at_10: 0.0391 - regularization_loss: 0.0000e+00 - loss_batch: 3.7592 - val_loss: 4.0198 - val_auc_10: 0.5342 - val_recall_at_10: 0.3168 - val_ndcg_at_10: 0.1562 - val_mrr_at_10: 0.1079 - val_precision_at_10: 0.0317 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7165\n",
            "Epoch 21/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.7455 - auc_10: 0.5678 - recall_at_10: 0.3942 - ndcg_at_10: 0.2008 - mrr_at_10: 0.1426 - precision_at_10: 0.0394 - regularization_loss: 0.0000e+00 - loss_batch: 3.7454 - val_loss: 3.9936 - val_auc_10: 0.5438 - val_recall_at_10: 0.3255 - val_ndcg_at_10: 0.1601 - val_mrr_at_10: 0.1105 - val_precision_at_10: 0.0325 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5818\n",
            "Epoch 22/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.9651 - auc_10: 0.5392 - recall_at_10: 0.3402 - ndcg_at_10: 0.1789 - mrr_at_10: 0.1306 - precision_at_10: 0.0340 - regularization_loss: 0.0000e+00 - loss_batch: 3.9649 - val_loss: 4.0110 - val_auc_10: 0.5419 - val_recall_at_10: 0.3227 - val_ndcg_at_10: 0.1676 - val_mrr_at_10: 0.1216 - val_precision_at_10: 0.0323 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.6600\n",
            "Epoch 23/50\n",
            "1097/1097 [==============================] - 27s 24ms/step - loss: 3.8576 - auc_10: 0.5520 - recall_at_10: 0.3442 - ndcg_at_10: 0.1873 - mrr_at_10: 0.1407 - precision_at_10: 0.0344 - regularization_loss: 0.0000e+00 - loss_batch: 3.8575 - val_loss: 4.0376 - val_auc_10: 0.5189 - val_recall_at_10: 0.3162 - val_ndcg_at_10: 0.1560 - val_mrr_at_10: 0.1081 - val_precision_at_10: 0.0316 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.4694\n",
            "Epoch 24/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8273 - auc_10: 0.5222 - recall_at_10: 0.3550 - ndcg_at_10: 0.1945 - mrr_at_10: 0.1468 - precision_at_10: 0.0355 - regularization_loss: 0.0000e+00 - loss_batch: 3.8272 - val_loss: 3.9885 - val_auc_10: 0.5178 - val_recall_at_10: 0.3167 - val_ndcg_at_10: 0.1640 - val_mrr_at_10: 0.1185 - val_precision_at_10: 0.0317 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.3174\n",
            "Epoch 25/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8219 - auc_10: 0.5211 - recall_at_10: 0.3566 - ndcg_at_10: 0.1977 - mrr_at_10: 0.1504 - precision_at_10: 0.0357 - regularization_loss: 0.0000e+00 - loss_batch: 3.8218 - val_loss: 3.9777 - val_auc_10: 0.5206 - val_recall_at_10: 0.3288 - val_ndcg_at_10: 0.1698 - val_mrr_at_10: 0.1225 - val_precision_at_10: 0.0329 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2981\n",
            "Epoch 26/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8157 - auc_10: 0.5192 - recall_at_10: 0.3613 - ndcg_at_10: 0.2010 - mrr_at_10: 0.1532 - precision_at_10: 0.0361 - regularization_loss: 0.0000e+00 - loss_batch: 3.8156 - val_loss: 4.0209 - val_auc_10: 0.5168 - val_recall_at_10: 0.3198 - val_ndcg_at_10: 0.1698 - val_mrr_at_10: 0.1252 - val_precision_at_10: 0.0320 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2672\n",
            "Epoch 27/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8141 - auc_10: 0.5195 - recall_at_10: 0.3577 - ndcg_at_10: 0.2005 - mrr_at_10: 0.1536 - precision_at_10: 0.0358 - regularization_loss: 0.0000e+00 - loss_batch: 3.8141 - val_loss: 3.9908 - val_auc_10: 0.5203 - val_recall_at_10: 0.3122 - val_ndcg_at_10: 0.1634 - val_mrr_at_10: 0.1193 - val_precision_at_10: 0.0312 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5140\n",
            "Epoch 28/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8128 - auc_10: 0.5163 - recall_at_10: 0.3585 - ndcg_at_10: 0.2000 - mrr_at_10: 0.1528 - precision_at_10: 0.0358 - regularization_loss: 0.0000e+00 - loss_batch: 3.8128 - val_loss: 3.9994 - val_auc_10: 0.5169 - val_recall_at_10: 0.3162 - val_ndcg_at_10: 0.1650 - val_mrr_at_10: 0.1201 - val_precision_at_10: 0.0316 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.4695\n",
            "Epoch 29/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8166 - auc_10: 0.5147 - recall_at_10: 0.3631 - ndcg_at_10: 0.2035 - mrr_at_10: 0.1560 - precision_at_10: 0.0363 - regularization_loss: 0.0000e+00 - loss_batch: 3.8166 - val_loss: 4.0322 - val_auc_10: 0.5156 - val_recall_at_10: 0.3062 - val_ndcg_at_10: 0.1632 - val_mrr_at_10: 0.1207 - val_precision_at_10: 0.0306 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.3389\n",
            "Epoch 30/50\n",
            "1097/1097 [==============================] - 27s 24ms/step - loss: 3.8091 - auc_10: 0.5152 - recall_at_10: 0.3562 - ndcg_at_10: 0.1986 - mrr_at_10: 0.1517 - precision_at_10: 0.0356 - regularization_loss: 0.0000e+00 - loss_batch: 3.8090 - val_loss: 4.0395 - val_auc_10: 0.5110 - val_recall_at_10: 0.3276 - val_ndcg_at_10: 0.1718 - val_mrr_at_10: 0.1254 - val_precision_at_10: 0.0328 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5195\n",
            "Epoch 31/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8125 - auc_10: 0.5177 - recall_at_10: 0.3636 - ndcg_at_10: 0.1992 - mrr_at_10: 0.1503 - precision_at_10: 0.0364 - regularization_loss: 0.0000e+00 - loss_batch: 3.8157 - val_loss: 4.0037 - val_auc_10: 0.5117 - val_recall_at_10: 0.3160 - val_ndcg_at_10: 0.1534 - val_mrr_at_10: 0.1047 - val_precision_at_10: 0.0316 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.1287\n",
            "Epoch 32/50\n",
            "1097/1097 [==============================] - 25s 23ms/step - loss: 3.8171 - auc_10: 0.5169 - recall_at_10: 0.3507 - ndcg_at_10: 0.1884 - mrr_at_10: 0.1401 - precision_at_10: 0.0351 - regularization_loss: 0.0000e+00 - loss_batch: 3.8170 - val_loss: 4.0071 - val_auc_10: 0.5160 - val_recall_at_10: 0.3204 - val_ndcg_at_10: 0.1675 - val_mrr_at_10: 0.1221 - val_precision_at_10: 0.0320 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2288\n",
            "Epoch 33/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8661 - auc_10: 0.5074 - recall_at_10: 0.3596 - ndcg_at_10: 0.2000 - mrr_at_10: 0.1525 - precision_at_10: 0.0360 - regularization_loss: 0.0000e+00 - loss_batch: 3.8660 - val_loss: 4.0291 - val_auc_10: 0.5000 - val_recall_at_10: 0.3309 - val_ndcg_at_10: 0.1730 - val_mrr_at_10: 0.1261 - val_precision_at_10: 0.0331 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.1376\n",
            "Epoch 34/50\n",
            "1097/1097 [==============================] - 23s 21ms/step - loss: 3.8456 - auc_10: 0.5019 - recall_at_10: 0.3508 - ndcg_at_10: 0.1979 - mrr_at_10: 0.1523 - precision_at_10: 0.0351 - regularization_loss: 0.0000e+00 - loss_batch: 3.8455 - val_loss: 4.0174 - val_auc_10: 0.5002 - val_recall_at_10: 0.3134 - val_ndcg_at_10: 0.1640 - val_mrr_at_10: 0.1196 - val_precision_at_10: 0.0313 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.2735\n",
            "Epoch 35/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8185 - auc_10: 0.5018 - recall_at_10: 0.3546 - ndcg_at_10: 0.2016 - mrr_at_10: 0.1561 - precision_at_10: 0.0355 - regularization_loss: 0.0000e+00 - loss_batch: 3.8184 - val_loss: 4.0020 - val_auc_10: 0.5018 - val_recall_at_10: 0.3190 - val_ndcg_at_10: 0.1622 - val_mrr_at_10: 0.1158 - val_precision_at_10: 0.0319 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.1573\n",
            "Epoch 36/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8160 - auc_10: 0.5023 - recall_at_10: 0.3553 - ndcg_at_10: 0.2022 - mrr_at_10: 0.1566 - precision_at_10: 0.0355 - regularization_loss: 0.0000e+00 - loss_batch: 3.8159 - val_loss: 4.0108 - val_auc_10: 0.5014 - val_recall_at_10: 0.3181 - val_ndcg_at_10: 0.1671 - val_mrr_at_10: 0.1223 - val_precision_at_10: 0.0318 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.5046\n",
            "Epoch 37/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8437 - auc_10: 0.5260 - recall_at_10: 0.3425 - ndcg_at_10: 0.1896 - mrr_at_10: 0.1441 - precision_at_10: 0.0343 - regularization_loss: 0.0000e+00 - loss_batch: 3.8436 - val_loss: 4.0650 - val_auc_10: 0.5279 - val_recall_at_10: 0.3262 - val_ndcg_at_10: 0.1677 - val_mrr_at_10: 0.1205 - val_precision_at_10: 0.0326 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5168\n",
            "Epoch 38/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8123 - auc_10: 0.5355 - recall_at_10: 0.3560 - ndcg_at_10: 0.1938 - mrr_at_10: 0.1455 - precision_at_10: 0.0356 - regularization_loss: 0.0000e+00 - loss_batch: 3.8122 - val_loss: 4.0345 - val_auc_10: 0.5356 - val_recall_at_10: 0.3120 - val_ndcg_at_10: 0.1589 - val_mrr_at_10: 0.1134 - val_precision_at_10: 0.0312 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.0021\n",
            "Epoch 39/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8086 - auc_10: 0.5210 - recall_at_10: 0.3577 - ndcg_at_10: 0.1949 - mrr_at_10: 0.1464 - precision_at_10: 0.0358 - regularization_loss: 0.0000e+00 - loss_batch: 3.8086 - val_loss: 4.0869 - val_auc_10: 0.5204 - val_recall_at_10: 0.3137 - val_ndcg_at_10: 0.1621 - val_mrr_at_10: 0.1171 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.7554\n",
            "Epoch 40/50\n",
            "1097/1097 [==============================] - 23s 21ms/step - loss: 3.8213 - auc_10: 0.5230 - recall_at_10: 0.3584 - ndcg_at_10: 0.1952 - mrr_at_10: 0.1465 - precision_at_10: 0.0358 - regularization_loss: 0.0000e+00 - loss_batch: 3.8213 - val_loss: 4.2973 - val_auc_10: 0.5468 - val_recall_at_10: 0.3163 - val_ndcg_at_10: 0.1620 - val_mrr_at_10: 0.1161 - val_precision_at_10: 0.0316 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 10.3236\n",
            "Epoch 41/50\n",
            "1097/1097 [==============================] - 22s 20ms/step - loss: 3.8340 - auc_10: 0.5366 - recall_at_10: 0.3525 - ndcg_at_10: 0.1920 - mrr_at_10: 0.1442 - precision_at_10: 0.0352 - regularization_loss: 0.0000e+00 - loss_batch: 3.8339 - val_loss: 4.1304 - val_auc_10: 0.5426 - val_recall_at_10: 0.3173 - val_ndcg_at_10: 0.1617 - val_mrr_at_10: 0.1154 - val_precision_at_10: 0.0317 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 8.9044\n",
            "Epoch 42/50\n",
            "1097/1097 [==============================] - 23s 21ms/step - loss: 3.8065 - auc_10: 0.5416 - recall_at_10: 0.3563 - ndcg_at_10: 0.1935 - mrr_at_10: 0.1450 - precision_at_10: 0.0356 - regularization_loss: 0.0000e+00 - loss_batch: 3.8064 - val_loss: 4.0909 - val_auc_10: 0.5362 - val_recall_at_10: 0.3113 - val_ndcg_at_10: 0.1604 - val_mrr_at_10: 0.1156 - val_precision_at_10: 0.0311 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5723\n",
            "Epoch 43/50\n",
            "1097/1097 [==============================] - 26s 22ms/step - loss: 3.8274 - auc_10: 0.5345 - recall_at_10: 0.3613 - ndcg_at_10: 0.1945 - mrr_at_10: 0.1448 - precision_at_10: 0.0361 - regularization_loss: 0.0000e+00 - loss_batch: 3.8275 - val_loss: 4.1738 - val_auc_10: 0.5212 - val_recall_at_10: 0.2894 - val_ndcg_at_10: 0.1470 - val_mrr_at_10: 0.1048 - val_precision_at_10: 0.0289 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.5857\n",
            "Epoch 44/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.9027 - auc_10: 0.5153 - recall_at_10: 0.3498 - ndcg_at_10: 0.1864 - mrr_at_10: 0.1378 - precision_at_10: 0.0350 - regularization_loss: 0.0000e+00 - loss_batch: 3.9026 - val_loss: 4.0337 - val_auc_10: 0.5000 - val_recall_at_10: 0.3149 - val_ndcg_at_10: 0.1680 - val_mrr_at_10: 0.1244 - val_precision_at_10: 0.0315 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 4.1704\n",
            "Epoch 45/50\n",
            "1097/1097 [==============================] - 25s 23ms/step - loss: 3.8279 - auc_10: 0.5000 - recall_at_10: 0.3566 - ndcg_at_10: 0.2051 - mrr_at_10: 0.1600 - precision_at_10: 0.0357 - regularization_loss: 0.0000e+00 - loss_batch: 3.8278 - val_loss: 4.2506 - val_auc_10: 0.5000 - val_recall_at_10: 0.3158 - val_ndcg_at_10: 0.1662 - val_mrr_at_10: 0.1219 - val_precision_at_10: 0.0316 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 7.4928\n",
            "Epoch 46/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8221 - auc_10: 0.5007 - recall_at_10: 0.3549 - ndcg_at_10: 0.2005 - mrr_at_10: 0.1546 - precision_at_10: 0.0355 - regularization_loss: 0.0000e+00 - loss_batch: 3.8220 - val_loss: 4.0709 - val_auc_10: 0.5000 - val_recall_at_10: 0.3141 - val_ndcg_at_10: 0.1610 - val_mrr_at_10: 0.1155 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 5.8882\n",
            "Epoch 47/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8216 - auc_10: 0.5093 - recall_at_10: 0.3567 - ndcg_at_10: 0.1999 - mrr_at_10: 0.1531 - precision_at_10: 0.0357 - regularization_loss: 0.0000e+00 - loss_batch: 3.8216 - val_loss: 4.0339 - val_auc_10: 0.5141 - val_recall_at_10: 0.3077 - val_ndcg_at_10: 0.1610 - val_mrr_at_10: 0.1174 - val_precision_at_10: 0.0308 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 6.2559\n",
            "Epoch 48/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8492 - auc_10: 0.5392 - recall_at_10: 0.3491 - ndcg_at_10: 0.1902 - mrr_at_10: 0.1429 - precision_at_10: 0.0349 - regularization_loss: 0.0000e+00 - loss_batch: 3.8491 - val_loss: 4.2060 - val_auc_10: 0.5379 - val_recall_at_10: 0.3040 - val_ndcg_at_10: 0.1566 - val_mrr_at_10: 0.1129 - val_precision_at_10: 0.0304 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 6.9827\n",
            "Epoch 49/50\n",
            "1097/1097 [==============================] - 23s 20ms/step - loss: 3.8152 - auc_10: 0.5535 - recall_at_10: 0.3563 - ndcg_at_10: 0.1934 - mrr_at_10: 0.1448 - precision_at_10: 0.0356 - regularization_loss: 0.0000e+00 - loss_batch: 3.8151 - val_loss: 4.1062 - val_auc_10: 0.5495 - val_recall_at_10: 0.3183 - val_ndcg_at_10: 0.1653 - val_mrr_at_10: 0.1198 - val_precision_at_10: 0.0318 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 6.3763\n",
            "Epoch 50/50\n",
            "1097/1097 [==============================] - 25s 22ms/step - loss: 3.8327 - auc_10: 0.5696 - recall_at_10: 0.3561 - ndcg_at_10: 0.1929 - mrr_at_10: 0.1443 - precision_at_10: 0.0356 - regularization_loss: 0.0000e+00 - loss_batch: 3.8326 - val_loss: 4.3755 - val_auc_10: 0.5495 - val_recall_at_10: 0.3154 - val_ndcg_at_10: 0.1654 - val_mrr_at_10: 0.1207 - val_precision_at_10: 0.0315 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 21.8747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d447afdcb20>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v5"
      ],
      "metadata": {
        "id": "wQOgf3OzxDFj"
      },
      "id": "wQOgf3OzxDFj"
    },
    {
      "cell_type": "code",
      "source": [
        "model_v5 = build_towers(tower_dim=64)"
      ],
      "metadata": {
        "id": "0Uu6k3W4q2KW"
      },
      "id": "0Uu6k3W4q2KW",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOK_K = 10\n",
        "model_v5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                 run_eagerly=False, metrics=[mm.TopKMetricsAggregator.default_metrics(top_ks=TOP_K)],\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "model_v5.fit(train, validation_data=valid, batch_size=32, epochs=20)"
      ],
      "metadata": {
        "id": "tDteBHc3q2Mt",
        "outputId": "cce1287b-842d-46d4-fbe3-26b9b0b83ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tDteBHc3q2Mt",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2194/2194 [==============================] - 61s 25ms/step - loss: 3.4274 - recall_at_10: 0.3553 - mrr_at_10: 0.1066 - ndcg_at_10: 0.1635 - map_at_10: 0.1066 - precision_at_10: 0.0355 - regularization_loss: 0.0000e+00 - loss_batch: 3.4272 - val_loss: 3.3944 - val_recall_at_10: 0.4311 - val_mrr_at_10: 0.1346 - val_ndcg_at_10: 0.2026 - val_map_at_10: 0.1346 - val_precision_at_10: 0.0431 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.6066\n",
            "Epoch 2/20\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.3122 - recall_at_10: 0.4674 - mrr_at_10: 0.1545 - ndcg_at_10: 0.2266 - map_at_10: 0.1545 - precision_at_10: 0.0467 - regularization_loss: 0.0000e+00 - loss_batch: 3.3121 - val_loss: 3.3180 - val_recall_at_10: 0.4833 - val_mrr_at_10: 0.1615 - val_ndcg_at_10: 0.2357 - val_map_at_10: 0.1615 - val_precision_at_10: 0.0483 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3734\n",
            "Epoch 3/20\n",
            "2194/2194 [==============================] - 50s 23ms/step - loss: 3.2593 - recall_at_10: 0.5038 - mrr_at_10: 0.1710 - ndcg_at_10: 0.2479 - map_at_10: 0.1710 - precision_at_10: 0.0504 - regularization_loss: 0.0000e+00 - loss_batch: 3.2592 - val_loss: 3.3110 - val_recall_at_10: 0.4815 - val_mrr_at_10: 0.1627 - val_ndcg_at_10: 0.2362 - val_map_at_10: 0.1627 - val_precision_at_10: 0.0481 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2080\n",
            "Epoch 4/20\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.2229 - recall_at_10: 0.5372 - mrr_at_10: 0.1852 - ndcg_at_10: 0.2666 - map_at_10: 0.1852 - precision_at_10: 0.0537 - regularization_loss: 0.0000e+00 - loss_batch: 3.2228 - val_loss: 3.2757 - val_recall_at_10: 0.5133 - val_mrr_at_10: 0.1756 - val_ndcg_at_10: 0.2536 - val_map_at_10: 0.1756 - val_precision_at_10: 0.0513 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.1271\n",
            "Epoch 5/20\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.2013 - recall_at_10: 0.5579 - mrr_at_10: 0.1917 - ndcg_at_10: 0.2763 - map_at_10: 0.1917 - precision_at_10: 0.0558 - regularization_loss: 0.0000e+00 - loss_batch: 3.2013 - val_loss: 3.2901 - val_recall_at_10: 0.5139 - val_mrr_at_10: 0.1746 - val_ndcg_at_10: 0.2530 - val_map_at_10: 0.1746 - val_precision_at_10: 0.0514 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2997\n",
            "Epoch 6/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.1859 - recall_at_10: 0.5569 - mrr_at_10: 0.1921 - ndcg_at_10: 0.2764 - map_at_10: 0.1921 - precision_at_10: 0.0557 - regularization_loss: 0.0000e+00 - loss_batch: 3.1859 - val_loss: 3.3707 - val_recall_at_10: 0.5100 - val_mrr_at_10: 0.1665 - val_ndcg_at_10: 0.2457 - val_map_at_10: 0.1665 - val_precision_at_10: 0.0510 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3473\n",
            "Epoch 7/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.1770 - recall_at_10: 0.5673 - mrr_at_10: 0.1943 - ndcg_at_10: 0.2805 - map_at_10: 0.1943 - precision_at_10: 0.0567 - regularization_loss: 0.0000e+00 - loss_batch: 3.1770 - val_loss: 3.2952 - val_recall_at_10: 0.5161 - val_mrr_at_10: 0.1727 - val_ndcg_at_10: 0.2519 - val_map_at_10: 0.1727 - val_precision_at_10: 0.0516 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3187\n",
            "Epoch 8/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.1786 - recall_at_10: 0.5713 - mrr_at_10: 0.1978 - ndcg_at_10: 0.2841 - map_at_10: 0.1978 - precision_at_10: 0.0571 - regularization_loss: 0.0000e+00 - loss_batch: 3.1785 - val_loss: 3.2852 - val_recall_at_10: 0.5204 - val_mrr_at_10: 0.1780 - val_ndcg_at_10: 0.2571 - val_map_at_10: 0.1780 - val_precision_at_10: 0.0520 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.5112\n",
            "Epoch 9/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.1630 - recall_at_10: 0.5757 - mrr_at_10: 0.1989 - ndcg_at_10: 0.2860 - map_at_10: 0.1989 - precision_at_10: 0.0576 - regularization_loss: 0.0000e+00 - loss_batch: 3.1629 - val_loss: 3.3119 - val_recall_at_10: 0.5142 - val_mrr_at_10: 0.1755 - val_ndcg_at_10: 0.2537 - val_map_at_10: 0.1755 - val_precision_at_10: 0.0514 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4957\n",
            "Epoch 10/20\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.1525 - recall_at_10: 0.5792 - mrr_at_10: 0.2006 - ndcg_at_10: 0.2881 - map_at_10: 0.2006 - precision_at_10: 0.0579 - regularization_loss: 0.0000e+00 - loss_batch: 3.1525 - val_loss: 3.2470 - val_recall_at_10: 0.5423 - val_mrr_at_10: 0.1873 - val_ndcg_at_10: 0.2694 - val_map_at_10: 0.1873 - val_precision_at_10: 0.0542 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4572\n",
            "Epoch 11/20\n",
            "2194/2194 [==============================] - 48s 21ms/step - loss: 3.1502 - recall_at_10: 0.5789 - mrr_at_10: 0.2017 - ndcg_at_10: 0.2889 - map_at_10: 0.2017 - precision_at_10: 0.0579 - regularization_loss: 0.0000e+00 - loss_batch: 3.1502 - val_loss: 3.2936 - val_recall_at_10: 0.5260 - val_mrr_at_10: 0.1805 - val_ndcg_at_10: 0.2604 - val_map_at_10: 0.1805 - val_precision_at_10: 0.0526 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2680\n",
            "Epoch 12/20\n",
            "2194/2194 [==============================] - 46s 21ms/step - loss: 3.1437 - recall_at_10: 0.5837 - mrr_at_10: 0.2040 - ndcg_at_10: 0.2918 - map_at_10: 0.2040 - precision_at_10: 0.0584 - regularization_loss: 0.0000e+00 - loss_batch: 3.1437 - val_loss: 3.3528 - val_recall_at_10: 0.5051 - val_mrr_at_10: 0.1678 - val_ndcg_at_10: 0.2456 - val_map_at_10: 0.1678 - val_precision_at_10: 0.0505 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4018\n",
            "Epoch 13/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.1466 - recall_at_10: 0.5824 - mrr_at_10: 0.2018 - ndcg_at_10: 0.2898 - map_at_10: 0.2018 - precision_at_10: 0.0582 - regularization_loss: 0.0000e+00 - loss_batch: 3.1466 - val_loss: 3.2716 - val_recall_at_10: 0.5273 - val_mrr_at_10: 0.1825 - val_ndcg_at_10: 0.2623 - val_map_at_10: 0.1825 - val_precision_at_10: 0.0527 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4086\n",
            "Epoch 14/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.1345 - recall_at_10: 0.5884 - mrr_at_10: 0.2062 - ndcg_at_10: 0.2946 - map_at_10: 0.2062 - precision_at_10: 0.0588 - regularization_loss: 0.0000e+00 - loss_batch: 3.1345 - val_loss: 3.2922 - val_recall_at_10: 0.5308 - val_mrr_at_10: 0.1832 - val_ndcg_at_10: 0.2636 - val_map_at_10: 0.1832 - val_precision_at_10: 0.0531 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4487\n",
            "Epoch 15/20\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 3.1323 - recall_at_10: 0.5848 - mrr_at_10: 0.2082 - ndcg_at_10: 0.2954 - map_at_10: 0.2082 - precision_at_10: 0.0585 - regularization_loss: 0.0000e+00 - loss_batch: 3.1323 - val_loss: 3.3689 - val_recall_at_10: 0.5007 - val_mrr_at_10: 0.1730 - val_ndcg_at_10: 0.2487 - val_map_at_10: 0.1730 - val_precision_at_10: 0.0501 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.5103\n",
            "Epoch 16/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.1406 - recall_at_10: 0.5874 - mrr_at_10: 0.2060 - ndcg_at_10: 0.2943 - map_at_10: 0.2060 - precision_at_10: 0.0587 - regularization_loss: 0.0000e+00 - loss_batch: 3.1405 - val_loss: 3.3031 - val_recall_at_10: 0.5118 - val_mrr_at_10: 0.1706 - val_ndcg_at_10: 0.2494 - val_map_at_10: 0.1706 - val_precision_at_10: 0.0512 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4186\n",
            "Epoch 17/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.1313 - recall_at_10: 0.5888 - mrr_at_10: 0.2097 - ndcg_at_10: 0.2975 - map_at_10: 0.2097 - precision_at_10: 0.0589 - regularization_loss: 0.0000e+00 - loss_batch: 3.1313 - val_loss: 3.2410 - val_recall_at_10: 0.5278 - val_mrr_at_10: 0.1876 - val_ndcg_at_10: 0.2664 - val_map_at_10: 0.1876 - val_precision_at_10: 0.0528 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.5070\n",
            "Epoch 18/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.1261 - recall_at_10: 0.5916 - mrr_at_10: 0.2097 - ndcg_at_10: 0.2981 - map_at_10: 0.2097 - precision_at_10: 0.0592 - regularization_loss: 0.0000e+00 - loss_batch: 3.1261 - val_loss: 3.3085 - val_recall_at_10: 0.5185 - val_mrr_at_10: 0.1829 - val_ndcg_at_10: 0.2606 - val_map_at_10: 0.1829 - val_precision_at_10: 0.0518 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.5603\n",
            "Epoch 19/20\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 3.1278 - recall_at_10: 0.5896 - mrr_at_10: 0.2084 - ndcg_at_10: 0.2967 - map_at_10: 0.2084 - precision_at_10: 0.0590 - regularization_loss: 0.0000e+00 - loss_batch: 3.1278 - val_loss: 3.2939 - val_recall_at_10: 0.5237 - val_mrr_at_10: 0.1805 - val_ndcg_at_10: 0.2599 - val_map_at_10: 0.1805 - val_precision_at_10: 0.0524 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3914\n",
            "Epoch 20/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.1497 - recall_at_10: 0.5838 - mrr_at_10: 0.2085 - ndcg_at_10: 0.2954 - map_at_10: 0.2085 - precision_at_10: 0.0584 - regularization_loss: 0.0000e+00 - loss_batch: 3.1497 - val_loss: 3.2820 - val_recall_at_10: 0.5199 - val_mrr_at_10: 0.1808 - val_ndcg_at_10: 0.2592 - val_map_at_10: 0.1808 - val_precision_at_10: 0.0520 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922cc2e0b50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v6"
      ],
      "metadata": {
        "id": "heByYzLh1zKK"
      },
      "id": "heByYzLh1zKK"
    },
    {
      "cell_type": "code",
      "source": [
        "model_v6 = build_towers(tower_dim=256)"
      ],
      "metadata": {
        "id": "-MxJuPQ8q2O3"
      },
      "id": "-MxJuPQ8q2O3",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOK_K = 10\n",
        "model_v6.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                 run_eagerly=False, metrics=[mm.TopKMetricsAggregator.default_metrics(top_ks=TOP_K)])\n",
        "model_v6.fit(train, validation_data=valid, batch_size=32, epochs=20)"
      ],
      "metadata": {
        "id": "cTQ0riMfxWhY",
        "outputId": "b536ab97-595e-4a06-8eb4-57381d0af820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cTQ0riMfxWhY",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2194/2194 [==============================] - 64s 26ms/step - loss: 3.4650 - recall_at_10: 0.3208 - mrr_at_10: 0.0946 - ndcg_at_10: 0.1462 - map_at_10: 0.0946 - precision_at_10: 0.0321 - regularization_loss: 0.0000e+00 - loss_batch: 3.4648 - val_loss: 3.4638 - val_recall_at_10: 0.3136 - val_mrr_at_10: 0.0923 - val_ndcg_at_10: 0.1429 - val_map_at_10: 0.0923 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2817\n",
            "Epoch 2/20\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 3.4638 - recall_at_10: 0.3138 - mrr_at_10: 0.0926 - ndcg_at_10: 0.1431 - map_at_10: 0.0926 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 3.4637 - val_loss: 3.4637 - val_recall_at_10: 0.3133 - val_mrr_at_10: 0.0922 - val_ndcg_at_10: 0.1427 - val_map_at_10: 0.0922 - val_precision_at_10: 0.0313 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 3/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4638 - recall_at_10: 0.3135 - mrr_at_10: 0.0925 - ndcg_at_10: 0.1430 - map_at_10: 0.0925 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.3134 - val_mrr_at_10: 0.0924 - val_ndcg_at_10: 0.1428 - val_map_at_10: 0.0924 - val_precision_at_10: 0.0313 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 4/20\n",
            "2194/2194 [==============================] - 49s 22ms/step - loss: 3.4637 - recall_at_10: 0.3135 - mrr_at_10: 0.0925 - ndcg_at_10: 0.1429 - map_at_10: 0.0925 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_recall_at_10: 0.3138 - val_mrr_at_10: 0.0923 - val_ndcg_at_10: 0.1429 - val_map_at_10: 0.0923 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 5/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4638 - recall_at_10: 0.3139 - mrr_at_10: 0.0925 - ndcg_at_10: 0.1431 - map_at_10: 0.0925 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.3140 - val_mrr_at_10: 0.0926 - val_ndcg_at_10: 0.1431 - val_map_at_10: 0.0926 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 6/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4637 - recall_at_10: 0.3133 - mrr_at_10: 0.0929 - ndcg_at_10: 0.1432 - map_at_10: 0.0929 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_recall_at_10: 0.3132 - val_mrr_at_10: 0.0924 - val_ndcg_at_10: 0.1428 - val_map_at_10: 0.0924 - val_precision_at_10: 0.0313 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 7/20\n",
            "2194/2194 [==============================] - 50s 23ms/step - loss: 3.4638 - recall_at_10: 0.3134 - mrr_at_10: 0.0928 - ndcg_at_10: 0.1432 - map_at_10: 0.0928 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.3139 - val_mrr_at_10: 0.0926 - val_ndcg_at_10: 0.1431 - val_map_at_10: 0.0926 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 8/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4638 - recall_at_10: 0.3134 - mrr_at_10: 0.0929 - ndcg_at_10: 0.1432 - map_at_10: 0.0929 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_recall_at_10: 0.3138 - val_mrr_at_10: 0.0925 - val_ndcg_at_10: 0.1431 - val_map_at_10: 0.0925 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 9/20\n",
            "2194/2194 [==============================] - 49s 22ms/step - loss: 3.4637 - recall_at_10: 0.3137 - mrr_at_10: 0.0930 - ndcg_at_10: 0.1434 - map_at_10: 0.0930 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.3142 - val_mrr_at_10: 0.0925 - val_ndcg_at_10: 0.1431 - val_map_at_10: 0.0925 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 10/20\n",
            "2194/2194 [==============================] - 49s 22ms/step - loss: 3.4637 - recall_at_10: 0.3140 - mrr_at_10: 0.0933 - ndcg_at_10: 0.1437 - map_at_10: 0.0933 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_recall_at_10: 0.3137 - val_mrr_at_10: 0.0924 - val_ndcg_at_10: 0.1429 - val_map_at_10: 0.0924 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 11/20\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 3.4637 - recall_at_10: 0.3132 - mrr_at_10: 0.0935 - ndcg_at_10: 0.1436 - map_at_10: 0.0935 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_recall_at_10: 0.3139 - val_mrr_at_10: 0.0926 - val_ndcg_at_10: 0.1431 - val_map_at_10: 0.0926 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 12/20\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.4637 - recall_at_10: 0.3138 - mrr_at_10: 0.0931 - ndcg_at_10: 0.1435 - map_at_10: 0.0931 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.3138 - val_mrr_at_10: 0.0927 - val_ndcg_at_10: 0.1432 - val_map_at_10: 0.0927 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 13/20\n",
            "2194/2194 [==============================] - 52s 24ms/step - loss: 3.4637 - recall_at_10: 0.3133 - mrr_at_10: 0.0936 - ndcg_at_10: 0.1438 - map_at_10: 0.0936 - precision_at_10: 0.0313 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_recall_at_10: 0.3135 - val_mrr_at_10: 0.0922 - val_ndcg_at_10: 0.1427 - val_map_at_10: 0.0922 - val_precision_at_10: 0.0313 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 14/20\n",
            "2194/2194 [==============================] - 48s 21ms/step - loss: 3.4637 - recall_at_10: 0.3143 - mrr_at_10: 0.0934 - ndcg_at_10: 0.1438 - map_at_10: 0.0934 - precision_at_10: 0.0314 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_recall_at_10: 0.3214 - val_mrr_at_10: 0.0951 - val_ndcg_at_10: 0.1467 - val_map_at_10: 0.0951 - val_precision_at_10: 0.0321 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 15/20\n",
            "2194/2194 [==============================] - 48s 21ms/step - loss: 3.4637 - recall_at_10: 0.3171 - mrr_at_10: 0.0941 - ndcg_at_10: 0.1450 - map_at_10: 0.0941 - precision_at_10: 0.0317 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4637 - val_recall_at_10: 0.3156 - val_mrr_at_10: 0.0965 - val_ndcg_at_10: 0.1465 - val_map_at_10: 0.0965 - val_precision_at_10: 0.0316 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 16/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4637 - recall_at_10: 0.3245 - mrr_at_10: 0.1024 - ndcg_at_10: 0.1531 - map_at_10: 0.1024 - precision_at_10: 0.0324 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_recall_at_10: 0.2942 - val_mrr_at_10: 0.0777 - val_ndcg_at_10: 0.1270 - val_map_at_10: 0.0777 - val_precision_at_10: 0.0294 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 17/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4637 - recall_at_10: 0.3354 - mrr_at_10: 0.1162 - ndcg_at_10: 0.1662 - map_at_10: 0.1162 - precision_at_10: 0.0335 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_recall_at_10: 0.3973 - val_mrr_at_10: 0.1797 - val_ndcg_at_10: 0.2294 - val_map_at_10: 0.1797 - val_precision_at_10: 0.0397 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 18/20\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4637 - recall_at_10: 0.3811 - mrr_at_10: 0.1788 - ndcg_at_10: 0.2246 - map_at_10: 0.1788 - precision_at_10: 0.0381 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_recall_at_10: 0.5767 - val_mrr_at_10: 0.3212 - val_ndcg_at_10: 0.3767 - val_map_at_10: 0.3212 - val_precision_at_10: 0.0577 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 19/20\n",
            "2194/2194 [==============================] - 46s 21ms/step - loss: 3.4637 - recall_at_10: 0.5818 - mrr_at_10: 0.4151 - ndcg_at_10: 0.4513 - map_at_10: 0.4151 - precision_at_10: 0.0582 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_recall_at_10: 0.5286 - val_mrr_at_10: 0.5249 - val_ndcg_at_10: 0.5257 - val_map_at_10: 0.5249 - val_precision_at_10: 0.0529 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 20/20\n",
            "2194/2194 [==============================] - 54s 25ms/step - loss: 3.4637 - recall_at_10: 0.6261 - mrr_at_10: 0.5231 - ndcg_at_10: 0.5489 - map_at_10: 0.5231 - precision_at_10: 0.0626 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_recall_at_10: 0.0468 - val_mrr_at_10: 0.0242 - val_ndcg_at_10: 0.0299 - val_map_at_10: 0.0242 - val_precision_at_10: 0.0047 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922cd119690>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v6.fit(train, validation_data=valid, batch_size=32, epochs=30, initial_epoch=20)"
      ],
      "metadata": {
        "id": "yB0EiZyMCQiB",
        "outputId": "9cd9efe0-8e78-4e2a-8924-1afc4d0f88e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yB0EiZyMCQiB",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30\n",
            "2194/2194 [==============================] - 50s 22ms/step - loss: 3.4637 - recall_at_10: 0.7700 - mrr_at_10: 0.5500 - ndcg_at_10: 0.6052 - map_at_10: 0.5500 - precision_at_10: 0.0770 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.0449 - val_mrr_at_10: 0.0237 - val_ndcg_at_10: 0.0290 - val_map_at_10: 0.0237 - val_precision_at_10: 0.0045 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 22/30\n",
            "2194/2194 [==============================] - 49s 22ms/step - loss: 3.4638 - recall_at_10: 0.7736 - mrr_at_10: 0.5556 - ndcg_at_10: 0.6104 - map_at_10: 0.5556 - precision_at_10: 0.0774 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4638 - val_recall_at_10: 1.0000 - val_mrr_at_10: 0.5492 - val_ndcg_at_10: 0.6623 - val_map_at_10: 0.5492 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 23/30\n",
            "2194/2194 [==============================] - 46s 21ms/step - loss: 3.4638 - recall_at_10: 0.7684 - mrr_at_10: 0.5568 - ndcg_at_10: 0.6099 - map_at_10: 0.5568 - precision_at_10: 0.0768 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_recall_at_10: 1.0000 - val_mrr_at_10: 0.5494 - val_ndcg_at_10: 0.6625 - val_map_at_10: 0.5494 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 24/30\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 3.4637 - recall_at_10: 0.8048 - mrr_at_10: 0.5569 - ndcg_at_10: 0.6191 - map_at_10: 0.5569 - precision_at_10: 0.0805 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_map_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 25/30\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4637 - recall_at_10: 0.8086 - mrr_at_10: 0.5849 - ndcg_at_10: 0.6411 - map_at_10: 0.5849 - precision_at_10: 0.0809 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_recall_at_10: 1.0000 - val_mrr_at_10: 0.5467 - val_ndcg_at_10: 0.6604 - val_map_at_10: 0.5467 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 26/30\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4638 - recall_at_10: 0.7781 - mrr_at_10: 0.5419 - ndcg_at_10: 0.6011 - map_at_10: 0.5419 - precision_at_10: 0.0778 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 1.0000 - val_mrr_at_10: 0.5518 - val_ndcg_at_10: 0.6643 - val_map_at_10: 0.5518 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 27/30\n",
            "2194/2194 [==============================] - 52s 23ms/step - loss: 3.4637 - recall_at_10: 0.8098 - mrr_at_10: 0.5494 - ndcg_at_10: 0.6148 - map_at_10: 0.5494 - precision_at_10: 0.0810 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_map_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 28/30\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 3.4637 - recall_at_10: 0.7826 - mrr_at_10: 0.5412 - ndcg_at_10: 0.6018 - map_at_10: 0.5412 - precision_at_10: 0.0783 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_recall_at_10: 0.0463 - val_mrr_at_10: 0.0245 - val_ndcg_at_10: 0.0300 - val_map_at_10: 0.0245 - val_precision_at_10: 0.0046 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 29/30\n",
            "2194/2194 [==============================] - 52s 23ms/step - loss: 3.4638 - recall_at_10: 0.7358 - mrr_at_10: 0.5267 - ndcg_at_10: 0.5791 - map_at_10: 0.5267 - precision_at_10: 0.0736 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4634 - val_recall_at_10: 1.0000 - val_mrr_at_10: 0.5453 - val_ndcg_at_10: 0.6594 - val_map_at_10: 0.5453 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 30/30\n",
            "2194/2194 [==============================] - 47s 21ms/step - loss: 3.4637 - recall_at_10: 0.7435 - mrr_at_10: 0.5217 - ndcg_at_10: 0.5773 - map_at_10: 0.5217 - precision_at_10: 0.0743 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4634 - val_recall_at_10: 1.0000 - val_mrr_at_10: 0.9998 - val_ndcg_at_10: 0.9999 - val_map_at_10: 0.9998 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922d83d7d90>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_v7"
      ],
      "metadata": {
        "id": "u2fymk2KAY5N"
      },
      "id": "u2fymk2KAY5N"
    },
    {
      "cell_type": "code",
      "source": [
        "model_v7 = build_towers(tower_dim=256)"
      ],
      "metadata": {
        "id": "awb-YpebxWjp"
      },
      "id": "awb-YpebxWjp",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v7.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-2),\n",
        "                 run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10), tf.keras.metrics.AUC(), mm.MRRAt(10), mm.PrecisionAt(10)])\n",
        "model_v7.fit(train, validation_data=valid, batch_size=32, epochs=20)"
      ],
      "metadata": {
        "id": "L73TlUUpxWmA",
        "outputId": "e9ea25fe-4e2b-42c1-f0fb-0a86dafc5610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L73TlUUpxWmA",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2194/2194 [==============================] - 57s 23ms/step - loss: 3.7826 - auc_14: 0.5041 - recall_at_10: 0.4627 - ndcg_at_10: 0.3637 - mrr_at_10: 0.3345 - precision_at_10: 0.0463 - regularization_loss: 0.0000e+00 - loss_batch: 3.7823 - val_loss: 3.4636 - val_auc_14: 0.5028 - val_recall_at_10: 0.1396 - val_ndcg_at_10: 0.1372 - val_mrr_at_10: 0.1364 - val_precision_at_10: 0.0140 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 2/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4637 - auc_14: 0.5026 - recall_at_10: 0.6896 - ndcg_at_10: 0.6859 - mrr_at_10: 0.6846 - precision_at_10: 0.0690 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_auc_14: 0.5023 - val_recall_at_10: 0.9311 - val_ndcg_at_10: 0.9306 - val_mrr_at_10: 0.9304 - val_precision_at_10: 0.0931 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 3/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4638 - auc_14: 0.5017 - recall_at_10: 0.7482 - ndcg_at_10: 0.7475 - mrr_at_10: 0.7472 - precision_at_10: 0.0748 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_auc_14: 0.5025 - val_recall_at_10: 0.9360 - val_ndcg_at_10: 0.9349 - val_mrr_at_10: 0.9346 - val_precision_at_10: 0.0936 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 4/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4637 - auc_14: 0.5024 - recall_at_10: 0.7335 - ndcg_at_10: 0.7331 - mrr_at_10: 0.7329 - precision_at_10: 0.0733 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_auc_14: 0.5023 - val_recall_at_10: 0.9421 - val_ndcg_at_10: 0.9421 - val_mrr_at_10: 0.9421 - val_precision_at_10: 0.0942 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 5/20\n",
            "2194/2194 [==============================] - 43s 19ms/step - loss: 3.4637 - auc_14: 0.5022 - recall_at_10: 0.7090 - ndcg_at_10: 0.7089 - mrr_at_10: 0.7088 - precision_at_10: 0.0709 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_auc_14: 0.5023 - val_recall_at_10: 0.1117 - val_ndcg_at_10: 0.1117 - val_mrr_at_10: 0.1117 - val_precision_at_10: 0.0112 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 6/20\n",
            "2194/2194 [==============================] - 46s 21ms/step - loss: 3.4637 - auc_14: 0.5022 - recall_at_10: 0.7216 - ndcg_at_10: 0.7216 - mrr_at_10: 0.7215 - precision_at_10: 0.0722 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_auc_14: 0.5023 - val_recall_at_10: 0.9547 - val_ndcg_at_10: 0.9543 - val_mrr_at_10: 0.9542 - val_precision_at_10: 0.0955 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 7/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4637 - auc_14: 0.5022 - recall_at_10: 0.7398 - ndcg_at_10: 0.7398 - mrr_at_10: 0.7398 - precision_at_10: 0.0740 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_auc_14: 0.5023 - val_recall_at_10: 0.9549 - val_ndcg_at_10: 0.9547 - val_mrr_at_10: 0.9546 - val_precision_at_10: 0.0955 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 8/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4648 - auc_14: 0.5096 - recall_at_10: 0.7241 - ndcg_at_10: 0.7239 - mrr_at_10: 0.7238 - precision_at_10: 0.0724 - regularization_loss: 0.0000e+00 - loss_batch: 3.4646 - val_loss: 3.4635 - val_auc_14: 0.5164 - val_recall_at_10: 0.1810 - val_ndcg_at_10: 0.1810 - val_mrr_at_10: 0.1810 - val_precision_at_10: 0.0181 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 9/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4649 - auc_14: 0.5166 - recall_at_10: 0.7333 - ndcg_at_10: 0.7333 - mrr_at_10: 0.7333 - precision_at_10: 0.0733 - regularization_loss: 0.0000e+00 - loss_batch: 3.4648 - val_loss: 3.4636 - val_auc_14: 0.5163 - val_recall_at_10: 0.0078 - val_ndcg_at_10: 0.0078 - val_mrr_at_10: 0.0078 - val_precision_at_10: 7.8240e-04 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2814\n",
            "Epoch 10/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7353 - ndcg_at_10: 0.7353 - mrr_at_10: 0.7353 - precision_at_10: 0.0735 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_auc_14: 0.5163 - val_recall_at_10: 0.9964 - val_ndcg_at_10: 0.9959 - val_mrr_at_10: 0.9958 - val_precision_at_10: 0.0996 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2818\n",
            "Epoch 11/20\n",
            "2194/2194 [==============================] - 43s 19ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.6754 - ndcg_at_10: 0.6754 - mrr_at_10: 0.6754 - precision_at_10: 0.0675 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4634 - val_auc_14: 0.5163 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 12/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7125 - ndcg_at_10: 0.7125 - mrr_at_10: 0.7125 - precision_at_10: 0.0713 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4637 - val_auc_14: 0.5163 - val_recall_at_10: 6.6872e-04 - val_ndcg_at_10: 6.6872e-04 - val_mrr_at_10: 6.6872e-04 - val_precision_at_10: 6.6872e-05 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 13/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.6754 - ndcg_at_10: 0.6754 - mrr_at_10: 0.6754 - precision_at_10: 0.0675 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4637 - val_auc_14: 0.5163 - val_recall_at_10: 6.6872e-04 - val_ndcg_at_10: 6.6872e-04 - val_mrr_at_10: 6.6872e-04 - val_precision_at_10: 6.6872e-05 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 14/20\n",
            "2194/2194 [==============================] - 44s 20ms/step - loss: 3.4636 - auc_14: 0.5166 - recall_at_10: 0.7077 - ndcg_at_10: 0.7077 - mrr_at_10: 0.7077 - precision_at_10: 0.0708 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_auc_14: 0.5163 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 0.9995 - val_mrr_at_10: 0.9994 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2816\n",
            "Epoch 15/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7491 - ndcg_at_10: 0.7491 - mrr_at_10: 0.7491 - precision_at_10: 0.0749 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4636 - val_auc_14: 0.5163 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 16/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7502 - ndcg_at_10: 0.7502 - mrr_at_10: 0.7502 - precision_at_10: 0.0750 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4635 - val_auc_14: 0.5163 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2814\n",
            "Epoch 17/20\n",
            "2194/2194 [==============================] - 48s 22ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7789 - ndcg_at_10: 0.7789 - mrr_at_10: 0.7789 - precision_at_10: 0.0779 - regularization_loss: 0.0000e+00 - loss_batch: 3.4635 - val_loss: 3.4634 - val_auc_14: 0.5163 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n",
            "Epoch 18/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7685 - ndcg_at_10: 0.7685 - mrr_at_10: 0.7685 - precision_at_10: 0.0768 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_auc_14: 0.5163 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2814\n",
            "Epoch 19/20\n",
            "2194/2194 [==============================] - 43s 19ms/step - loss: 3.4637 - auc_14: 0.5166 - recall_at_10: 0.7791 - ndcg_at_10: 0.7791 - mrr_at_10: 0.7791 - precision_at_10: 0.0779 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4635 - val_auc_14: 0.5164 - val_recall_at_10: 1.0000 - val_ndcg_at_10: 1.0000 - val_mrr_at_10: 1.0000 - val_precision_at_10: 0.1000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2814\n",
            "Epoch 20/20\n",
            "2194/2194 [==============================] - 45s 20ms/step - loss: 3.4638 - auc_14: 0.5166 - recall_at_10: 0.7500 - ndcg_at_10: 0.7500 - mrr_at_10: 0.7500 - precision_at_10: 0.0750 - regularization_loss: 0.0000e+00 - loss_batch: 3.4636 - val_loss: 3.4636 - val_auc_14: 0.5163 - val_recall_at_10: 6.6872e-04 - val_ndcg_at_10: 6.6872e-04 - val_mrr_at_10: 6.6872e-04 - val_precision_at_10: 6.6872e-05 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.2815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d44516a7340>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v7.predict()"
      ],
      "metadata": {
        "id": "MyAC5ep1GUkt"
      },
      "id": "MyAC5ep1GUkt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_v7 = model_v7.batch_predict(valid, batch_size=128)"
      ],
      "metadata": {
        "id": "WXb0J-h5xWpN",
        "outputId": "263eb033-5ca5-4c66-8878-99e013e9b1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "WXb0J-h5xWpN",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as model_context_14_layer_call_fn, model_context_14_layer_call_and_return_conditional_losses, prepare_list_features_44_layer_call_fn, prepare_list_features_44_layer_call_and_return_conditional_losses, dot_product_14_layer_call_fn while saving (showing 5 of 56). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6855\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_numeric_only_deprecation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6856\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, df, filter_input_columns, filter_output_columns)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Iterate over batches of df and collect predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Iterate over batches of df and collect predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\u001b[0m in \u001b[0;36mmodel_encode\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, targets, training, testing, output_context)\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\u001b[0m in \u001b[0;36m_call_child\u001b[0;34m(self, child, inputs, context)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\u001b[0m in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# This will call the `call` method implemented by the super class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_filter_layer_inputs_using_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, targets, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         return combinators.call_sequentially(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall_sequentially\u001b[0;34m(layers, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\u001b[0m in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# This will call the `call` method implemented by the super class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_filter_layer_inputs_using_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\u001b[0m in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# This will call the `call` method implemented by the super class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_filter_layer_inputs_using_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\u001b[0m in \u001b[0;36m_call_table\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_combiner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer 'genres' (type Embedding).\n\n{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to int32 is not supported [Op:Cast]\n\nCall arguments received by layer 'genres' (type Embedding):\n  • inputs=tf.Tensor(shape=(2,), dtype=string)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e277f25a5723>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_v7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_v7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\u001b[0m in \u001b[0;36mbatch_predict\u001b[0;34m(self, dataset, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0mmodel_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFModelEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerlin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \"\"\"\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minsert_meta_param_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6924\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6926\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_meta_map_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6927\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6928\u001b[0m         layer = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_get_meta_map_partitions\u001b[0;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[1;32m   7035\u001b[0m         \u001b[0;31m# Use non-normalized kwargs here, as we want the real values (not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7036\u001b[0m         \u001b[0;31m# delayed values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7037\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_emulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7038\u001b[0m         \u001b[0mmeta_is_emulated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7039\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6853\u001b[0m     \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6854\u001b[0m     \"\"\"\n\u001b[0;32m-> 6855\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_numeric_only_deprecation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6856\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" in `{funcname}`\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `<merlin.models.tf.utils.batch_utils.TFModelEncode `.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nUnimplementedError()\n\nTraceback:\n---------\n  File \"/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\", line 6856, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\", line 51, in __call__\n    outputs = concat_func([encode_func(self.model, batch) for batch in iterator_func(df)])\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\", line 51, in <listcomp>\n    outputs = concat_func([encode_func(self.model, batch) for batch in iterator_func(df)])\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\", line 155, in model_encode\n    model_outputs = model(batch[0])\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\", line 1763, in call\n    outputs, context = self._call_child(block, outputs, context)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\", line 1792, in _call_child\n    outputs = call_layer(child, inputs, **call_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\", line 480, in _tabular_call\n    outputs = self.super().__call__(inputs, *args, **kwargs)  # type: ignore\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 566, in call\n    out = call_layer(layer, layer_inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\", line 189, in __call__\n    return super().__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\", line 173, in call\n    return combinators.call_sequentially(\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 840, in call_sequentially\n    outputs = call_layer(layer, outputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\", line 480, in _tabular_call\n    outputs = self.super().__call__(inputs, *args, **kwargs)  # type: ignore\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 566, in call\n    out = call_layer(layer, layer_inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\", line 480, in _tabular_call\n    outputs = self.super().__call__(inputs, *args, **kwargs)  # type: ignore\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 566, in call\n    out = call_layer(layer, layer_inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\", line 390, in call\n    out[feature_name] = self._call_table(inputs[feature_name], **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\", line 425, in _call_table\n    out = call_layer(self.table, inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QYZS_meGq2RK"
      },
      "id": "QYZS_meGq2RK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v3 = build_towers()"
      ],
      "metadata": {
        "id": "vOfMO-SwFGYp"
      },
      "id": "vOfMO-SwFGYp",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_recommenders as tfrs\n",
        "topk_metric = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=tf.data.Dataset.from_tensor_slices(train.to_ddf().compute()['movie_id'].unique())\n",
        ")\n",
        "# hack\n",
        "setattr(topk_metric, 'reset_state', topk_metric.reset_states)"
      ],
      "metadata": {
        "id": "-bd8ZYXL9CWA"
      },
      "id": "-bd8ZYXL9CWA",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "model_v3.compile(optimizer=opt, run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10),\n",
        "                                                            tf.keras.metrics.AUC(), mm.MRRAt(10),\n",
        "                                                            topk_metric\n",
        "                                                            ])\n",
        "history = model_v3.fit(train, validation_data=valid, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "id": "-4fPoJvhFI6J",
        "outputId": "23191fd8-05f4-40e3-d6f1-9fe77830dd40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-4fPoJvhFI6J",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2194/2194 [==============================] - 62s 26ms/step - loss: 3.4275 - auc_8: 0.5490 - factorized_top_k: 0.0303 - recall_at_10: 0.3520 - ndcg_at_10: 0.1636 - mrr_at_10: 0.1077 - regularization_loss: 0.0000e+00 - loss_batch: 3.4274 - val_loss: 3.4139 - val_auc_8: 0.5758 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4113 - val_ndcg_at_10: 0.1926 - val_mrr_at_10: 0.1274 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3728\n",
            "Epoch 2/10\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.3574 - auc_8: 0.5811 - factorized_top_k: 0.0303 - recall_at_10: 0.4486 - ndcg_at_10: 0.2135 - mrr_at_10: 0.1433 - regularization_loss: 0.0000e+00 - loss_batch: 3.3572 - val_loss: 3.3950 - val_auc_8: 0.5729 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4260 - val_ndcg_at_10: 0.2004 - val_mrr_at_10: 0.1331 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4693\n",
            "Epoch 3/10\n",
            "2194/2194 [==============================] - 50s 23ms/step - loss: 3.3413 - auc_8: 0.5860 - factorized_top_k: 0.0303 - recall_at_10: 0.4683 - ndcg_at_10: 0.2250 - mrr_at_10: 0.1523 - regularization_loss: 0.0000e+00 - loss_batch: 3.3412 - val_loss: 3.3844 - val_auc_8: 0.5407 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.3967 - val_ndcg_at_10: 0.1881 - val_mrr_at_10: 0.1260 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.5383\n",
            "Epoch 4/10\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.3529 - auc_8: 0.5305 - factorized_top_k: 0.0303 - recall_at_10: 0.4447 - ndcg_at_10: 0.2109 - mrr_at_10: 0.1411 - regularization_loss: 0.0000e+00 - loss_batch: 3.3527 - val_loss: 3.3642 - val_auc_8: 0.5614 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4469 - val_ndcg_at_10: 0.2054 - val_mrr_at_10: 0.1337 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.6680\n",
            "Epoch 5/10\n",
            "2194/2194 [==============================] - 52s 23ms/step - loss: 3.3042 - auc_8: 0.5363 - factorized_top_k: 0.0303 - recall_at_10: 0.4557 - ndcg_at_10: 0.2169 - mrr_at_10: 0.1456 - regularization_loss: 0.0000e+00 - loss_batch: 3.3041 - val_loss: 3.3514 - val_auc_8: 0.5560 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4547 - val_ndcg_at_10: 0.2165 - val_mrr_at_10: 0.1455 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.6412\n",
            "Epoch 6/10\n",
            "2194/2194 [==============================] - 56s 25ms/step - loss: 3.2943 - auc_8: 0.5378 - factorized_top_k: 0.0303 - recall_at_10: 0.4639 - ndcg_at_10: 0.2207 - mrr_at_10: 0.1481 - regularization_loss: 0.0000e+00 - loss_batch: 3.2942 - val_loss: 3.3640 - val_auc_8: 0.5522 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4556 - val_ndcg_at_10: 0.2154 - val_mrr_at_10: 0.1441 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.5606\n",
            "Epoch 7/10\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 3.2748 - auc_8: 0.5872 - factorized_top_k: 0.0303 - recall_at_10: 0.4770 - ndcg_at_10: 0.2253 - mrr_at_10: 0.1503 - regularization_loss: 0.0000e+00 - loss_batch: 3.2747 - val_loss: 3.3480 - val_auc_8: 0.5988 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4644 - val_ndcg_at_10: 0.2170 - val_mrr_at_10: 0.1433 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.6285\n",
            "Epoch 8/10\n",
            "2194/2194 [==============================] - 50s 22ms/step - loss: 3.2668 - auc_8: 0.5836 - factorized_top_k: 0.0303 - recall_at_10: 0.4792 - ndcg_at_10: 0.2259 - mrr_at_10: 0.1505 - regularization_loss: 0.0000e+00 - loss_batch: 3.2667 - val_loss: 3.3461 - val_auc_8: 0.6019 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4598 - val_ndcg_at_10: 0.2173 - val_mrr_at_10: 0.1451 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.4492\n",
            "Epoch 9/10\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.2570 - auc_8: 0.6048 - factorized_top_k: 0.0303 - recall_at_10: 0.4790 - ndcg_at_10: 0.2249 - mrr_at_10: 0.1492 - regularization_loss: 0.0000e+00 - loss_batch: 3.2569 - val_loss: 3.3479 - val_auc_8: 0.6203 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4478 - val_ndcg_at_10: 0.2118 - val_mrr_at_10: 0.1414 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3645\n",
            "Epoch 10/10\n",
            "2194/2194 [==============================] - 52s 24ms/step - loss: 3.2512 - auc_8: 0.6538 - factorized_top_k: 0.0303 - recall_at_10: 0.4801 - ndcg_at_10: 0.2256 - mrr_at_10: 0.1499 - regularization_loss: 0.0000e+00 - loss_batch: 3.2511 - val_loss: 3.3163 - val_auc_8: 0.6405 - val_factorized_top_k: 0.0303 - val_recall_at_10: 0.4553 - val_ndcg_at_10: 0.2154 - val_mrr_at_10: 0.1438 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 2.3695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model top-k results"
      ],
      "metadata": {
        "id": "7QqObQklQe_m"
      },
      "id": "7QqObQklQe_m"
    },
    {
      "cell_type": "code",
      "source": [
        "from mm.metrics.topk.\n"
      ],
      "metadata": {
        "id": "ugGvNfwgIo2X",
        "outputId": "4f2c6eee-8a13-4dcb-db7a-4fc331c1f33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "id": "ugGvNfwgIo2X",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-fbc57fa26d40>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmerlin_standard_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFactorizedTopK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'FactorizedTopK' from 'merlin_standard_lib' (/usr/local/lib/python3.10/dist-packages/merlin_standard_lib/__init__.py)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-K evaluation\n",
        "from merlin.models.utils.dataset import unique_rows_by_features\n",
        "\n",
        "candidate_features = unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID)\n",
        "candidate_features.head()"
      ],
      "metadata": {
        "id": "KYBU3kGmQiMl",
        "outputId": "38a50f66-a3ef-4268-e08b-019531b9d77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "id": "KYBU3kGmQiMl",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/merlin/io/dataset.py:264: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movie_id         genres\n",
              "0         9    [14, 2, 10]\n",
              "1       231  [7, 2, 17, 5]\n",
              "2       544            [9]\n",
              "3       484         [1, 4]\n",
              "4        10      [1, 9, 3]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fe26a0cf-586c-4c56-9900-eff89141ca75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>[14, 2, 10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>231</td>\n",
              "      <td>[7, 2, 17, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>544</td>\n",
              "      <td>[9]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>484</td>\n",
              "      <td>[1, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>[1, 9, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe26a0cf-586c-4c56-9900-eff89141ca75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-79a74262-5516-406f-ab3e-983307d44fd3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79a74262-5516-406f-ab3e-983307d44fd3')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-79a74262-5516-406f-ab3e-983307d44fd3 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe26a0cf-586c-4c56-9900-eff89141ca75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe26a0cf-586c-4c56-9900-eff89141ca75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_features.to_ddf()['genres'][0].compute().values"
      ],
      "metadata": {
        "id": "UwE0I50kIFa4",
        "outputId": "a5d26382-11c5-4fb9-c91b-cc787b219a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UwE0I50kIFa4",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array([14,  2, 10])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk = 20\n",
        "topk_model = model.to_top_k_encoder(candidate_features, k=topk, batch_size=128)\n",
        "\n",
        "# we can set `metrics` param in the `compile(), if we want\n",
        "topk_model.compile(run_eagerly=False)"
      ],
      "metadata": {
        "id": "_fML1HOwQvkD",
        "outputId": "0a32b0b9-a6a7-45d0-ba48-4c81bb619d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "_fML1HOwQvkD",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as prepare_list_features_1_layer_call_fn, prepare_list_features_1_layer_call_and_return_conditional_losses, model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, concat_features_1_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/io/dataset.py:264: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6855\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_numeric_only_deprecation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6856\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, df, filter_input_columns, filter_output_columns)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Iterate over batches of df and collect predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Iterate over batches of df and collect predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\u001b[0m in \u001b[0;36mmodel_encode\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, targets, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         return combinators.call_sequentially(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall_sequentially\u001b[0;34m(layers, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\u001b[0m in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# This will call the `call` method implemented by the super class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_filter_layer_inputs_using_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\u001b[0m in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# This will call the `call` method implemented by the super class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_filter_layer_inputs_using_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\u001b[0m in \u001b[0;36m_call_table\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_combiner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\u001b[0m in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfiltered_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer 'genres' (type Embedding).\n\n{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to int32 is not supported [Op:Cast]\n\nCall arguments received by layer 'genres' (type Embedding):\n  • inputs=tf.Tensor(shape=(2,), dtype=string)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-5554053d4147>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopk_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_top_k_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# we can set `metrics` param in the `compile(), if we want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtopk_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\u001b[0m in \u001b[0;36mto_top_k_encoder\u001b[0;34m(self, candidates, candidate_id, strategy, k, **kwargs)\u001b[0m\n\u001b[1;32m   2497\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mbrute\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \"\"\"\n\u001b[0;32m-> 2499\u001b[0;31m         \u001b[0mcandidates_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcandidate_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m         topk_model = TopKEncoder(\n\u001b[1;32m   2501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py\u001b[0m in \u001b[0;36mcandidate_embeddings\u001b[0;34m(self, dataset, index, **kwargs)\u001b[0m\n\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2390\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, dataset, index, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid index: {index}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         return self.batch_predict(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\u001b[0m in \u001b[0;36mbatch_predict\u001b[0;34m(self, dataset, batch_size, output_schema, index, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_schema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mencode_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filter_input_columns\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mencode_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \"\"\"\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minsert_meta_param_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6924\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6926\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_meta_map_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6927\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6928\u001b[0m         layer = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_get_meta_map_partitions\u001b[0;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[1;32m   7035\u001b[0m         \u001b[0;31m# Use non-normalized kwargs here, as we want the real values (not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7036\u001b[0m         \u001b[0;31m# delayed values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7037\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_emulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7038\u001b[0m         \u001b[0mmeta_is_emulated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7039\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6853\u001b[0m     \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6854\u001b[0m     \"\"\"\n\u001b[0;32m-> 6855\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_numeric_only_deprecation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6856\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" in `{funcname}`\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `<merlin.models.tf.utils.batch_utils.TFModelEncode `.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nUnimplementedError()\n\nTraceback:\n---------\n  File \"/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py\", line 6856, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\", line 51, in __call__\n    outputs = concat_func([encode_func(self.model, batch) for batch in iterator_func(df)])\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\", line 51, in <listcomp>\n    outputs = concat_func([encode_func(self.model, batch) for batch in iterator_func(df)])\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py\", line 155, in model_encode\n    model_outputs = model(batch[0])\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\", line 189, in __call__\n    return super().__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py\", line 173, in call\n    return combinators.call_sequentially(\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 840, in call_sequentially\n    outputs = call_layer(layer, outputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\", line 480, in _tabular_call\n    outputs = self.super().__call__(inputs, *args, **kwargs)  # type: ignore\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 566, in call\n    out = call_layer(layer, layer_inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/tabular.py\", line 480, in _tabular_call\n    outputs = self.super().__call__(inputs, *args, **kwargs)  # type: ignore\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/combinators.py\", line 566, in call\n    out = call_layer(layer, layer_inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/config/schema.py\", line 58, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\", line 390, in call\n    out[feature_name] = self._call_table(inputs[feature_name], **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/inputs/embedding.py\", line 425, in _call_table\n    out = call_layer(self.table, inputs, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/tf_utils.py\", line 449, in call_layer\n    return layer(inputs, *args, **filtered_kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TMP"
      ],
      "metadata": {
        "id": "SOkzkLd-Qjkk"
      },
      "id": "SOkzkLd-Qjkk"
    },
    {
      "cell_type": "code",
      "source": [
        "# model = mm.DLRMModel(\n",
        "#     train.schema,\n",
        "#     embedding_dim=64,\n",
        "#     bottom_block=mm.MLPBlock([128, 64]),\n",
        "#     top_block=mm.MLPBlock([128, 64, 32]),\n",
        "#     prediction_tasks=mm.BinaryOutput(\n",
        "#         train.schema.select_by_tag(Tags.TARGET).column_names[0]\n",
        "#     ),\n",
        "# )\n",
        "# model.compile(optimizer=\"adam\")\n",
        "# model.fit(train, batch_size=1024)"
      ],
      "metadata": {
        "id": "ybqJ0w08ubHQ"
      },
      "id": "ybqJ0w08ubHQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema"
      ],
      "metadata": {
        "id": "6B314gNRiJ16",
        "outputId": "c3881ef5-8d94-4da6-ad91-5dd8cade6097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "id": "6B314gNRiJ16",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'movie_id', 'tags': {<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'embedding_sizes': {'cardinality': 1665.0, 'dimension': 102.0}, 'cat_path': './/categories/unique.movie_id.parquet', 'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'domain': {'min': 0, 'max': 1664, 'name': 'movie_id'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_id', 'tags': {<Tags.ID: 'id'>, <Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'start_index': 0.0, 'cat_path': './/categories/unique.user_id.parquet', 'freq_threshold': 0.0, 'num_buckets': None, 'max_size': 0.0, 'embedding_sizes': {'cardinality': 944.0, 'dimension': 74.0}, 'domain': {'min': 0, 'max': 943, 'name': 'user_id'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'gender', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'start_index': 0.0, 'cat_path': './/categories/unique.gender.parquet', 'max_size': 0.0, 'embedding_sizes': {'cardinality': 3.0, 'dimension': 16.0}, 'num_buckets': None, 'freq_threshold': 0.0, 'domain': {'min': 0, 'max': 2, 'name': 'gender'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'occupation', 'tags': {<Tags.USER: 'user'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'start_index': 0.0, 'max_size': 0.0, 'freq_threshold': 0.0, 'embedding_sizes': {'cardinality': 22.0, 'dimension': 16.0}, 'num_buckets': None, 'cat_path': './/categories/unique.occupation.parquet', 'domain': {'min': 0, 'max': 21, 'name': 'occupation'}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'genres', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'freq_threshold': 0.0, 'cat_path': './/categories/unique.genres.parquet', 'embedding_sizes': {'dimension': 16.0, 'cardinality': 20.0}, 'num_buckets': None, 'start_index': 0.0, 'max_size': 0.0, 'domain': {'min': 0, 'max': 19, 'name': 'genres'}, 'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}, {'name': 'rating', 'tags': {<Tags.TARGET: 'target'>, <Tags.BINARY_CLASSIFICATION: 'binary_classification'>}, 'properties': {}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>dtype</th>\n",
              "      <th>is_list</th>\n",
              "      <th>is_ragged</th>\n",
              "      <th>properties.embedding_sizes.cardinality</th>\n",
              "      <th>properties.embedding_sizes.dimension</th>\n",
              "      <th>properties.cat_path</th>\n",
              "      <th>properties.num_buckets</th>\n",
              "      <th>properties.freq_threshold</th>\n",
              "      <th>properties.max_size</th>\n",
              "      <th>properties.start_index</th>\n",
              "      <th>properties.domain.min</th>\n",
              "      <th>properties.domain.max</th>\n",
              "      <th>properties.domain.name</th>\n",
              "      <th>properties.value_count.min</th>\n",
              "      <th>properties.value_count.max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie_id</td>\n",
              "      <td>(Tags.ID, Tags.ITEM, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1665.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>.//categories/unique.movie_id.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1664.0</td>\n",
              "      <td>movie_id</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user_id</td>\n",
              "      <td>(Tags.ID, Tags.USER, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>944.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>.//categories/unique.user_id.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>943.0</td>\n",
              "      <td>user_id</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gender</td>\n",
              "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>.//categories/unique.gender.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>gender</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>occupation</td>\n",
              "      <td>(Tags.USER, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>.//categories/unique.occupation.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>occupation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>genres</td>\n",
              "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
              "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>.//categories/unique.genres.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>genres</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rating</td>\n",
              "      <td>(Tags.TARGET, Tags.BINARY_CLASSIFICATION)</td>\n",
              "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "import tensorflow as tf\n",
        "QUERY_DROPOUT = 0.1\n",
        "ITEM_DROPOUT = 0.1\n",
        "\n",
        "model_v0 = mm.TwoTowerModel(\n",
        "    schema,\n",
        "    query_tower=mm.MLPBlock(\n",
        "        [128,256],\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(3.9e-06),\n",
        "        bias_regularizer=tf.keras.regularizers.l1(3.9e-06),\n",
        "        no_activation_last_layer=True,\n",
        "        # dropout=QUERY_DROPOUT\n",
        "     ),\n",
        "     item_tower=mm.MLPBlock(\n",
        "         [128,256],\n",
        "         kernel_regularizer=tf.keras.regularizers.l1(3.9e-06),\n",
        "         bias_regularizer=tf.keras.regularizers.l1(3.9e-06),\n",
        "         no_activation_last_layer=True,\n",
        "        #  dropout=ITEM_DROPOUT\n",
        "     ),\n",
        "     samplers=[mm.InBatchSampler()] # default value\n",
        ")"
      ],
      "metadata": {
        "id": "7w6hc-sVBRL_"
      },
      "id": "7w6hc-sVBRL_",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_K = [10]\n",
        "\n",
        "model_v0.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "    run_eagerly=False,\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[mm.TopKMetricsAggregator.default_metrics(top_ks=TOP_K),\n",
        "            #  tfr.keras.metrics.MRRMetric(topn=4)\n",
        "             ],\n",
        ")\n",
        "model_v0.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    schema=schema,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    # shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "ykZ3UXvmJIzT",
        "outputId": "107eed05-5bc9-49e7-c698-1559026322e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ykZ3UXvmJIzT",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:merlin_models:The sampler InBatchSampler returned no samples for this batch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2194/2194 [==============================] - ETA: 0s - loss: 4.3563 - recall_at_10: 0.3120 - mrr_at_10: 0.0964 - ndcg_at_10: 0.1456 - map_at_10: 0.0964 - precision_at_10: 0.0312 - regularization_loss: 0.0469 - loss_batch: 4.3562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:merlin_models:The sampler InBatchSampler returned no samples for this batch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2194/2194 [==============================] - 64s 26ms/step - loss: 4.3563 - recall_at_10: 0.3120 - mrr_at_10: 0.0964 - ndcg_at_10: 0.1456 - map_at_10: 0.0964 - precision_at_10: 0.0312 - regularization_loss: 0.0469 - loss_batch: 4.3557 - val_loss: 3.5576 - val_recall_at_10: 0.4510 - val_mrr_at_10: 0.2752 - val_ndcg_at_10: 0.3147 - val_map_at_10: 0.2752 - val_precision_at_10: 0.0451 - val_regularization_loss: 0.0635 - val_loss_batch: 2.4614\n",
            "Epoch 2/10\n",
            "2194/2194 [==============================] - 58s 26ms/step - loss: 7.0354 - recall_at_10: 0.3588 - mrr_at_10: 0.1765 - ndcg_at_10: 0.2181 - map_at_10: 0.1765 - precision_at_10: 0.0359 - regularization_loss: 0.1229 - loss_batch: 7.0334 - val_loss: 3.6345 - val_recall_at_10: 0.3021 - val_mrr_at_10: 0.0890 - val_ndcg_at_10: 0.1377 - val_map_at_10: 0.0890 - val_precision_at_10: 0.0302 - val_regularization_loss: 0.1405 - val_loss_batch: 2.5384\n",
            "Epoch 3/10\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.7440 - recall_at_10: 0.3026 - mrr_at_10: 0.0867 - ndcg_at_10: 0.1360 - map_at_10: 0.0867 - precision_at_10: 0.0303 - regularization_loss: 0.1348 - loss_batch: 3.7438 - val_loss: 3.6201 - val_recall_at_10: 0.3013 - val_mrr_at_10: 0.0897 - val_ndcg_at_10: 0.1379 - val_map_at_10: 0.0897 - val_precision_at_10: 0.0301 - val_regularization_loss: 0.1259 - val_loss_batch: 2.5238\n",
            "Epoch 4/10\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 3.6661 - recall_at_10: 0.3050 - mrr_at_10: 0.0910 - ndcg_at_10: 0.1398 - map_at_10: 0.0910 - precision_at_10: 0.0305 - regularization_loss: 0.1143 - loss_batch: 3.6660 - val_loss: 3.5927 - val_recall_at_10: 0.2995 - val_mrr_at_10: 0.0872 - val_ndcg_at_10: 0.1356 - val_map_at_10: 0.0872 - val_precision_at_10: 0.0299 - val_regularization_loss: 0.0986 - val_loss_batch: 2.4965\n",
            "Epoch 5/10\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.5975 - recall_at_10: 0.3052 - mrr_at_10: 0.0879 - ndcg_at_10: 0.1375 - map_at_10: 0.0879 - precision_at_10: 0.0305 - regularization_loss: 0.0853 - loss_batch: 3.5974 - val_loss: 3.6018 - val_recall_at_10: 0.2934 - val_mrr_at_10: 0.0842 - val_ndcg_at_10: 0.1319 - val_map_at_10: 0.0842 - val_precision_at_10: 0.0293 - val_regularization_loss: 0.0763 - val_loss_batch: 2.4794\n",
            "Epoch 6/10\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 5.2356 - recall_at_10: 0.3831 - mrr_at_10: 0.2053 - ndcg_at_10: 0.2460 - map_at_10: 0.2053 - precision_at_10: 0.0383 - regularization_loss: 0.0904 - loss_batch: 5.2346 - val_loss: 3.5939 - val_recall_at_10: 0.6291 - val_mrr_at_10: 0.5893 - val_ndcg_at_10: 0.5983 - val_map_at_10: 0.5893 - val_precision_at_10: 0.0629 - val_regularization_loss: 0.0998 - val_loss_batch: 2.4978\n",
            "Epoch 7/10\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 5.2035 - recall_at_10: 0.4869 - mrr_at_10: 0.4243 - ndcg_at_10: 0.4387 - map_at_10: 0.4243 - precision_at_10: 0.0487 - regularization_loss: 0.1215 - loss_batch: 5.2025 - val_loss: 3.6230 - val_recall_at_10: 0.3003 - val_mrr_at_10: 0.0782 - val_ndcg_at_10: 0.1290 - val_map_at_10: 0.0782 - val_precision_at_10: 0.0300 - val_regularization_loss: 0.1290 - val_loss_batch: 2.5269\n",
            "Epoch 8/10\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 5.0757 - recall_at_10: 0.3011 - mrr_at_10: 0.0790 - ndcg_at_10: 0.1297 - map_at_10: 0.0790 - precision_at_10: 0.0301 - regularization_loss: 0.1301 - loss_batch: 5.0748 - val_loss: 3.6225 - val_recall_at_10: 0.2987 - val_mrr_at_10: 0.0791 - val_ndcg_at_10: 0.1292 - val_map_at_10: 0.0791 - val_precision_at_10: 0.0299 - val_regularization_loss: 0.1284 - val_loss_batch: 2.5263\n",
            "Epoch 9/10\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 6.5876 - recall_at_10: 0.3001 - mrr_at_10: 0.0788 - ndcg_at_10: 0.1294 - map_at_10: 0.0788 - precision_at_10: 0.0300 - regularization_loss: 0.1228 - loss_batch: 6.5866 - val_loss: 4.2035 - val_recall_at_10: 0.3007 - val_mrr_at_10: 0.0768 - val_ndcg_at_10: 0.1280 - val_map_at_10: 0.0768 - val_precision_at_10: 0.0301 - val_regularization_loss: 0.1242 - val_loss_batch: 2.7552\n",
            "Epoch 10/10\n",
            "2194/2194 [==============================] - 50s 22ms/step - loss: 4.7167 - recall_at_10: 0.3010 - mrr_at_10: 0.0783 - ndcg_at_10: 0.1291 - map_at_10: 0.0783 - precision_at_10: 0.0301 - regularization_loss: 0.1177 - loss_batch: 4.7163 - val_loss: 3.7266 - val_recall_at_10: 0.3023 - val_mrr_at_10: 0.0811 - val_ndcg_at_10: 0.1316 - val_map_at_10: 0.0811 - val_precision_at_10: 0.0302 - val_regularization_loss: 0.1135 - val_loss_batch: 2.5717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922e5deee30>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    schema=schema,\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    initial_epoch=10\n",
        "    # shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "buZGXRyoMCQR",
        "outputId": "b00b8fd4-dc37-4794-cc39-fea0f593cc9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "buZGXRyoMCQR",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "2194/2194 [==============================] - 49s 22ms/step - loss: 4.3707 - recall_at_10: 0.2994 - mrr_at_10: 0.0776 - ndcg_at_10: 0.1282 - map_at_10: 0.0776 - precision_at_10: 0.0299 - regularization_loss: 0.1081 - loss_batch: 4.3701 - val_loss: 3.6014 - val_recall_at_10: 0.2994 - val_mrr_at_10: 0.0769 - val_ndcg_at_10: 0.1277 - val_map_at_10: 0.0769 - val_precision_at_10: 0.0299 - val_regularization_loss: 0.1071 - val_loss_batch: 2.5050\n",
            "Epoch 12/20\n",
            "2194/2194 [==============================] - 50s 22ms/step - loss: 4.2492 - recall_at_10: 0.2999 - mrr_at_10: 0.0775 - ndcg_at_10: 0.1283 - map_at_10: 0.0775 - precision_at_10: 0.0300 - regularization_loss: 0.1018 - loss_batch: 4.2488 - val_loss: 3.5974 - val_recall_at_10: 0.2982 - val_mrr_at_10: 0.0765 - val_ndcg_at_10: 0.1271 - val_map_at_10: 0.0765 - val_precision_at_10: 0.0298 - val_regularization_loss: 0.1031 - val_loss_batch: 2.5013\n",
            "Epoch 13/20\n",
            "2194/2194 [==============================] - 56s 25ms/step - loss: 5.1365 - recall_at_10: 0.3013 - mrr_at_10: 0.0795 - ndcg_at_10: 0.1301 - map_at_10: 0.0795 - precision_at_10: 0.0301 - regularization_loss: 0.1104 - loss_batch: 5.1355 - val_loss: 3.6089 - val_recall_at_10: 0.3396 - val_mrr_at_10: 0.1362 - val_ndcg_at_10: 0.1826 - val_map_at_10: 0.1362 - val_precision_at_10: 0.0340 - val_regularization_loss: 0.1137 - val_loss_batch: 2.5116\n",
            "Epoch 14/20\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 3.7280 - recall_at_10: 0.3277 - mrr_at_10: 0.1246 - ndcg_at_10: 0.1710 - map_at_10: 0.1246 - precision_at_10: 0.0328 - regularization_loss: 0.1123 - loss_batch: 3.7279 - val_loss: 3.6014 - val_recall_at_10: 0.2993 - val_mrr_at_10: 0.0766 - val_ndcg_at_10: 0.1274 - val_map_at_10: 0.0766 - val_precision_at_10: 0.0299 - val_regularization_loss: 0.1066 - val_loss_batch: 2.5047\n",
            "Epoch 15/20\n",
            "2194/2194 [==============================] - 50s 22ms/step - loss: 3.8147 - recall_at_10: 0.3050 - mrr_at_10: 0.0845 - ndcg_at_10: 0.1349 - map_at_10: 0.0845 - precision_at_10: 0.0305 - regularization_loss: 0.1027 - loss_batch: 3.8145 - val_loss: 5.9463 - val_recall_at_10: 0.3003 - val_mrr_at_10: 0.0898 - val_ndcg_at_10: 0.1379 - val_map_at_10: 0.0898 - val_precision_at_10: 0.0300 - val_regularization_loss: 0.1042 - val_loss_batch: 2.5021\n",
            "Epoch 16/20\n",
            "2194/2194 [==============================] - 50s 22ms/step - loss: 5.7237 - recall_at_10: 0.5468 - mrr_at_10: 0.3698 - ndcg_at_10: 0.4111 - map_at_10: 0.3698 - precision_at_10: 0.0547 - regularization_loss: 0.1186 - loss_batch: 5.7225 - val_loss: 3.6142 - val_recall_at_10: 0.5201 - val_mrr_at_10: 0.3833 - val_ndcg_at_10: 0.4132 - val_map_at_10: 0.3833 - val_precision_at_10: 0.0520 - val_regularization_loss: 0.1198 - val_loss_batch: 2.5177\n",
            "Epoch 17/20\n",
            "2194/2194 [==============================] - 50s 23ms/step - loss: 7.2446 - recall_at_10: 0.5591 - mrr_at_10: 0.4610 - ndcg_at_10: 0.4836 - map_at_10: 0.4610 - precision_at_10: 0.0559 - regularization_loss: 0.1277 - loss_batch: 7.2425 - val_loss: 3.6242 - val_recall_at_10: 0.5695 - val_mrr_at_10: 0.5695 - val_ndcg_at_10: 0.5695 - val_map_at_10: 0.5695 - val_precision_at_10: 0.0569 - val_regularization_loss: 0.1302 - val_loss_batch: 2.5281\n",
            "Epoch 18/20\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 18.4883 - recall_at_10: 0.6872 - mrr_at_10: 0.6817 - ndcg_at_10: 0.6830 - map_at_10: 0.6817 - precision_at_10: 0.0687 - regularization_loss: 0.1697 - loss_batch: 18.4802 - val_loss: 3.6769 - val_recall_at_10: 0.3204 - val_mrr_at_10: 0.3204 - val_ndcg_at_10: 0.3204 - val_map_at_10: 0.3204 - val_precision_at_10: 0.0320 - val_regularization_loss: 0.1828 - val_loss_batch: 2.5807\n",
            "Epoch 19/20\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 3.9933 - recall_at_10: 0.6733 - mrr_at_10: 0.6194 - ndcg_at_10: 0.6323 - map_at_10: 0.6194 - precision_at_10: 0.0673 - regularization_loss: 0.1838 - loss_batch: 3.9930 - val_loss: 3.6699 - val_recall_at_10: 0.5396 - val_mrr_at_10: 0.5382 - val_ndcg_at_10: 0.5385 - val_map_at_10: 0.5382 - val_precision_at_10: 0.0540 - val_regularization_loss: 0.1759 - val_loss_batch: 2.5738\n",
            "Epoch 20/20\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 6.2858 - recall_at_10: 0.6147 - mrr_at_10: 0.5550 - ndcg_at_10: 0.5698 - map_at_10: 0.5550 - precision_at_10: 0.0615 - regularization_loss: 0.1796 - loss_batch: 6.2843 - val_loss: 3.6735 - val_recall_at_10: 0.9932 - val_mrr_at_10: 0.9932 - val_ndcg_at_10: 0.9932 - val_map_at_10: 0.9932 - val_precision_at_10: 0.0993 - val_regularization_loss: 0.1795 - val_loss_batch: 2.5774\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922e5defb20>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    schema=schema,\n",
        "    batch_size=32,\n",
        "    epochs=30,\n",
        "    initial_epoch=20\n",
        "    # shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "s_-nZzObTnU2",
        "outputId": "187c4241-ad78-4321-d6ef-73d110a707be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "s_-nZzObTnU2",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 3.6762 - recall_at_10: 0.7259 - mrr_at_10: 0.7224 - ndcg_at_10: 0.7233 - map_at_10: 0.7224 - precision_at_10: 0.0726 - regularization_loss: 0.1679 - loss_batch: 3.6761 - val_loss: 3.6507 - val_recall_at_10: 0.6606 - val_mrr_at_10: 0.6419 - val_ndcg_at_10: 0.6467 - val_map_at_10: 0.6419 - val_precision_at_10: 0.0661 - val_regularization_loss: 0.1566 - val_loss_batch: 2.5545\n",
            "Epoch 22/30\n",
            "2194/2194 [==============================] - 58s 26ms/step - loss: 4.5342 - recall_at_10: 0.7213 - mrr_at_10: 0.6803 - ndcg_at_10: 0.6905 - map_at_10: 0.6803 - precision_at_10: 0.0721 - regularization_loss: 0.1464 - loss_batch: 4.5336 - val_loss: 3.9705 - val_recall_at_10: 0.0030 - val_mrr_at_10: 0.0030 - val_ndcg_at_10: 0.0030 - val_map_at_10: 0.0030 - val_precision_at_10: 3.0092e-04 - val_regularization_loss: 0.1468 - val_loss_batch: 2.5447\n",
            "Epoch 23/30\n",
            "2194/2194 [==============================] - 59s 27ms/step - loss: 4.1471 - recall_at_10: 0.5244 - mrr_at_10: 0.5132 - ndcg_at_10: 0.5158 - map_at_10: 0.5132 - precision_at_10: 0.0524 - regularization_loss: 0.1389 - loss_batch: 4.1467 - val_loss: 3.6219 - val_recall_at_10: 0.6306 - val_mrr_at_10: 0.6241 - val_ndcg_at_10: 0.6258 - val_map_at_10: 0.6241 - val_precision_at_10: 0.0631 - val_regularization_loss: 0.1279 - val_loss_batch: 2.5257\n",
            "Epoch 24/30\n",
            "2194/2194 [==============================] - 64s 29ms/step - loss: 12.2520 - recall_at_10: 0.6657 - mrr_at_10: 0.6371 - ndcg_at_10: 0.6442 - map_at_10: 0.6371 - precision_at_10: 0.0666 - regularization_loss: 0.1451 - loss_batch: 12.2472 - val_loss: 3.6549 - val_recall_at_10: 0.7663 - val_mrr_at_10: 0.7663 - val_ndcg_at_10: 0.7663 - val_map_at_10: 0.7663 - val_precision_at_10: 0.0766 - val_regularization_loss: 0.1610 - val_loss_batch: 2.5589\n",
            "Epoch 25/30\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 5.7764 - recall_at_10: 0.6928 - mrr_at_10: 0.6720 - ndcg_at_10: 0.6772 - map_at_10: 0.6720 - precision_at_10: 0.0693 - regularization_loss: 0.1611 - loss_batch: 5.7752 - val_loss: 4.1171 - val_recall_at_10: 0.0799 - val_mrr_at_10: 0.0559 - val_ndcg_at_10: 0.0619 - val_map_at_10: 0.0559 - val_precision_at_10: 0.0080 - val_regularization_loss: 0.1674 - val_loss_batch: 2.5653\n",
            "Epoch 26/30\n",
            "2194/2194 [==============================] - 52s 23ms/step - loss: 4.6086 - recall_at_10: 0.6420 - mrr_at_10: 0.5651 - ndcg_at_10: 0.5842 - map_at_10: 0.5651 - precision_at_10: 0.0642 - regularization_loss: 0.1711 - loss_batch: 4.6080 - val_loss: 3.7028 - val_recall_at_10: 0.0184 - val_mrr_at_10: 0.0179 - val_ndcg_at_10: 0.0180 - val_map_at_10: 0.0179 - val_precision_at_10: 0.0018 - val_regularization_loss: 0.1753 - val_loss_batch: 2.5732\n",
            "Epoch 27/30\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 3.8571 - recall_at_10: 0.6332 - mrr_at_10: 0.4300 - ndcg_at_10: 0.4796 - map_at_10: 0.4300 - precision_at_10: 0.0633 - regularization_loss: 0.1706 - loss_batch: 3.8569 - val_loss: 3.6552 - val_recall_at_10: 0.0343 - val_mrr_at_10: 0.0042 - val_ndcg_at_10: 0.0107 - val_map_at_10: 0.0042 - val_precision_at_10: 0.0034 - val_regularization_loss: 0.1612 - val_loss_batch: 2.5591\n",
            "Epoch 28/30\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 3.6495 - recall_at_10: 0.3639 - mrr_at_10: 0.1739 - ndcg_at_10: 0.2172 - map_at_10: 0.1739 - precision_at_10: 0.0364 - regularization_loss: 0.1448 - loss_batch: 3.6494 - val_loss: 3.6202 - val_recall_at_10: 0.3733 - val_mrr_at_10: 0.2107 - val_ndcg_at_10: 0.2475 - val_map_at_10: 0.2107 - val_precision_at_10: 0.0373 - val_regularization_loss: 0.1260 - val_loss_batch: 2.5239\n",
            "Epoch 29/30\n",
            "2194/2194 [==============================] - 54s 24ms/step - loss: 3.6723 - recall_at_10: 0.3426 - mrr_at_10: 0.1534 - ndcg_at_10: 0.1965 - map_at_10: 0.1534 - precision_at_10: 0.0343 - regularization_loss: 0.1129 - loss_batch: 3.6722 - val_loss: 3.5941 - val_recall_at_10: 0.4466 - val_mrr_at_10: 0.2376 - val_ndcg_at_10: 0.2854 - val_map_at_10: 0.2376 - val_precision_at_10: 0.0447 - val_regularization_loss: 0.1001 - val_loss_batch: 2.4980\n",
            "Epoch 30/30\n",
            "2194/2194 [==============================] - 56s 25ms/step - loss: 4.8903 - recall_at_10: 0.4511 - mrr_at_10: 0.3504 - ndcg_at_10: 0.3733 - map_at_10: 0.3504 - precision_at_10: 0.0451 - regularization_loss: 0.0994 - loss_batch: 4.8895 - val_loss: 3.5901 - val_recall_at_10: 0.7452 - val_mrr_at_10: 0.7452 - val_ndcg_at_10: 0.7452 - val_map_at_10: 0.7452 - val_precision_at_10: 0.0745 - val_regularization_loss: 0.0962 - val_loss_batch: 2.4948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922fa0748e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    schema=schema,\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    initial_epoch=30\n",
        "    # shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "5ByXgUU1yP2T",
        "outputId": "c2333caa-72d3-4177-e439-38762bd4e28f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5ByXgUU1yP2T",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 7.2550 - recall_at_10: 0.6450 - mrr_at_10: 0.5660 - ndcg_at_10: 0.5853 - map_at_10: 0.5660 - precision_at_10: 0.0645 - regularization_loss: 0.1026 - loss_batch: 7.2530 - val_loss: 3.6137 - val_recall_at_10: 0.6239 - val_mrr_at_10: 0.6239 - val_ndcg_at_10: 0.6239 - val_map_at_10: 0.6239 - val_precision_at_10: 0.0624 - val_regularization_loss: 0.1196 - val_loss_batch: 2.5174\n",
            "Epoch 32/50\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 9.6542 - recall_at_10: 0.6776 - mrr_at_10: 0.6344 - ndcg_at_10: 0.6450 - map_at_10: 0.6344 - precision_at_10: 0.0678 - regularization_loss: 0.1363 - loss_batch: 9.6508 - val_loss: 3.6436 - val_recall_at_10: 0.9446 - val_mrr_at_10: 0.9342 - val_ndcg_at_10: 0.9367 - val_map_at_10: 0.9342 - val_precision_at_10: 0.0945 - val_regularization_loss: 0.1495 - val_loss_batch: 2.5474\n",
            "Epoch 33/50\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 4.8386 - recall_at_10: 0.5684 - mrr_at_10: 0.5342 - ndcg_at_10: 0.5419 - map_at_10: 0.5342 - precision_at_10: 0.0568 - regularization_loss: 0.1521 - loss_batch: 4.8379 - val_loss: 3.6582 - val_recall_at_10: 0.9807 - val_mrr_at_10: 0.9803 - val_ndcg_at_10: 0.9804 - val_map_at_10: 0.9803 - val_precision_at_10: 0.0981 - val_regularization_loss: 0.1641 - val_loss_batch: 2.5620\n",
            "Epoch 34/50\n",
            "2194/2194 [==============================] - 58s 26ms/step - loss: 3.8181 - recall_at_10: 0.4716 - mrr_at_10: 0.3593 - ndcg_at_10: 0.3846 - map_at_10: 0.3593 - precision_at_10: 0.0472 - regularization_loss: 0.1651 - loss_batch: 3.8179 - val_loss: 3.6557 - val_recall_at_10: 0.1852 - val_mrr_at_10: 0.0279 - val_ndcg_at_10: 0.0627 - val_map_at_10: 0.0279 - val_precision_at_10: 0.0185 - val_regularization_loss: 0.1572 - val_loss_batch: 2.5551\n",
            "Epoch 35/50\n",
            "2194/2194 [==============================] - 56s 25ms/step - loss: 3.8824 - recall_at_10: 0.5133 - mrr_at_10: 0.3625 - ndcg_at_10: 0.3956 - map_at_10: 0.3625 - precision_at_10: 0.0513 - regularization_loss: 0.1460 - loss_batch: 3.8822 - val_loss: 3.6316 - val_recall_at_10: 0.3138 - val_mrr_at_10: 0.1040 - val_ndcg_at_10: 0.1520 - val_map_at_10: 0.1040 - val_precision_at_10: 0.0314 - val_regularization_loss: 0.1375 - val_loss_batch: 2.5354\n",
            "Epoch 36/50\n",
            "2194/2194 [==============================] - 50s 23ms/step - loss: 5.5037 - recall_at_10: 0.3934 - mrr_at_10: 0.1935 - ndcg_at_10: 0.2388 - map_at_10: 0.1935 - precision_at_10: 0.0393 - regularization_loss: 0.1259 - loss_batch: 5.5026 - val_loss: 3.6056 - val_recall_at_10: 0.1335 - val_mrr_at_10: 0.0185 - val_ndcg_at_10: 0.0437 - val_map_at_10: 0.0185 - val_precision_at_10: 0.0134 - val_regularization_loss: 0.1115 - val_loss_batch: 2.5094\n",
            "Epoch 37/50\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 3.6141 - recall_at_10: 0.3361 - mrr_at_10: 0.1306 - ndcg_at_10: 0.1775 - map_at_10: 0.1306 - precision_at_10: 0.0336 - regularization_loss: 0.0973 - loss_batch: 3.6139 - val_loss: 3.5755 - val_recall_at_10: 0.2530 - val_mrr_at_10: 0.0551 - val_ndcg_at_10: 0.0999 - val_map_at_10: 0.0551 - val_precision_at_10: 0.0253 - val_regularization_loss: 0.0814 - val_loss_batch: 2.4793\n",
            "Epoch 38/50\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 4.9298 - recall_at_10: 0.3621 - mrr_at_10: 0.1778 - ndcg_at_10: 0.2198 - map_at_10: 0.1778 - precision_at_10: 0.0362 - regularization_loss: 0.0776 - loss_batch: 4.9290 - val_loss: 3.5731 - val_recall_at_10: 0.7005 - val_mrr_at_10: 0.7005 - val_ndcg_at_10: 0.7005 - val_map_at_10: 0.7005 - val_precision_at_10: 0.0701 - val_regularization_loss: 0.0789 - val_loss_batch: 2.4775\n",
            "Epoch 39/50\n",
            "2194/2194 [==============================] - 55s 25ms/step - loss: 13.1743 - recall_at_10: 0.6719 - mrr_at_10: 0.5877 - ndcg_at_10: 0.6087 - map_at_10: 0.5877 - precision_at_10: 0.0672 - regularization_loss: 0.1054 - loss_batch: 13.1691 - val_loss: 3.6216 - val_recall_at_10: 0.5185 - val_mrr_at_10: 0.5151 - val_ndcg_at_10: 0.5159 - val_map_at_10: 0.5151 - val_precision_at_10: 0.0518 - val_regularization_loss: 0.1275 - val_loss_batch: 2.5254\n",
            "Epoch 40/50\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 7.8838 - recall_at_10: 0.5508 - mrr_at_10: 0.4960 - ndcg_at_10: 0.5090 - map_at_10: 0.4960 - precision_at_10: 0.0551 - regularization_loss: 0.1419 - loss_batch: 7.8814 - val_loss: 3.6420 - val_recall_at_10: 0.3865 - val_mrr_at_10: 0.3852 - val_ndcg_at_10: 0.3855 - val_map_at_10: 0.3852 - val_precision_at_10: 0.0387 - val_regularization_loss: 0.1479 - val_loss_batch: 2.5458\n",
            "Epoch 41/50\n",
            "2194/2194 [==============================] - 56s 25ms/step - loss: 5.1984 - recall_at_10: 0.3939 - mrr_at_10: 0.2211 - ndcg_at_10: 0.2605 - map_at_10: 0.2211 - precision_at_10: 0.0394 - regularization_loss: 0.1557 - loss_batch: 5.1975 - val_loss: 3.6457 - val_recall_at_10: 0.2328 - val_mrr_at_10: 0.0439 - val_ndcg_at_10: 0.0864 - val_map_at_10: 0.0439 - val_precision_at_10: 0.0233 - val_regularization_loss: 0.1516 - val_loss_batch: 2.5495\n",
            "Epoch 42/50\n",
            "2194/2194 [==============================] - 50s 23ms/step - loss: 3.8595 - recall_at_10: 0.3234 - mrr_at_10: 0.1321 - ndcg_at_10: 0.1756 - map_at_10: 0.1321 - precision_at_10: 0.0323 - regularization_loss: 0.1446 - loss_batch: 3.8593 - val_loss: 3.6339 - val_recall_at_10: 0.2737 - val_mrr_at_10: 0.0671 - val_ndcg_at_10: 0.1140 - val_map_at_10: 0.0671 - val_precision_at_10: 0.0274 - val_regularization_loss: 0.1399 - val_loss_batch: 2.5378\n",
            "Epoch 43/50\n",
            "2194/2194 [==============================] - 59s 26ms/step - loss: 3.6224 - recall_at_10: 0.3457 - mrr_at_10: 0.1416 - ndcg_at_10: 0.1880 - map_at_10: 0.1416 - precision_at_10: 0.0346 - regularization_loss: 0.1249 - loss_batch: 3.6223 - val_loss: 3.6036 - val_recall_at_10: 0.2936 - val_mrr_at_10: 0.0760 - val_ndcg_at_10: 0.1257 - val_map_at_10: 0.0760 - val_precision_at_10: 0.0294 - val_regularization_loss: 0.1095 - val_loss_batch: 2.5074\n",
            "Epoch 44/50\n",
            "2194/2194 [==============================] - 53s 24ms/step - loss: 4.6701 - recall_at_10: 0.3153 - mrr_at_10: 0.1036 - ndcg_at_10: 0.1519 - map_at_10: 0.1036 - precision_at_10: 0.0315 - regularization_loss: 0.0974 - loss_batch: 4.6694 - val_loss: 3.5875 - val_recall_at_10: 0.7216 - val_mrr_at_10: 0.5328 - val_ndcg_at_10: 0.5756 - val_map_at_10: 0.5328 - val_precision_at_10: 0.0722 - val_regularization_loss: 0.0935 - val_loss_batch: 2.4914\n",
            "Epoch 45/50\n",
            "2194/2194 [==============================] - 52s 23ms/step - loss: 3.6162 - recall_at_10: 0.4129 - mrr_at_10: 0.2321 - ndcg_at_10: 0.2731 - map_at_10: 0.2321 - precision_at_10: 0.0413 - regularization_loss: 0.0863 - loss_batch: 3.6161 - val_loss: 3.5744 - val_recall_at_10: 0.5368 - val_mrr_at_10: 0.3387 - val_ndcg_at_10: 0.3839 - val_map_at_10: 0.3387 - val_precision_at_10: 0.0537 - val_regularization_loss: 0.0803 - val_loss_batch: 2.4782\n",
            "Epoch 46/50\n",
            "2194/2194 [==============================] - 57s 26ms/step - loss: 5.7730 - recall_at_10: 0.4256 - mrr_at_10: 0.2703 - ndcg_at_10: 0.3057 - map_at_10: 0.2703 - precision_at_10: 0.0426 - regularization_loss: 0.0864 - loss_batch: 5.7717 - val_loss: 4.1797 - val_recall_at_10: 0.2468 - val_mrr_at_10: 0.0531 - val_ndcg_at_10: 0.0969 - val_map_at_10: 0.0531 - val_precision_at_10: 0.0247 - val_regularization_loss: 0.0903 - val_loss_batch: 2.4882\n",
            "Epoch 47/50\n",
            "2194/2194 [==============================] - 57s 26ms/step - loss: 21.4589 - recall_at_10: 0.5582 - mrr_at_10: 0.4891 - ndcg_at_10: 0.5051 - map_at_10: 0.4891 - precision_at_10: 0.0558 - regularization_loss: 0.1156 - loss_batch: 21.4492 - val_loss: 3.6207 - val_recall_at_10: 0.5492 - val_mrr_at_10: 0.5460 - val_ndcg_at_10: 0.5467 - val_map_at_10: 0.5460 - val_precision_at_10: 0.0549 - val_regularization_loss: 0.1266 - val_loss_batch: 2.5244\n",
            "Epoch 48/50\n",
            "2194/2194 [==============================] - 58s 26ms/step - loss: 7.5693 - recall_at_10: 0.6074 - mrr_at_10: 0.5666 - ndcg_at_10: 0.5766 - map_at_10: 0.5666 - precision_at_10: 0.0607 - regularization_loss: 0.1364 - loss_batch: 7.5670 - val_loss: 3.6370 - val_recall_at_10: 0.4874 - val_mrr_at_10: 0.3459 - val_ndcg_at_10: 0.3766 - val_map_at_10: 0.3459 - val_precision_at_10: 0.0487 - val_regularization_loss: 0.1429 - val_loss_batch: 2.5408\n",
            "Epoch 49/50\n",
            "2194/2194 [==============================] - 56s 25ms/step - loss: 5.6013 - recall_at_10: 0.5392 - mrr_at_10: 0.4576 - ndcg_at_10: 0.4759 - map_at_10: 0.4576 - precision_at_10: 0.0539 - regularization_loss: 0.1546 - loss_batch: 5.6002 - val_loss: 3.6481 - val_recall_at_10: 0.6567 - val_mrr_at_10: 0.5317 - val_ndcg_at_10: 0.5601 - val_map_at_10: 0.5317 - val_precision_at_10: 0.0657 - val_regularization_loss: 0.1540 - val_loss_batch: 2.5519\n",
            "Epoch 50/50\n",
            "2194/2194 [==============================] - 51s 23ms/step - loss: 7.2006 - recall_at_10: 0.4124 - mrr_at_10: 0.2541 - ndcg_at_10: 0.2900 - map_at_10: 0.2541 - precision_at_10: 0.0412 - regularization_loss: 0.1535 - loss_batch: 7.1986 - val_loss: 3.6709 - val_recall_at_10: 0.7006 - val_mrr_at_10: 0.6994 - val_ndcg_at_10: 0.6997 - val_map_at_10: 0.6994 - val_precision_at_10: 0.0701 - val_regularization_loss: 0.1767 - val_loss_batch: 2.5746\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7922f42b8100>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rE4QwSopzHdV"
      },
      "id": "rE4QwSopzHdV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "merlin": {
      "containers": [
        "nvcr.io/nvidia/merlin/merlin-tensorflow:latest"
      ]
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "a398807c5c2ed8e5ff9d9890488d007fa99cbabcec733962e21659a28c5da99b"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}